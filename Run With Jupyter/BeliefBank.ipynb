{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jQ3-k15glgv"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/HLR/DomiKnowS.git\n",
        "%cd DomiKnowS\n",
        "!git checkout origin/Tasks\n",
        "!pip install DomiKnowS\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "import __main__\n",
        "__main__.__file__=\"beliefbank.py\"\n",
        "\n",
        "%cd beliefe_bank\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing specific classes and functions from various libraries"
      ],
      "metadata": {
        "id": "AZ6dkbj0hK-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from domiknows.program.lossprogram import SampleLossProgram\n",
        "import torch,argparse,sys\n",
        "from transformers import AdamW\n",
        "from domiknows.program.loss import NBCrossEntropyLoss, BCEWithLogitsIMLoss\n",
        "from domiknows.program.metric import MacroAverageTracker, PRF1Tracker, MetricTracker, CMWithLogitsMetric, DatanodeCMMetric\n",
        "import logging\n",
        "from reader import read_data\n",
        "from domiknows.graph import Graph, Concept, Relation, ifL, andL, notL, existsL\n",
        "from domiknows.program.lossprogram import PrimalDualProgram\n",
        "from domiknows.sensor.pytorch import ModuleLearner\n",
        "from domiknows.sensor.pytorch.relation_sensors import CompositionCandidateSensor\n",
        "from domiknows.sensor.pytorch.sensors import ReaderSensor, JointSensor, FunctionalSensor\n",
        "from utils import Generator, make_facts, label_reader, RobertaTokenizer, BBRobert,SimpleTokenizer\n",
        "from domiknows.program import SolverPOIProgram, IMLProgram\n",
        "from domiknows.program.model.pytorch import SolverModel, IMLModel"
      ],
      "metadata": {
        "id": "GZIbjUGnhJz-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuring the parser to take command line arguments for various parameters\n"
      ],
      "metadata": {
        "id": "turFibcnhUE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Args:\n",
        "    def __init__(self):\n",
        "        self.cuda_number = 0\n",
        "        self.cur_epoch = 5\n",
        "        self.samplenum = 15\n",
        "        self.simple_model = True\n",
        "        self.primaldual = False\n",
        "        self.IML = False\n",
        "        self.SAM = False\n",
        "        self.batch_size = 64\n",
        "        self.beta = 0.1\n",
        "        self.learning_rate = 2e-4\n",
        "\n",
        "args = Args()\n",
        "\n",
        "# Setting logging level to INFO\n",
        "logging.basicConfig(level=logging.INFO)"
      ],
      "metadata": {
        "id": "fj2vKFz-grQk"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the data and partitioning it into training and validation sets\n"
      ],
      "metadata": {
        "id": "_Cn3LsmDiIct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_data,silver_data,constraints_yes,constraints_no=read_data(batch_size=args.batch_size,sample_size=args.samplenum)\n",
        "train_size=len(calibration_data)*3//4\n",
        "calibration_data_dev=calibration_data[train_size:]\n",
        "calibration_data=calibration_data[:train_size]\n",
        "cuda_number= args.cuda_number\n",
        "device = \"cuda:\"+str(cuda_number) if torch.cuda.is_available() else 'cpu'\n",
        "print(\"device is : \",device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2h37lY-wiLBd",
        "outputId": "b8647bdb-bcfa-4c04-c78e-24a831ecf839"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of links: 4060\n",
            "data sizes: 16 254 1846 1846\n",
            "device is :  cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining helper functions guess_pair_yes and guess_pair_no to check if sentence pairs satisfy constraints\n"
      ],
      "metadata": {
        "id": "4SGY7agrije1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def guess_pair_yes(sentence, arg1, arg2):\n",
        "\n",
        "    if len(sentence)<2 or arg1==arg2:\n",
        "        return False\n",
        "    sentence1, sentence2 = arg1.getAttribute('sentence'), arg2.getAttribute('sentence')\n",
        "    if sentence1 in constraints_yes and sentence2 in constraints_yes[sentence1]:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def guess_pair_no(sentence, narg1, narg2):\n",
        "\n",
        "    if len(sentence)<2 or narg1==narg2:\n",
        "        return False\n",
        "    sentence1, sentence2 = narg1.getAttribute('sentence'), narg2.getAttribute('sentence')\n",
        "    if sentence1 in constraints_no and sentence2 in constraints_no[sentence1]:\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ],
      "metadata": {
        "id": "HLJZCNz6il51"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clearing the existing graphs, concepts, and relations"
      ],
      "metadata": {
        "id": "qplgCdSSir1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Graph.clear()\n",
        "Concept.clear()\n",
        "Relation.clear()"
      ],
      "metadata": {
        "id": "EKnI_fuaivre"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Constructing a graph to model the problem"
      ],
      "metadata": {
        "id": "soaBfpFZivwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with Graph('belief_bank') as graph:\n",
        "    subject = Concept(name='subject')\n",
        "    facts = Concept(name='facts')\n",
        "    subject_facts_contains, = subject.contains(facts)\n",
        "\n",
        "    fact_check = facts(name='fact_check')\n",
        "    implication = Concept(name='implication')\n",
        "    i_arg1, i_arg2 = implication.has_a(arg1=facts, arg2=facts)\n",
        "\n",
        "    nimplication = Concept(name='nimplication')\n",
        "    ni_arg1, ni_arg2 = nimplication.has_a(narg1=facts, narg2=facts)\n",
        "\n",
        "    ifL(andL(fact_check('x'), existsL(implication('s', path=('x', implication)))), fact_check(path=('s', i_arg2)))\n",
        "    #ifL(implication('s'), ifL(fact_check(path=('s',i_arg1.reversed)),fact_check(path=('s',i_arg2.reversed )) ) )\n",
        "    #ifL(andL(implication('s'),fact_check(path=('s',i_arg1.reversed)) ,fact_check(path=('s',i_arg2.reversed )) ) )\n",
        "    ifL(andL(fact_check('x'), existsL(nimplication('s', path=('x', nimplication)))), notL(fact_check(path=('s', ni_arg2))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yw515qKCiv1c",
        "outputId": "bc62af3e-8162-4a50-f09e-6af4c1570c34"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-a8b1ff6db25b>:8: UserWarning: Please use OrderedDict rather than dict to prevent unpredictable order of arguments.For this instance, OrderedDict([('arg1', 'facts'), ('arg2', 'facts')]) is used.\n",
            "  i_arg1, i_arg2 = implication.has_a(arg1=facts, arg2=facts)\n",
            "<ipython-input-23-a8b1ff6db25b>:11: UserWarning: Please use OrderedDict rather than dict to prevent unpredictable order of arguments.For this instance, OrderedDict([('narg1', 'facts'), ('narg2', 'facts')]) is used.\n",
            "  ni_arg1, ni_arg2 = nimplication.has_a(narg1=facts, narg2=facts)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuring the sensors to process the data and make inferences"
      ],
      "metadata": {
        "id": "9H1VllRBiv6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subject['name'] = ReaderSensor(keyword='name')\n",
        "subject['facts'] = ReaderSensor(keyword='facts')\n",
        "subject['labels'] = ReaderSensor(keyword='labels')\n",
        "\n",
        "facts[subject_facts_contains,\"name\", \"sentence\", 'label'] = JointSensor(\\\n",
        "    subject['name'], subject['facts'], subject['labels'],forward=make_facts,device=device)\n",
        "facts[fact_check] = FunctionalSensor(subject_facts_contains, \"label\", forward=label_reader, label=True,device=device)\n",
        "\n",
        "implication[i_arg1.reversed, i_arg2.reversed] = CompositionCandidateSensor(facts['sentence'],relations=(i_arg1.reversed, i_arg2.reversed),forward=guess_pair_yes,device=device)\n",
        "nimplication[ni_arg1.reversed, ni_arg2.reversed] = CompositionCandidateSensor(facts['sentence'],relations=(ni_arg1.reversed, ni_arg2.reversed),forward=guess_pair_no,device=device)\n"
      ],
      "metadata": {
        "id": "drOfMAc_i_6t"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuring the learning model"
      ],
      "metadata": {
        "id": "bx-949I7jABW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not args.simple_model:\n",
        "    facts[\"token_ids\", \"Mask\"] = JointSensor(\"name\", \"sentence\", forward=RobertaTokenizer(),device=device)\n",
        "    facts[fact_check] = ModuleLearner(\"token_ids\", \"Mask\", module=BBRobert(),device=device)\n",
        "else:\n",
        "    facts[\"emb\"] = JointSensor(\"name\", \"sentence\", forward=SimpleTokenizer(device),device=device)\n",
        "    facts[fact_check] = ModuleLearner(\"emb\", module=torch.nn.Linear(96, 2),device=device)\n",
        "\n",
        "f=open(\"output_save.txt\",\"w\")\n",
        "if not args.primaldual and not args.IML and not args.SAM:\n",
        "    program = SolverPOIProgram(graph, poi=[facts[fact_check],implication,nimplication],inferTypes=['ILP','local/argmax'],\\\n",
        "                    loss=MacroAverageTracker(NBCrossEntropyLoss()),metric={'ILP': PRF1Tracker(DatanodeCMMetric()),\\\n",
        "                                                'softmax': PRF1Tracker(DatanodeCMMetric('local/argmax'))},f=f)\n",
        "elif args.primaldual:\n",
        "    program = PrimalDualProgram(graph,SolverModel, poi=[facts[fact_check],implication,nimplication],inferTypes=['ILP','local/argmax'],\\\n",
        "                    loss=MacroAverageTracker(NBCrossEntropyLoss()),metric={'ILP': PRF1Tracker(DatanodeCMMetric()),\\\n",
        "                                               'softmax': PRF1Tracker(DatanodeCMMetric('local/argmax'))},beta=args.beta,device=device,f=f)\n",
        "elif args.IML:\n",
        "    program = IMLProgram(graph, poi=[facts[fact_check],implication,nimplication],inferTypes=['ILP','local/argmax'],\\\n",
        "                   loss=MacroAverageTracker(BCEWithLogitsIMLoss(lmbd=args.beta)),metric={'ILP': PRF1Tracker(DatanodeCMMetric()),\\\n",
        "                                               'softmax': PRF1Tracker(DatanodeCMMetric('local/argmax'))})\n",
        "elif args.SAM:\n",
        "    program = SampleLossProgram(graph, SolverModel,poi=[facts[fact_check],implication,nimplication],inferTypes=['ILP','local/argmax'],\n",
        "        metric={'argmax': PRF1Tracker(DatanodeCMMetric('local/argmax'))},loss=MacroAverageTracker(NBCrossEntropyLoss()),sample=True,sampleSize=50,sampleGlobalLoss=True,beta=args.beta,device=device)\n",
        "\n"
      ],
      "metadata": {
        "id": "Ar_MPWGtjAHd"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the program"
      ],
      "metadata": {
        "id": "Ho1FNpAOjAM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "program.train(calibration_data,valid_set=calibration_data_dev, train_epoch_num=args.cur_epoch, Optim=lambda param: AdamW(param, lr = args.learning_rate ,eps = 1e-9 ),device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZPvzFosjAR3",
        "outputId": "abddd44b-732f-4158-83b4-4f10e3bf7862"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1 Training: 100%|██████████| 12/12 [00:06<00:00,  1.89it/s]\n",
            "Epoch 1 Validation: 100%|██████████| 4/4 [00:02<00:00,  1.43it/s]\n",
            "Epoch 2 Training: 100%|██████████| 12/12 [00:09<00:00,  1.26it/s]\n",
            "Epoch 2 Validation: 100%|██████████| 4/4 [00:01<00:00,  2.00it/s]\n",
            "Epoch 3 Training: 100%|██████████| 12/12 [00:07<00:00,  1.64it/s]\n",
            "Epoch 3 Validation: 100%|██████████| 4/4 [00:03<00:00,  1.19it/s]\n",
            "Epoch 4 Training: 100%|██████████| 12/12 [00:06<00:00,  1.72it/s]\n",
            "Epoch 4 Validation: 100%|██████████| 4/4 [00:03<00:00,  1.21it/s]\n",
            "Epoch 5 Training: 100%|██████████| 12/12 [00:08<00:00,  1.49it/s]\n",
            "Epoch 5 Validation: 100%|██████████| 4/4 [00:02<00:00,  1.97it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the accuracy of the model and constraints using a subset of the silver_data"
      ],
      "metadata": {
        "id": "4OyB-BQ4jAW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ac_, t_ = 0, 0\n",
        "for datanode in program.populate(silver_data[:40], device=\"cpu\"):\n",
        "    #     tdatanode = datanode.findDatanodes(select = context)[0]\n",
        "    #     print(len(datanode.findDatanodes(select = context)))\n",
        "    #     print(tdatanode.getChildDataNodes(conceptName=step))\n",
        "\n",
        "\n",
        "    datanode.inferILPResults()\n",
        "    verifyResult = datanode.verifyResultsLC()\n",
        "    verifyResultILP = datanode.verifyResultsLC()\n",
        "    ac_ += sum([verifyResultILP[lc]['satisfied'] for lc in verifyResultILP])\n",
        "    t_ +=len(verifyResultILP.keys())\n",
        "\n",
        "print(\"constraint accuracy: \", ac_ / t_ )\n",
        "\n",
        "#, c_warmup_iters=0,test_set=silver_data\n",
        "f.close()\n",
        "_,silver_data_test,constraints_yes,constraints_no=read_data(batch_size=32*8,sample_size=40)\n",
        "\n",
        "program.test(silver_data_test[:30], device=device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnJXWU50jAd2",
        "outputId": "e27c9519-0b28-40c8-ca95-b9a2a53d1f50"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:29,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "constraint accuracy:  100.0\n",
            "number of links: 4060\n",
            "data sizes: 7 85 1846 1846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 30/30 [01:05<00:00,  2.18s/it]\n"
          ]
        }
      ]
    }
  ]
}