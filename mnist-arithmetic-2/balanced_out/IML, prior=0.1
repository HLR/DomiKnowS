/Users/alexanderwan/miniconda3/envs/domiknows/bin/python /Users/alexanderwan/Documents/alex_fork/DomiKnowS/examples/mnist-arithmetic-2/train.py
* Owlready2 * Warning: optimized Cython parser module 'owlready2_optimized' is not available, defaulting to slower Python implementation
Log file for dataNode is in: /Users/alexanderwan/Documents/alex_fork/DomiKnowS/examples/mnist-arithmetic-2/logs/datanode.log
INFO:regr.program.program:Epoch: 1
INFO:regr.program.program:Training:
Epoch 1 Training:   0%|          | 0/10000 [00:00<?, ?it/s]initializing optimizer
../../regr/program/model/iml.py:40: UserWarning: Failed to get inference result for digits0. Is it included in the inference (with `inference_with` attribute)? Continue with predicted value.
  warnings.warn(message)
../../regr/program/model/iml.py:40: UserWarning: Failed to get inference result for digits1. Is it included in the inference (with `inference_with` attribute)? Continue with predicted value.
  warnings.warn(message)
../../regr/program/model/iml.py:40: UserWarning: Failed to get inference result for summations. Is it included in the inference (with `inference_with` attribute)? Continue with predicted value.
  warnings.warn(message)
Epoch 1 Training: 100%|██████████| 10000/10000 [01:17<00:00, 129.07it/s]
INFO:regr.program.program: - loss:
INFO:regr.program.program:{'digits0': tensor(0.0252), 'digits1': tensor(0.0253), 'summations': tensor(0.3864)}
INFO:regr.program.program:Epoch: 2
INFO:regr.program.program:Training:
Epoch 2 Training: 100%|██████████| 10000/10000 [01:21<00:00, 122.98it/s]
INFO:regr.program.program: - loss:
INFO:regr.program.program:{'digits0': tensor(0.0261), 'digits1': tensor(0.0261), 'summations': tensor(0.3815)}
INFO:regr.program.program:Epoch: 3
INFO:regr.program.program:Training:
Epoch 3 Training: 100%|██████████| 10000/10000 [01:19<00:00, 125.81it/s]
INFO:regr.program.program: - loss:
INFO:regr.program.program:{'digits0': tensor(0.0263), 'digits1': tensor(0.0263), 'summations': tensor(0.3803)}
INFO:regr.program.program:Epoch: 4
INFO:regr.program.program:Training:
Epoch 4 Training: 100%|██████████| 10000/10000 [01:19<00:00, 126.09it/s]
INFO:regr.program.program: - loss:
INFO:regr.program.program:{'digits0': tensor(0.0264), 'digits1': tensor(0.0264), 'summations': tensor(0.3797)}
INFO:regr.program.program:Epoch: 5
INFO:regr.program.program:Training:
  0%|          | 0/1000 [00:00<?, ?it/s]train evaluation
Log file for ilpOntSolver is in: /Users/alexanderwan/Documents/alex_fork/DomiKnowS/examples/mnist-arithmetic-2/logs/ilpOntSolver.log
Log file for ilpOntSolverTime is in: /Users/alexanderwan/Documents/alex_fork/DomiKnowS/examples/mnist-arithmetic-2/logs/ilpOntSolver.log
INFO:gurobipy.gurobipy:Academic license - for non-commercial use only - expires 2022-09-17
INFO:gurobipy.gurobipy:Using license file /Users/alexanderwan/gurobi.lic
Academic license - for non-commercial use only - expires 2022-09-17
Using license file /Users/alexanderwan/gurobi.lic
100%|██████████| 1000/1000 [00:59<00:00, 16.88it/s]
============== RESULTS FOR: /ILP ==============
              precision    recall  f1-score   support

           0       0.98      1.00      0.99       182
           1       0.98      0.99      0.98       238
           2       0.94      0.99      0.96       207
           3       0.98      0.93      0.96       207
           4       0.99      0.97      0.98       192
           5       0.99      0.96      0.97       156
           6       0.99      0.99      0.99       179
           7       0.97      0.97      0.97       212
           8       0.96      0.99      0.98       209
           9       0.99      0.98      0.98       218

    accuracy                           0.98      2000
   macro avg       0.98      0.98      0.98      2000
weighted avg       0.98      0.98      0.98      2000

              precision    recall  f1-score   support

           0       1.00      1.00      1.00         4
           1       0.90      1.00      0.95        18
           2       0.97      0.97      0.97        34
           3       0.92      0.98      0.95        46
           4       0.92      0.94      0.93        49
           5       0.97      0.97      0.97        59
           6       0.96      0.94      0.95        72
           7       0.97      0.94      0.95        77
           8       0.97      0.98      0.97        87
           9       0.97      0.94      0.95       110
          10       0.95      0.94      0.95       105
          11       0.96      0.95      0.96        79
          12       0.97      0.94      0.96        68
          13       0.89      0.97      0.93        33
          14       0.95      0.98      0.96        41
          15       0.93      0.95      0.94        41
          16       0.94      0.94      0.94        35
          17       0.93      0.93      0.93        28
          18       1.00      1.00      1.00        14

    accuracy                           0.95      1000
   macro avg       0.95      0.96      0.96      1000
weighted avg       0.95      0.95      0.95      1000

==========================================
============== RESULTS FOR: /local/argmax ==============
              precision    recall  f1-score   support

           0       0.98      1.00      0.99       182
           1       0.98      0.99      0.98       238
           2       0.94      0.99      0.96       207
           3       0.98      0.93      0.96       207
           4       0.99      0.97      0.98       192
           5       0.99      0.96      0.97       156
           6       0.99      0.99      0.99       179
           7       0.97      0.97      0.97       212
           8       0.96      0.99      0.97       209
           9       0.98      0.98      0.98       218

    accuracy                           0.98      2000
   macro avg       0.98      0.98      0.98      2000
weighted avg       0.98      0.98      0.98      2000

              precision    recall  f1-score   support

           0       1.00      1.00      1.00         4
           1       0.95      1.00      0.97        18
           2       0.97      0.97      0.97        34
           3       0.92      0.98      0.95        46
           4       0.90      0.94      0.92        49
           5       0.98      0.97      0.97        59
           6       0.96      0.93      0.94        72
           7       0.97      0.94      0.95        77
           8       0.98      0.98      0.98        87
           9       0.95      0.95      0.95       110
          10       0.95      0.94      0.95       105
          11       0.97      0.96      0.97        79
          12       0.97      0.94      0.96        68
          13       0.89      0.97      0.93        33
          14       0.95      0.98      0.96        41
          15       0.93      0.95      0.94        41
          16       0.94      0.94      0.94        35
          17       0.93      0.93      0.93        28
          18       1.00      1.00      1.00        14

    accuracy                           0.95      1000
   macro avg       0.95      0.96      0.96      1000
weighted avg       0.95      0.95      0.95      1000

==========================================
validation evaluation
100%|██████████| 1000/1000 [01:00<00:00, 16.54it/s]
============== RESULTS FOR: /ILP ==============
              precision    recall  f1-score   support

           0       1.00      0.99      0.99       190
           1       0.98      1.00      0.99       209
           2       0.97      1.00      0.99       194
           3       0.98      0.97      0.97       202
           4       1.00      0.98      0.99       216
           5       0.98      0.93      0.96       195
           6       0.98      0.98      0.98       199
           7       0.99      0.99      0.99       225
           8       0.97      0.96      0.97       188
           9       0.93      0.99      0.96       182

    accuracy                           0.98      2000
   macro avg       0.98      0.98      0.98      2000
weighted avg       0.98      0.98      0.98      2000

              precision    recall  f1-score   support

           0       1.00      1.00      1.00        10
           1       1.00      0.88      0.94        17
           2       1.00      0.96      0.98        28
           3       0.89      1.00      0.94        48
           4       1.00      0.98      0.99        44
           5       0.96      0.96      0.96        56
           6       0.99      0.96      0.98        82
           7       0.95      0.96      0.95        72
           8       0.98      0.94      0.96        85
           9       0.98      0.96      0.97       123
          10       0.95      0.99      0.97        82
          11       0.99      0.94      0.96        96
          12       0.90      0.97      0.93        59
          13       0.96      0.90      0.93        50
          14       0.95      0.98      0.97        43
          15       0.96      0.98      0.97        51
          16       0.87      0.93      0.90        28
          17       0.95      1.00      0.98        20
          18       1.00      1.00      1.00         6

    accuracy                           0.96      1000
   macro avg       0.96      0.96      0.96      1000
weighted avg       0.96      0.96      0.96      1000

==========================================
============== RESULTS FOR: /local/argmax ==============
              precision    recall  f1-score   support

           0       0.99      0.99      0.99       190
           1       0.98      1.00      0.99       209
           2       0.97      1.00      0.99       194
           3       0.98      0.97      0.98       202
           4       1.00      0.98      0.99       216
           5       0.98      0.93      0.96       195
           6       0.98      0.98      0.98       199
           7       0.99      0.99      0.99       225
           8       0.97      0.96      0.97       188
           9       0.93      0.99      0.96       182

    accuracy                           0.98      2000
   macro avg       0.98      0.98      0.98      2000
weighted avg       0.98      0.98      0.98      2000

              precision    recall  f1-score   support

           0       1.00      1.00      1.00        10
           1       1.00      0.88      0.94        17
           2       1.00      0.96      0.98        28
           3       0.89      1.00      0.94        48
           4       1.00      0.98      0.99        44
           5       0.98      0.96      0.97        56
           6       0.99      0.96      0.98        82
           7       0.95      0.96      0.95        72
           8       0.98      0.94      0.96        85
           9       0.97      0.96      0.96       123
          10       0.94      0.99      0.96        82
          11       0.99      0.94      0.96        96
          12       0.90      0.97      0.93        59
          13       0.96      0.90      0.93        50
          14       0.98      0.98      0.98        43
          15       0.96      0.98      0.97        51
          16       0.87      0.93      0.90        28
          17       0.95      1.00      0.98        20
          18       1.00      1.00      1.00         6

    accuracy                           0.96      1000
   macro avg       0.96      0.96      0.96      1000
weighted avg       0.96      0.96      0.96      1000

==========================================
Epoch 5 Training: 100%|██████████| 10000/10000 [03:20<00:00, 49.95it/s]
INFO:regr.program.program: - loss:
INFO:regr.program.program:None
INFO:regr.program.program:Epoch: 6
INFO:regr.program.program:Training:
Epoch 6 Training:   0%|          | 0/10000 [00:00<?, ?it/s]../../regr/program/model/iml.py:40: UserWarning: Failed to get inference result for digits0. Is it included in the inference (with `inference_with` attribute)? Continue with predicted value.
  warnings.warn(message)
../../regr/program/model/iml.py:40: UserWarning: Failed to get inference result for digits1. Is it included in the inference (with `inference_with` attribute)? Continue with predicted value.
  warnings.warn(message)
../../regr/program/model/iml.py:40: UserWarning: Failed to get inference result for summations. Is it included in the inference (with `inference_with` attribute)? Continue with predicted value.
  warnings.warn(message)
Epoch 6 Training: 100%|██████████| 10000/10000 [01:18<00:00, 126.70it/s]
INFO:regr.program.program: - loss:
INFO:regr.program.program:{'digits0': tensor(0.0265), 'digits1': tensor(0.0265), 'summations': tensor(0.3790)}
INFO:regr.program.program:Epoch: 7
INFO:regr.program.program:Training:
Epoch 7 Training: 100%|██████████| 10000/10000 [01:19<00:00, 125.50it/s]
INFO:regr.program.program: - loss:
INFO:regr.program.program:{'digits0': tensor(0.0265), 'digits1': tensor(0.0265), 'summations': tensor(0.3789)}
INFO:regr.program.program:Epoch: 8
INFO:regr.program.program:Training:
Epoch 8 Training: 100%|██████████| 10000/10000 [01:20<00:00, 124.66it/s]
INFO:regr.program.program: - loss:
INFO:regr.program.program:{'digits0': tensor(0.0266), 'digits1': tensor(0.0265), 'summations': tensor(0.3787)}
INFO:regr.program.program:Epoch: 9
INFO:regr.program.program:Training:
Epoch 9 Training: 100%|██████████| 10000/10000 [01:21<00:00, 123.13it/s]
INFO:regr.program.program: - loss:
INFO:regr.program.program:{'digits0': tensor(0.0266), 'digits1': tensor(0.0265), 'summations': tensor(0.3788)}
INFO:regr.program.program:Epoch: 10
INFO:regr.program.program:Training:
  0%|          | 0/1000 [00:00<?, ?it/s]train evaluation
100%|██████████| 1000/1000 [00:57<00:00, 17.34it/s]
============== RESULTS FOR: /ILP ==============
              precision    recall  f1-score   support

           0       0.98      1.00      0.99       182
           1       0.97      0.99      0.98       238
           2       0.96      0.99      0.98       207
           3       0.99      0.94      0.97       207
           4       0.99      0.96      0.97       192
           5       0.99      0.97      0.98       156
           6       0.98      1.00      0.99       179
           7       0.99      0.97      0.98       212
           8       0.97      0.99      0.98       209
           9       0.97      0.99      0.98       218

    accuracy                           0.98      2000
   macro avg       0.98      0.98      0.98      2000
weighted avg       0.98      0.98      0.98      2000

              precision    recall  f1-score   support

           0       1.00      1.00      1.00         4
           1       0.82      1.00      0.90        18
           2       0.97      0.94      0.96        34
           3       0.92      0.98      0.95        46
           4       0.96      0.92      0.94        49
           5       0.98      0.98      0.98        59
           6       0.96      0.94      0.95        72
           7       1.00      0.95      0.97        77
           8       0.97      0.99      0.98        87
           9       0.97      0.95      0.96       110
          10       0.98      0.94      0.96       105
          11       0.97      0.94      0.95        79
          12       0.96      0.99      0.97        68
          13       0.91      0.97      0.94        33
          14       0.91      0.95      0.93        41
          15       0.91      0.95      0.93        41
          16       0.94      0.97      0.96        35
          17       0.96      0.93      0.95        28
          18       1.00      1.00      1.00        14

    accuracy                           0.96      1000
   macro avg       0.95      0.96      0.96      1000
weighted avg       0.96      0.96      0.96      1000

==========================================
============== RESULTS FOR: /local/argmax ==============
              precision    recall  f1-score   support

           0       0.98      1.00      0.99       182
           1       0.97      0.99      0.98       238
           2       0.96      0.99      0.98       207
           3       0.99      0.94      0.97       207
           4       0.99      0.96      0.97       192
           5       0.99      0.97      0.98       156
           6       0.98      1.00      0.99       179
           7       0.99      0.97      0.98       212
           8       0.97      0.99      0.98       209
           9       0.97      0.99      0.98       218

    accuracy                           0.98      2000
   macro avg       0.98      0.98      0.98      2000
weighted avg       0.98      0.98      0.98      2000

  0%|          | 0/1000 [00:00<?, ?it/s]              precision    recall  f1-score   support

           0       1.00      1.00      1.00         4
           1       0.82      1.00      0.90        18
           2       0.97      0.94      0.96        34
           3       0.92      0.98      0.95        46
           4       0.96      0.92      0.94        49
           5       0.98      0.98      0.98        59
           6       0.96      0.94      0.95        72
           7       1.00      0.95      0.97        77
           8       0.98      0.99      0.98        87
           9       0.96      0.96      0.96       110
          10       0.98      0.94      0.96       105
          11       0.99      0.94      0.96        79
          12       0.96      0.99      0.97        68
          13       0.92      1.00      0.96        33
          14       0.93      0.95      0.94        41
          15       0.91      0.98      0.94        41
          16       0.97      0.97      0.97        35
          17       0.93      0.93      0.93        28
          18       1.00      0.93      0.96        14

    accuracy                           0.96      1000
   macro avg       0.95      0.96      0.96      1000
weighted avg       0.96      0.96      0.96      1000

==========================================
validation evaluation
100%|██████████| 1000/1000 [00:56<00:00, 17.60it/s]
============== RESULTS FOR: /ILP ==============
              precision    recall  f1-score   support

           0       0.99      0.99      0.99       190
           1       0.99      0.99      0.99       209
           2       0.97      1.00      0.98       194
           3       0.98      0.98      0.98       202
           4       1.00      0.98      0.99       216
           5       0.96      0.93      0.95       195
           6       0.98      0.97      0.98       199
           7       0.98      0.98      0.98       225
           8       0.96      0.96      0.96       188
           9       0.95      0.98      0.96       182

    accuracy                           0.98      2000
   macro avg       0.98      0.98      0.98      2000
weighted avg       0.98      0.98      0.98      2000

              precision    recall  f1-score   support

           0       1.00      1.00      1.00        10
           1       1.00      1.00      1.00        17
           2       0.96      0.96      0.96        28
           3       0.96      1.00      0.98        48
           4       0.94      1.00      0.97        44
           5       0.98      0.96      0.97        56
           6       0.99      0.95      0.97        82
           7       0.91      0.96      0.93        72
           8       0.98      0.95      0.96        85
           9       0.97      0.94      0.95       123
          10       0.95      0.96      0.96        82
          11       0.98      0.93      0.95        96
          12       0.92      0.97      0.94        59
          13       0.91      0.86      0.89        50
          14       0.93      0.98      0.95        43
          15       0.96      0.94      0.95        51
          16       0.87      0.93      0.90        28
          17       0.95      1.00      0.98        20
          18       1.00      1.00      1.00         6

    accuracy                           0.95      1000
   macro avg       0.96      0.96      0.96      1000
weighted avg       0.95      0.95      0.95      1000

==========================================
============== RESULTS FOR: /local/argmax ==============
              precision    recall  f1-score   support

           0       0.99      0.99      0.99       190
           1       0.99      0.99      0.99       209
           2       0.97      1.00      0.98       194
           3       0.98      0.98      0.98       202
           4       1.00      0.98      0.99       216
           5       0.96      0.93      0.95       195
           6       0.98      0.97      0.98       199
           7       0.98      0.98      0.98       225
           8       0.96      0.96      0.96       188
           9       0.95      0.98      0.96       182

    accuracy                           0.98      2000
   macro avg       0.98      0.98      0.98      2000
weighted avg       0.98      0.98      0.98      2000

              precision    recall  f1-score   support

           0       1.00      1.00      1.00        10
           1       1.00      1.00      1.00        17
           2       0.96      0.96      0.96        28
           3       0.98      1.00      0.99        48
           4       0.94      1.00      0.97        44
           5       0.98      0.98      0.98        56
           6       0.99      0.95      0.97        82
           7       0.91      0.94      0.93        72
           8       0.98      0.94      0.96        85
           9       0.95      0.94      0.95       123
          10       0.94      0.96      0.95        82
          11       0.97      0.93      0.95        96
          12       0.92      0.95      0.93        59
          13       0.93      0.86      0.90        50
          14       0.93      0.98      0.95        43
          15       0.96      0.94      0.95        51
          16       0.87      0.93      0.90        28
          17       0.95      1.00      0.98        20
          18       1.00      1.00      1.00         6

    accuracy                           0.95      1000
   macro avg       0.96      0.96      0.96      1000
weighted avg       0.95      0.95      0.95      1000

==========================================
Epoch 10 Training: 100%|██████████| 10000/10000 [03:16<00:00, 50.77it/s]
INFO:regr.program.program: - loss:
INFO:regr.program.program:None
INFO:regr.program.program:Epoch: 11
INFO:regr.program.program:Training:
Epoch 11 Training:   0%|          | 0/10000 [00:00<?, ?it/s]../../regr/program/model/iml.py:40: UserWarning: Failed to get inference result for digits0. Is it included in the inference (with `inference_with` attribute)? Continue with predicted value.
  warnings.warn(message)
../../regr/program/model/iml.py:40: UserWarning: Failed to get inference result for digits1. Is it included in the inference (with `inference_with` attribute)? Continue with predicted value.
  warnings.warn(message)
../../regr/program/model/iml.py:40: UserWarning: Failed to get inference result for summations. Is it included in the inference (with `inference_with` attribute)? Continue with predicted value.
  warnings.warn(message)
Epoch 11 Training:  18%|█▊        | 1838/10000 [00:15<01:10, 115.13it/s]
Traceback (most recent call last):
  File "/Users/alexanderwan/Documents/alex_fork/DomiKnowS/examples/mnist-arithmetic-2/train.py", line 126, in <module>
    device='auto')
  File "../../regr/program/callbackprogram.py", line 54, in train
    super().train(*args, **kwargs)
  File "../../regr/program/program.py", line 270, in train
    self.call_epoch('Training', training_set, self.train_epoch, **kwargs)
  File "../../regr/program/program.py", line 209, in call_epoch
    consume(tqdm(epoch_fn(dataset, **kwargs), total=get_len(dataset), desc=desc))
  File "../../regr/utils.py", line 299, in consume
    collections.deque(it, maxlen=0)
  File "/Users/alexanderwan/miniconda3/envs/domiknows/lib/python3.7/site-packages/tqdm/std.py", line 1185, in __iter__
    for obj in iterable:
  File "../../regr/program/callbackprogram.py", line 68, in train_epoch
    self.train_pure_epoch(dataset),
  File "../../regr/program/callbackprogram.py", line 60, in train_pure_epoch
    for data_item in dataset:
  File "/Users/alexanderwan/miniconda3/envs/domiknows/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/Users/alexanderwan/miniconda3/envs/domiknows/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 557, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/Users/alexanderwan/miniconda3/envs/domiknows/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/Users/alexanderwan/miniconda3/envs/domiknows/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/Users/alexanderwan/Documents/alex_fork/DomiKnowS/examples/mnist-arithmetic-2/data.py", line 58, in __getitem__
    d1_image = self.dataset[d1_id]
  File "/Users/alexanderwan/miniconda3/envs/domiknows/lib/python3.7/site-packages/torchvision/datasets/mnist.py", line 106, in __getitem__
    img = self.transform(img)
  File "/Users/alexanderwan/miniconda3/envs/domiknows/lib/python3.7/site-packages/torchvision/transforms/transforms.py", line 60, in __call__
    img = t(img)
  File "/Users/alexanderwan/miniconda3/envs/domiknows/lib/python3.7/site-packages/torchvision/transforms/transforms.py", line 97, in __call__
    return F.to_tensor(pic)
  File "/Users/alexanderwan/miniconda3/envs/domiknows/lib/python3.7/site-packages/torchvision/transforms/functional.py", line 136, in to_tensor
    img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))
KeyboardInterrupt

Process finished with exit code 1
