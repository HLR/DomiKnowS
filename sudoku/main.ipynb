{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ethical-encoding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hfaghihi/Framework/fix/DomiKnowS/examples\n",
      "root Folder Absoloute path:  /home/hfaghihi/Framework/fix/DomiKnowS\n"
     ]
    }
   ],
   "source": [
    "import os,sys,inspect\n",
    "import json\n",
    "import torch\n",
    "currentdir = os.path.dirname(os.getcwd())\n",
    "print(currentdir)\n",
    "# parent_dir = os.path.abspath(os.path.join(currentdir, os.pardir))\n",
    "root = os.path.dirname(currentdir)\n",
    "print(\"root Folder Absoloute path: \", root)\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(root)\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "import __main__\n",
    "\n",
    "__main__.__file__=\"main.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "checked-fight",
   "metadata": {},
   "outputs": [],
   "source": [
    "from regr.data.reader import RegrReader\n",
    "import torch\n",
    "from random import sample\n",
    "import copy\n",
    "\n",
    "class SudokuReader(RegrReader):\n",
    "    def __init__(self, *args, **kargs):\n",
    "        super().__init__(*args, *kargs)\n",
    "        base  = 3\n",
    "        self.side  = base*base\n",
    "\n",
    "        # pattern for a baseline valid solution\n",
    "        def pattern(r,c): return (base*(r%base)+r//base+c)%self.side\n",
    "\n",
    "        # randomize rows, columns and numbers (of valid base pattern)\n",
    "        def shuffle(s): return sample(s,len(s)) \n",
    "        rBase = range(base) \n",
    "        rows  = [ g*base + r for g in shuffle(rBase) for r in shuffle(rBase) ] \n",
    "        cols  = [ g*base + c for g in shuffle(rBase) for c in shuffle(rBase) ]\n",
    "        nums  = shuffle(range(1,base*base+1))\n",
    "\n",
    "        # produce board using randomized baseline pattern\n",
    "        board = [ [nums[pattern(r,c)] for c in cols] for r in rows ]\n",
    "        self._sudoku = board\n",
    "        \n",
    "        board1 = copy.copy(self._sudoku)\n",
    "        squares = self.side*self.side\n",
    "        empties = squares * 3//4\n",
    "        F = []\n",
    "        for i in board1:\n",
    "            F.append([])\n",
    "            for j in i:\n",
    "                F[-1].append(j)\n",
    "                \n",
    "        for p in sample(range(squares),empties):\n",
    "            F[p//self.side][p%self.side] = 0\n",
    "        self.F = F\n",
    "        \n",
    "    def parse_file(self):\n",
    "        return [[\"random\"] * 1]\n",
    "    \n",
    "    def getidval(self, item):\n",
    "        return [1]\n",
    "    \n",
    "    def getwhole_sudokuval(self, item):\n",
    "        return torch.tensor(self.F)\n",
    "    \n",
    "    def getsudokuval(self, item):\n",
    "        return self._sudoku\n",
    "            \n",
    "    \n",
    "    def getsizeval(self, item):\n",
    "        return 9, 9\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "diverse-barbados",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainreader = SudokuReader(\"randn\", type=\"raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "increasing-berlin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': [1], 'size': (9, 9), 'sudoku': [[3, 7, 4, 2, 5, 9, 6, 1, 8], [6, 8, 1, 7, 4, 3, 9, 5, 2], [9, 2, 5, 8, 1, 6, 3, 4, 7], [1, 6, 2, 3, 8, 4, 5, 7, 9], [4, 3, 8, 9, 7, 5, 1, 2, 6], [5, 9, 7, 6, 2, 1, 4, 8, 3], [2, 1, 9, 4, 6, 8, 7, 3, 5], [7, 5, 3, 1, 9, 2, 8, 6, 4], [8, 4, 6, 5, 3, 7, 2, 9, 1]], 'whole_sudoku': tensor([[0, 0, 4, 0, 5, 0, 0, 0, 0],\n",
      "        [6, 0, 0, 0, 0, 3, 9, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 3, 0, 7],\n",
      "        [0, 0, 2, 0, 0, 0, 0, 7, 0],\n",
      "        [0, 3, 8, 9, 0, 0, 0, 0, 0],\n",
      "        [5, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "        [2, 0, 0, 0, 0, 0, 0, 3, 0],\n",
      "        [7, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [8, 0, 0, 0, 0, 0, 2, 0, 0]])}\n",
      "tensor([[0, 2],\n",
      "        [0, 4],\n",
      "        [1, 0],\n",
      "        [1, 5],\n",
      "        [1, 6],\n",
      "        [2, 4],\n",
      "        [2, 6],\n",
      "        [2, 8],\n",
      "        [3, 2],\n",
      "        [3, 7],\n",
      "        [4, 1],\n",
      "        [4, 2],\n",
      "        [4, 3],\n",
      "        [5, 0],\n",
      "        [5, 5],\n",
      "        [6, 0],\n",
      "        [6, 7],\n",
      "        [7, 0],\n",
      "        [7, 3],\n",
      "        [8, 0],\n",
      "        [8, 6]])\n",
      "(tensor([0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8]), tensor([2, 4, 0, 5, 6, 4, 6, 8, 2, 7, 1, 2, 3, 0, 5, 0, 7, 0, 3, 0, 6]))\n",
      "tensor([4, 5, 6, 3, 9, 1, 3, 7, 2, 7, 3, 8, 9, 5, 1, 2, 3, 7, 1, 8, 2])\n"
     ]
    }
   ],
   "source": [
    "item = next(iter(trainreader))\n",
    "print(item)\n",
    "indices = (item['whole_sudoku'] != 0).nonzero()\n",
    "print(indices)\n",
    "print(torch.where(item['whole_sudoku'] != 0))\n",
    "print(item['whole_sudoku'][indices[:, 0], indices[:, 1]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adaptive-spiritual",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file for dataNode is in: /home/hfaghihi/Framework/fix/DomiKnowS/examples/sudoku/logs/datanode.log\n",
      "col1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "main.py:26: UserWarning: Please use OrderedDict rather than dict to prevent unpredictable order of arguments.For this instance, OrderedDict([('arg1', 'empty_entry'), ('arg2', 'empty_entry')]) is used.\n",
      "  \n",
      "main.py:31: UserWarning: Please use OrderedDict rather than dict to prevent unpredictable order of arguments.For this instance, OrderedDict([('col1', 'empty_entry'), ('col2', 'empty_entry')]) is used.\n",
      "  class SudokuReader(RegrReader):\n",
      "main.py:36: UserWarning: Please use OrderedDict rather than dict to prevent unpredictable order of arguments.For this instance, OrderedDict([('entry1', 'empty_entry'), ('entry2', 'empty_entry')]) is used.\n",
      "  # pattern for a baseline valid solution\n"
     ]
    }
   ],
   "source": [
    "from regr.graph import Graph, Concept, Relation\n",
    "from regr.graph.logicalConstrain import orL, andL, existsL, notL, atLeastL, atMostL, ifL, nandL, V, exactL, fixedL, eqL\n",
    "from regr.graph import EnumConcept\n",
    "\n",
    "\n",
    "Graph.clear()\n",
    "Concept.clear()\n",
    "Relation.clear()\n",
    "\n",
    "with Graph('global') as graph:\n",
    "    sudoku = Concept(\"sodoku\")\n",
    "    \n",
    "#     empty_entries = Concept(name=\"empty_entries\")\n",
    "#     fixed_entries = Concept(name=\"fixed_entries\")\n",
    "    \n",
    "#     (sudoku_empty, sudoku_fixed) = sudoku.has_a(empty_entries, fixed_entries)\n",
    "    \n",
    "    empty_entry = Concept(name='empty_entry')\n",
    "    (empty_rel, ) = sudoku.contains(empty_entry)\n",
    "    \n",
    "#     fixed_entry = Concept(name='fixed_entry')\n",
    "#     (fixed_rel, ) = fixed_entries.contains(fixed_entry)\n",
    "    \n",
    "    same_row = Concept(name=\"same_row\")\n",
    "#     same_row_mixed = Concept(name=\"same_row_mixed\")\n",
    "    (same_row_arg1, same_row_arg2) = same_row.has_a(arg1=empty_entry, arg2=empty_entry)\n",
    "#     (same_row_mixed_arg1, same_row_mixed_arg2) = same_row_mixed.has_a(arg1=empty_entry, arg2=fixed_entry)\n",
    "    \n",
    "    same_col = Concept(name=\"same_col\")\n",
    "#     same_col_mixed = Concept(name=\"same_col_mixed\")\n",
    "    (same_col_arg1, same_col_arg2) = same_col.has_a(col1=empty_entry, col2=empty_entry)\n",
    "    print(same_col_arg1)\n",
    "#     (same_col_mixed_arg1, same_col_mixed_arg2) = same_col_mixed.has_a(arg1=empty_entry, arg2=fixed_entry)\n",
    "\n",
    "    same_table = Concept(name=\"same_table\")\n",
    "    (same_table_arg1, same_table_arg2) = same_table.has_a(entry1=empty_entry, entry2=empty_entry)\n",
    "    \n",
    "    empty_entry_label = empty_entry(name=\"empty_entry_label\", ConceptClass=EnumConcept, values=[\"v1\", \"v2\", \"v3\", \"v4\", \"v5\", \"v6\", \"v7\", \"v8\", \"v9\"])\n",
    "\n",
    "\n",
    "    ### Constraints\n",
    "    # entry = concept(name=\"entry\")\n",
    "    # entry[\"given\"] = ReaderSensor(keyword=\"given\")\n",
    "    # entry_label= entry(name=\"label\")\n",
    "    # fixedL(entry_label(\"x\", eqL(entry, \"given\", {True})))\n",
    "    \n",
    "    fixedL(empty_entry_label(\"x\", eqL(empty_entry, \"fixed\", {True})))\n",
    "    \n",
    "    #fixedL(empty_entry_label(\"x\", path=('x', eqL(empty_entry, \"fixed\", {True}))))\n",
    "\n",
    "    \n",
    "    for val in [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]:\n",
    "        ### No same number in the same row between empty entries and empty entries\n",
    "        ifL(getattr(empty_entry_label, f'v{val}')('x'), \n",
    "            notL(\n",
    "                existsL(\n",
    "                    andL(\n",
    "                        same_row('z', path=(\"x\", same_row_arg1.reversed)), \n",
    "                        getattr(empty_entry_label, f'v{val}')('y', path=(\"z\", same_row_arg2))\n",
    "                ))\n",
    "        ))\n",
    "        \n",
    "        ### No same number in the same column between empty entries and empty entries\n",
    "        ifL(getattr(empty_entry_label, f'v{val}')('x'), \n",
    "            notL(\n",
    "                existsL(\n",
    "                    andL(\n",
    "                        same_col('z', path=(\"x\", same_col_arg1.reversed)), \n",
    "                        getattr(empty_entry_label, f'v{val}')('y', path=(\"z\", same_col_arg2))\n",
    "                ))\n",
    "        ))\n",
    "        \n",
    "        ### No same number in the same table between empty entries and empty entries\n",
    "        ifL(getattr(empty_entry_label, f'v{val}')('x'), \n",
    "            notL(\n",
    "                existsL(\n",
    "                    andL(\n",
    "                        same_table('z', path=(\"x\", same_table_arg1.reversed)), \n",
    "                        getattr(empty_entry_label, f'v{val}')('y', path=(\"z\", same_table_arg2))\n",
    "                ))\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "advisory-edmonton",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Conv2dSame(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, bias=True, padding_layer=torch.nn.ReflectionPad2d):\n",
    "        \"\"\"It only support square kernels and stride=1, dilation=1, groups=1.\"\"\"\n",
    "        super(Conv2dSame, self).__init__()\n",
    "        ka = kernel_size // 2\n",
    "        kb = ka - 1 if kernel_size % 2 == 0 else ka\n",
    "        self.net = nn.Sequential(\n",
    "            padding_layer((ka,kb,ka,kb)),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, bias=bias),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class SudokuCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SudokuCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(Conv2dSame(1,512,3), #1\n",
    "                                         Conv2dSame(512,512,3),#2\n",
    "                                         Conv2dSame(512,512,3),#3\n",
    "                                         Conv2dSame(512,512,3),#4\n",
    "                                         Conv2dSame(512,512,3),#5\n",
    "                                         Conv2dSame(512,512,3),#6\n",
    "                                         Conv2dSame(512,512,3),#7\n",
    "                                         Conv2dSame(512,512,3),#8\n",
    "                                         Conv2dSame(512,512,3),#9\n",
    "                                         Conv2dSame(512,512,3),#10\n",
    "                                         Conv2dSame(512,512,3),#11\n",
    "                                         Conv2dSame(512,512,3),#12\n",
    "                                         Conv2dSame(512,512,3),#13\n",
    "                                         Conv2dSame(512,512,3),#14\n",
    "                                         Conv2dSame(512,512,3))#15\n",
    "        self.last_conv = nn.Conv2d(512, 9, 1)\n",
    "    def forward(self, x):\n",
    "        x = x.view(1, 1,9, 9)\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.last_conv(x)\n",
    "        x = x.permute(0,2,3,1)\n",
    "        x = x.view(81, 9)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "formal-double",
   "metadata": {},
   "outputs": [],
   "source": [
    "from regr.sensor.pytorch.sensors import FunctionalSensor, JointSensor, ReaderSensor, FunctionalReaderSensor\n",
    "from regr.sensor.pytorch.learners import ModuleLearner\n",
    "from regr.sensor.pytorch.relation_sensors import CompositionCandidateSensor, CompositionCandidateSensor\n",
    "from regr.sensor.pytorch.query_sensor import DataNodeReaderSensor\n",
    "\n",
    "class JointFunctionalReaderSensor(JointSensor, FunctionalReaderSensor):\n",
    "    pass\n",
    "\n",
    "\n",
    "# def getempties(*prev, data):\n",
    "#     rows, cols = torch.where(data == 0)\n",
    "#     rel = torch.ones(1, 1)\n",
    "#     return [rows], [cols]\n",
    "    \n",
    "def getfixed(*prev, data):\n",
    "    rows, cols = torch.where(data != 0)\n",
    "    fix = torch.zeros(data.shape)\n",
    "    vals = torch.ones(data.shape) * -1\n",
    "    for i, j in zip(rows.detach().tolist(), cols.detach().tolist()):\n",
    "        fix[i][j] = 1\n",
    "        vals[i][j] = data[i][j]\n",
    "        \n",
    "        \n",
    "    return fix.reshape(fix.shape[0]*fix.shape[1]), vals.reshape(vals.shape[0]*vals.shape[1])\n",
    "\n",
    "def makeSoduko(*prev, data):\n",
    "    num_rows = data[0]\n",
    "    num_cols = data[1]\n",
    "    rows = torch.arange(num_rows).unsqueeze(-1)\n",
    "    rows = rows.repeat(1,num_cols).reshape(num_rows*num_cols)\n",
    "    \n",
    "    cols = torch.arange(num_rows)\n",
    "    cols = cols.unsqueeze(0).repeat(num_rows, 1).reshape(num_rows*num_cols)\n",
    "    \n",
    "    rel = torch.ones(data[0]*data[1], 1)\n",
    "    \n",
    "    return rows, cols, rel\n",
    "\n",
    "def getlabel(*prev, data):\n",
    "    rows, cols = torch.where(data != 0)\n",
    "    vals = torch.ones(data.shape) * -100\n",
    "    for i, j in zip(rows.detach().tolist(), cols.detach().tolist()):\n",
    "        vals[i][j] = data[i][j] - 1\n",
    "        \n",
    "        \n",
    "    return vals.reshape(vals.shape[0]*vals.shape[1])\n",
    "    \n",
    "    \n",
    "def createSudoku(*prev, data):\n",
    "    return [1]\n",
    "\n",
    "sudoku['index'] = FunctionalReaderSensor(keyword='size', forward=createSudoku)\n",
    "    \n",
    "empty_entry['rows', 'cols', empty_rel] = JointFunctionalReaderSensor(sudoku['index'], keyword='size', forward=makeSoduko)\n",
    "empty_entry['fixed', 'val'] = JointFunctionalReaderSensor('rows', 'cols', empty_rel, keyword='whole_sudoku', forward=getfixed)\n",
    "\n",
    "empty_entry[empty_entry_label] = ModuleLearner('val', module=SudokuCNN())\n",
    "empty_entry[empty_entry_label] = FunctionalReaderSensor(keyword='whole_sudoku', label=True, forward=getlabel)\n",
    "\n",
    "def filter_col(*inputs, col1, col2):\n",
    "    if col1.getAttribute('cols').item() == col2.getAttribute('cols').item() and col1.instanceID != col2.instanceID:\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "same_col[same_col_arg1.reversed, same_col_arg2.reversed] = CompositionCandidateSensor(\n",
    "    empty_entry['cols'],\n",
    "    relations=(same_col_arg1.reversed, same_col_arg2.reversed),\n",
    "    forward=filter_col)\n",
    "\n",
    "def filter_row(*inputs, arg1, arg2):\n",
    "    if arg1.getAttribute('rows').item() == arg2.getAttribute('rows').item() and arg1.instanceID != arg2.instanceID:\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "same_row[same_row_arg1.reversed, same_row_arg2.reversed] = CompositionCandidateSensor(\n",
    "    empty_entry['rows'],\n",
    "    relations=(same_row_arg1.reversed, same_row_arg2.reversed),\n",
    "    forward=filter_row)\n",
    "\n",
    "\n",
    "def filter_table(*inputs, entry1, entry2):\n",
    "    if entry1.instanceID != entry2.instanceID:\n",
    "        if int(entry1.getAttribute('rows').item() / 3) == int(entry2.getAttribute('rows').item() / 3) and int(entry1.getAttribute('cols').item() / 3) == int(entry2.getAttribute('cols').item() / 3):\n",
    "            return True\n",
    "    return False\n",
    "    \n",
    "same_table[same_table_arg1.reversed, same_table_arg2.reversed] = CompositionCandidateSensor(\n",
    "    empty_entry['rows'], empty_entry['cols'],\n",
    "    relations=(same_table_arg1.reversed, same_table_arg2.reversed),\n",
    "    forward=filter_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "material-black",
   "metadata": {},
   "outputs": [],
   "source": [
    "from regr.program import POIProgram, SolverPOIProgram, IMLProgram, CallbackProgram\n",
    "from regr.program.callbackprogram import ProgramStorageCallback\n",
    "from regr.program.metric import MacroAverageTracker, PRF1Tracker, DatanodeCMMetric\n",
    "from regr.program.lossprogram import SampleLossProgram\n",
    "from regr.program.loss import NBCrossEntropyLoss, NBCrossEntropyIMLoss\n",
    "from regr.program.model.pytorch import SolverModel\n",
    "\n",
    "program = SolverPOIProgram(\n",
    "        graph, poi=(sudoku, empty_entry, ), inferTypes=['local/argmax'],\n",
    "        loss=MacroAverageTracker(NBCrossEntropyLoss()),\n",
    "        metric={\n",
    "            'argmax': PRF1Tracker(DatanodeCMMetric('local/argmax'))})\n",
    "\n",
    "program = SampleLossProgram(\n",
    "        graph, SolverModel,\n",
    "        poi=(sudoku, empty_entry, ),\n",
    "        inferTypes=['local/argmax'],\n",
    "        # inferTypes=['ILP', 'local/argmax'],\n",
    "        metric={\n",
    "            'argmax': PRF1Tracker(DatanodeCMMetric('local/argmax'))},\n",
    "\n",
    "        #metric={ 'softmax' : ValueTracker(prediction_softmax),\n",
    "        #       'ILP': PRF1Tracker(DatanodeCMMetric()),\n",
    "        #        'argmax': PRF1Tracker(DatanodeCMMetric('local/argmax'))\n",
    "        #       },\n",
    "        loss=MacroAverageTracker(NBCrossEntropyLoss()),\n",
    "        \n",
    "        sample = True,\n",
    "        sampleSize=300, \n",
    "        sampleGlobalLoss = False,\n",
    "        beta=10\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "improving-richards",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:regr.program.program:Epoch: 1\n",
      "INFO:regr.program.program:Training:\n",
      "INFO:regr.program.program: - loss:\n",
      "INFO:regr.program.program:{'empty_entry_label': tensor(2.2740)}\n",
      "INFO:regr.program.program: - Constraint loss:\n",
      "INFO:regr.program.program:{'LC5': tensor(-5.7038), 'LC9': tensor(-5.7038), 'LC13': tensor(-5.7038), 'LC17': tensor(-5.7038), 'LC21': tensor(-5.7038), 'LC25': tensor(-5.7038), 'LC29': tensor(-5.7038), 'LC33': tensor(-5.7038), 'LC37': tensor(-5.7038), 'LC41': tensor(-5.7038), 'LC45': tensor(-5.7038), 'LC49': tensor(-5.7038), 'LC53': tensor(-5.7038), 'LC57': tensor(-5.7038), 'LC61': tensor(-5.7038), 'LC65': tensor(-5.7038), 'LC69': tensor(-5.7038), 'LC73': tensor(-5.7038), 'LC77': tensor(-5.7038), 'LC81': tensor(-5.7038), 'LC85': tensor(-5.7038), 'LC89': tensor(-5.7038), 'LC93': tensor(-5.7038), 'LC97': tensor(-5.7038), 'LC101': tensor(-5.7038), 'LC105': tensor(-5.7038), 'LC109': tensor(-5.7038)}\n",
      "INFO:regr.program.program: - metric:\n",
      "INFO:regr.program.program: - - argmax\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    }
   ],
   "source": [
    "from IPython.utils import io\n",
    "\n",
    "for i in range(1):\n",
    "    with io.capture_output() as captured:\n",
    "        program.train(trainreader, train_epoch_num=1, c_warmup_iters=0, \n",
    "                      Optim=lambda param: torch.optim.SGD(param, lr=0.01), device='auto')\n",
    "    for datanode in program.populate(trainreader):\n",
    "        count = 0\n",
    "        _sud = list(trainreader)[0]['sudoku']\n",
    "        entries = datanode.getChildDataNodes(conceptName=empty_entry)\n",
    "        for entry in entries:\n",
    "            row = entry.getAttribute('rows').item()\n",
    "            col = entry.getAttribute('cols').item()\n",
    "            val = entry.getAttribute(empty_entry_label, 'local/argmax').argmax(dim=-1)\n",
    "            if val != _sud[row][col]:\n",
    "                count += 1\n",
    "        print(count)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "thirty-swaziland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sodoku 0\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(7, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(7, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(7, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(7, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(7, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(7, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(7, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(7, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(7, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(7, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(7, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(7, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(7, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(7, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(7, device='cuda:0')\n",
      "tensor(7, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(7, device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(8, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(8, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(8, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(8, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(8, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(8, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(8, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(8, device='cuda:0')\n",
      "tensor(7, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n",
      "tensor(8, device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for datanode in program.populate(trainreader):\n",
    "    print(datanode)\n",
    "    \n",
    "    entries = datanode.getChildDataNodes(conceptName=empty_entry)\n",
    "    for entry in entries:\n",
    "        print(entry.getAttribute('rows'))\n",
    "        print(entry.getAttribute('cols'))\n",
    "        print(entry.getAttribute(empty_entry_label, 'local/argmax'))\n",
    "        print(\"---\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-organic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
