In a running session, for example a forward (and backward) calculation in training or testing, the internal values are maintained in a python `dict`, namely `context: Dict[str, Any]`, and passed between sensors and learners.
It is the argument in `Sensor.forward(...)` interface, that you need to interact with.

## Data structure

The `context` argument is simply a python `dict`. The keys are strings and the values are any values or python objects.

However, there is a convention to __store output of each sensor, which is the value return by `Sensor.forward(...)`, with the `fullname` of the sensor, and the `fullname` of the associated property at the same time.__

## Caching trick

The convention is implemented in `Sensor` base class and will be applied automatically when one uses `Sensor.__call__(...)` instead of `Sensor.forward(...)`, which is intended. In this case, a sensor (or learner) will look at the `context` first, return the value if it is already there. Otherwise, it will redirect to `forward(...)`, cache the return value using `self.fullname` and `self.sup.fullname`, then return the same value.

### Multiple Assignment Semantic

Since we allow [multiple assignments](Dev-%7C-Property-%7C-Assignment#multiple-assignments) to property, the value to be stored in the cache with the property's name could be ambiguous. With the default implementation, the `context` contains both property-level values and sensor-level values. We use a sensor's name for the result from exact this sensor and a property's name for the same result of an assigned sensor **lastly** executed.
For example, we have the following set up
``` python
c = Concept()
sensor = Sensor()
c['label'] = sensor
learner = Learner()
c['label'] = learner
# ...
context = {}
sensor(context)
learner(context)
# ...
c_label = list(c.poi).pop()
```
Then, `context[sensor.fullname]` should give value generated by the `sensor`;  `context[learner.fullname]` should give value generated by the `learner`; `context[c_label.fullname]` should give value generated by the `learner`, which is executed later then the `sensor`.

However, how to use this `context` is totally unconstrainted! Users can override the behavior of the cache to fit their programs.

## Ordering

One problem when we need to handle the complex computation with multiple components is the order. The context cache provides a potential implement to easy handling of the computation order. Starting from any sensor you need, just call the pre-required sensor first to make sure it is in the cache, retrieve it from the context, and consume it. You do not need to worry about the repeated calculation of the same sensor if it is required by multiple sensors because it will cache using the `context` by itself.

However, there is not a general way to provide "pre-required" sensor(s). And different frameworks do have a different flavor to handle computational order. We did not implement this in the core `regr` package. Rather, we implement for the platforms we have native support (like AllenNLP, Flair) separately. We also provide an example to use this pattern with bare pyTorch code.
