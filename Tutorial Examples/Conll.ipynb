{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg5_lfTjRIyA"
      },
      "source": [
        "# CONLL Entity Relation Extraction Tutorial\n",
        "\n",
        "\n",
        "\n",
        "This tutorial is to show you how to make a very simple, yet thorough learning program that also utilizes the domain knowledge to apply constraints on Entity Recognition and Relation Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsSnpr4uVA1W"
      },
      "source": [
        "First dowload DomiKnows and prepare the environment to execute the example."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install DomiKnowS"
      ],
      "metadata": {
        "id": "gNptVm70ETuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -b Examples --single-branch --filter=blob:none --no-checkout https://github.com/HLR/DomiKnowS\n",
        "%cd DomiKnowS\n",
        "!git sparse-checkout set conll04 tutorials\n",
        "!mv * ..\n",
        "%cd .."
      ],
      "metadata": {
        "id": "IPb32hcwmdrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/')\n",
        "\n",
        "print(\"sys.path - %s\"%(sys.path))"
      ],
      "metadata": {
        "id": "jG2yF6spoXdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "!python3 /content/conll04/scripts/split.py /content/conll04/data/conll04.corp\n",
        "\n",
        "import __main__\n",
        "__main__.__file__=\"connl04.py\""
      ],
      "metadata": {
        "id": "jVtXRP_noeoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PT_HvHjDRIyD"
      },
      "source": [
        "### Task\n",
        "The task is to detect entities and relationships from a sentence and classify them correctly. Following is an example of this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhDNK_XwRIyD"
      },
      "source": [
        "from IPython.display import Image\n",
        "Image(filename='tutorials/emr_example.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY4UQANSRIyE"
      },
      "source": [
        "## The Graph\n",
        "First we define the graph code that defines the domain knowledge for this problem.\n",
        "This graph defines a set of input side data structure in the subgraph of *linguistics* and define the output decision space in the subgraph of *application*. We encourage you to follow the same split for more readable graph declaration but the structure is optional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfOTYkxARIyE"
      },
      "source": [
        "from domiknows.graph import Graph, Concept, Relation\n",
        "from domiknows.graph.logicalConstrain import ifL, andL, nandL, V, orL, exactL\n",
        "\n",
        "Graph.clear()\n",
        "Concept.clear()\n",
        "Relation.clear()\n",
        "\n",
        "with Graph('global') as graph:\n",
        "    with Graph('linguistic') as ling_graph:\n",
        "        word = Concept(name='word')\n",
        "        phrase = Concept(name='phrase')\n",
        "        sentence = Concept(name='sentence')\n",
        "        (rel_sentence_contains_word,) = sentence.contains(word)\n",
        "        (rel_sentence_contains_phrase,) = sentence.contains(phrase)\n",
        "        (rel_phrase_contains_word,) = phrase.contains(word)\n",
        "\n",
        "        pair = Concept(name='pair')\n",
        "        (rel_pair_phrase1, rel_pair_phrase2) = pair.has_a(arg1=phrase, arg2=phrase)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFGHvvHZRIyE"
      },
      "source": [
        "The graph structure can be used as a background knowledge to introduce rules into the inference algorithms automatically, you can specify the keyword *auto_constraint* to be **True** if you want to generate automatic constraints based on the graph. You can disable the constraint generation for specific relationship definition by setting the same parameter as **False**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHor-ukSRIyF"
      },
      "source": [
        "with graph:\n",
        "    with Graph('application', auto_constraint=True) as app_graph:\n",
        "        entity = phrase(name='entity')\n",
        "        people = entity(name='people', auto_constraint=True)\n",
        "        organization = entity(name='organization', auto_constraint=False)\n",
        "        location = entity(name='location', auto_constraint=None)\n",
        "        # auto_constraint->True due to its graph\n",
        "        other = entity(name='other')\n",
        "        o = entity(name='O')\n",
        "\n",
        "        work_for = pair(name='work_for')\n",
        "\n",
        "        located_in = pair(name='located_in')\n",
        "\n",
        "        live_in = pair(name='live_in')\n",
        "        # auto_constraint->True due to its graph\n",
        "\n",
        "        orgbase_on = pair(name='orgbase_on')\n",
        "        kill = pair(name='kill')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mVRNo4gRIyF"
      },
      "source": [
        "The **has_a** relationship is equivalant to having a many to many relationships between the arguments in the relation. So the *pair*, we are introducing a relationship between phrases. The **contains** relationship also implies a parent child structure which is a one-to-many relationship between the concept that contains the other one and the concept being contained."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0h6HjxpNJUl"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFbkDWiGRIyG"
      },
      "source": [
        "from domiknows.graph.relation import disjoint\n",
        "\n",
        "with graph:\n",
        "    with app_graph:\n",
        "        ifL(work_for('x'), andL(people(path=('x', rel_pair_phrase1.name)), organization(path=('x', rel_pair_phrase2.name))))\n",
        "\n",
        "        ifL(located_in('x'), andL(location(path=('x', rel_pair_phrase1.name)), location(path=('x', rel_pair_phrase2.name))))\n",
        "        #located_in.has_a(location, location, auto_constraint=True)\n",
        "\n",
        "        ifL(live_in('x'), andL(people(path=('x', rel_pair_phrase1.name)), location(path=('x', rel_pair_phrase2.name))))\n",
        "        #live_in.has_a(people, location, auto_constraint=None)\n",
        "\n",
        "        ifL(orgbase_on('x'), andL(organization(path=('x', rel_pair_phrase1.name)), location(path=('x', rel_pair_phrase2.name))))\n",
        "\n",
        "        ifL(kill('x'), andL(people(path=('x', rel_pair_phrase1.name)), people(path=('x', rel_pair_phrase2.name))))\n",
        "\n",
        "        exactL(people, organization, location, other, o)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtkgIDgdRIyG"
      },
      "source": [
        "To introduce the domain range constraints for relationships, we can use either the **has_a** graph structure or directluy introduce a constraint by using our Constraint interface. Remember that if you use the **has_a** to introduce the rules for the domain and range of the arguments, you have to specify the auto_constraints to be *True*. If you put *auto_constraint=None* or do not add any *auto_constraint* input then the *auto_constraint* value will be inherited from the graph definition as all the nodes and relationships are defined inside the graph.\n",
        "\n",
        "The **exactL** constraint is also implying that the concept classes mentioned in the paranthesis are disjoint.\n",
        "\n",
        "For more information on how to write your own constraints, please refer to our constraint interface tutorials and documents!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5K2vv4jRIyG"
      },
      "source": [
        "### Visualize\n",
        "We can use the following code to visualize the graph representations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cji2t_26RIyH"
      },
      "source": [
        "graph.visualize(\"./image\")\n",
        "Image(filename='image.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXbMUXqKRIyH"
      },
      "source": [
        "## Data and Data Reader\n",
        "Here we use the Pytorch DataLoader to define our training and test instances. You can use your customized readers as long as the output for the reader class is an iterable object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmeeglgsRIyH"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from conll04.conll.data.reader import Conll04CorpusReader\n",
        "\n",
        "class Conll04DataLoader(DataLoader):\n",
        "    def __init__(self, path, reader=None, **kwargs):\n",
        "        self.path = path\n",
        "        self.reader = reader or Conll04CorpusReader()\n",
        "        sentences_list, relations_list = self.reader(path)\n",
        "        samples = list(zip(sentences_list, relations_list))\n",
        "        super().__init__(samples, collate_fn=self._collate_fn, **kwargs)\n",
        "\n",
        "    def _collate_fn(self, batch):\n",
        "        sentences, relations = zip(*batch)\n",
        "        # (tokens, pos, label)\n",
        "        # (relation_type, (src_index, src_token), (dst_index, dst_token))\n",
        "        tokens, postags, labels = zip(*sentences)\n",
        "        data_item = {\n",
        "            'sentence': [' '.join(token_list) for token_list in tokens],\n",
        "            'tokens': list(tokens),\n",
        "            'postag': list(postags),\n",
        "            'label': list(labels),\n",
        "            'relation': list(relations),\n",
        "        }\n",
        "        #import pdb; pdb.set_trace()\n",
        "        return data_item\n",
        "\n",
        "class SingletonDataLoader(Conll04DataLoader):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, batch_size=1, **kwargs)\n",
        "\n",
        "    def _collate_fn(self, batch):\n",
        "        assert len(batch) == 1\n",
        "        sentences, relations = zip(*batch)\n",
        "        # (tokens, pos, label)\n",
        "        # (relation_type, (src_index, src_token), (dst_index, dst_token))\n",
        "        tokens, postags, labels = zip(*sentences)\n",
        "        data_item = {\n",
        "            #'sentence': [' '.join(token_list) for token_list in tokens],\n",
        "            'tokens': tokens[0],\n",
        "            'postag': postags[0],\n",
        "            'label': labels[0],\n",
        "            'relation': relations[0],\n",
        "        }\n",
        "        return data_item"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ia864_AjRIyI"
      },
      "source": [
        "Let's see how the output of the reader looks like"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3UWqRJQRIyI"
      },
      "source": [
        "train_reader = SingletonDataLoader('conll04/data/conll04.corp_1_train.corp')\n",
        "test_reader = SingletonDataLoader('conll04/data/conll04.corp_1_test.corp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJwWVd1RRIyI"
      },
      "source": [
        "print(list(iter(train_reader))[120])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gYuV09qRIyI"
      },
      "source": [
        "We have defined the keywords to be `tokens`, `postag`, `label`, `relation`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0iIXU-nRIyI"
      },
      "source": [
        "## Model Declaration\n",
        "\n",
        "In this section, we start by defining our sensors and required toolkits and then start connecting our sensors and learners to their right place in the graph.\n",
        "\n",
        "First, As we want to use `Spacy` to define the word features, we intialize a `Spacy` instance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbt8ry0oRIyI"
      },
      "source": [
        "import spacy\n",
        "# from spacy.lang.en import English\n",
        "nlp = spacy.load('en_core_web_sm') #English()\n",
        "\n",
        "FEATURE_DIM = 96"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBmCMRv9RIyJ"
      },
      "source": [
        "We also define a classifier which we will use later in the process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElS63FggRIyJ"
      },
      "source": [
        "import torch\n",
        "\n",
        "class Classifier(torch.nn.Sequential):\n",
        "    def __init__(self, in_features) -> None:\n",
        "        linear = torch.nn.Linear(in_features, 2)\n",
        "        super().__init__(linear)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpbsfe01RIyJ"
      },
      "source": [
        "Next we import a set of our predefined basic sensors which enables us to use the functionality of the DomiKnows declarative sensor and learner definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffX_NWHpRIyJ"
      },
      "source": [
        "from domiknows.sensor.pytorch.sensors import FunctionalSensor, JointSensor, ReaderSensor, FunctionalReaderSensor\n",
        "from domiknows.sensor.pytorch.learners import ModuleLearner\n",
        "from domiknows.sensor.pytorch.relation_sensors import CompositionCandidateSensor\n",
        "from domiknows.sensor.pytorch.query_sensor import DataNodeReaderSensor\n",
        "\n",
        "graph.detach()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRhC13yDRIyJ"
      },
      "source": [
        "Then we start by Definign some **ReaderSensor**s to connect our DataLoader with appropriate properties in the graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqKYjOdbRIyJ"
      },
      "source": [
        "phrase['text'] = ReaderSensor(keyword='tokens')\n",
        "phrase['postag'] = ReaderSensor(keyword='postag')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSEPlKFRRIyK"
      },
      "source": [
        "After reading the data about the Phrases, we also read the annotation of labels into the graph by using a customized **ReaderSensor** which we call **FunctionalReaderSensor**. In addition to having access to the DataLoader output, the **FunctionalReaderSensor** accepts a function as input at initialization which it will apply on the read data before generating the outputs. Remember to put `label=True` Whenever you are reading an annotation to the graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfB5yfaHRIyK"
      },
      "source": [
        "def find_label(label_type):\n",
        "        def find(data):\n",
        "            try:\n",
        "                label = torch.tensor([item==label_type for item in data])\n",
        "            except:\n",
        "                print(data)\n",
        "                raise\n",
        "            return label # torch.stack((~label, label), dim=1)\n",
        "        return find\n",
        "        raise\n",
        "phrase[people] = FunctionalReaderSensor(keyword='label', forward=find_label('Peop'), label=True)\n",
        "phrase[organization] = FunctionalReaderSensor(keyword='label', forward=find_label('Org'), label=True)\n",
        "phrase[location] = FunctionalReaderSensor(keyword='label', forward=find_label('Loc'), label=True)\n",
        "phrase[other] = FunctionalReaderSensor(keyword='label', forward=find_label('Other'), label=True)\n",
        "phrase[o] = FunctionalReaderSensor(keyword='label', forward=find_label('O'), label=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lx1hDdrtRIyK"
      },
      "source": [
        "Next, We define a word to vector sensor using a **FunctionalSensor** to generate the word representation from their string utilizing the spacy library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XA8-r93XRIyK"
      },
      "source": [
        "def word2vec(text):\n",
        "    texts = list(map(lambda x: ' '.join(x.split('/')), text))\n",
        "    tokens_list = list(nlp.pipe(texts))\n",
        "    return torch.tensor([tokens.vector for tokens in tokens_list])\n",
        "\n",
        "phrase['w2v'] = FunctionalSensor('text', forward=word2vec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rrX-OUARIyK"
      },
      "source": [
        "Now as our data included the phrases directly, we want to merge phrases in the same sentence to create the concept nodes for `sentence`. To generate a concept from another one, we have to use the edges defined on the graph between those two concepts. Here we use the `contains` edge defined on the graph and as the default relationship was defined from a sentence to a phrase, here we use the keyword `reversed` after the relationship variable to indicate the reverse direction of the same relationship.\n",
        "\n",
        "Whenever, you want to define the connection, you have to return a matric connecting the nodes from the source to the target concept in a form of 0 and 1s. Apart from that we also want to generate the feature `Text` containing the actual string feature for a sentence in the same sensor, because of that, we use a **JointSensor** which is able to connect one sensor to multiple proprties on the graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDYMdVpGRIyK"
      },
      "source": [
        "def merge_phrase(phrase_text):\n",
        "    return [' '.join(phrase_text)], torch.ones((1, len(phrase_text)))\n",
        "sentence['text', rel_sentence_contains_phrase.reversed] = JointSensor(phrase['text'], forward=merge_phrase)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfyvE-QtRIyL"
      },
      "source": [
        "Next, we define a set of learners on top of the phrases to decide about each phrase class. In this scenario, we are assigning independent boolean classifers for each phrase type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQLEIGLwRIyL"
      },
      "source": [
        "phrase[people] = ModuleLearner('w2v', module=Classifier(FEATURE_DIM))\n",
        "phrase[organization] = ModuleLearner('w2v', module=Classifier(FEATURE_DIM))\n",
        "phrase[location] = ModuleLearner('w2v', module=Classifier(FEATURE_DIM))\n",
        "phrase[other] = ModuleLearner('w2v', module=Classifier(FEATURE_DIM))\n",
        "phrase[o] = ModuleLearner('w2v', module=Classifier(FEATURE_DIM))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73ylWKL2RIyL"
      },
      "source": [
        "Next, we define the pair concept and use the **ComposionCandidateSensor** to generate pair candidates based on our phrases. This sensor receives one instance of each argument at a time and return **True** to make a candidate pair for that combination or **False** to skip the combination."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rzYtZj4RIyL"
      },
      "source": [
        "pair[rel_pair_phrase1.reversed, rel_pair_phrase2.reversed] = CompositionCandidateSensor(\n",
        "    phrase['w2v'],\n",
        "    relations=(rel_pair_phrase1.reversed, rel_pair_phrase2.reversed),\n",
        "    forward=lambda *_, **__: True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBJs4Pb8RIyL"
      },
      "source": [
        "Next, we define a property `emb` for the pair candidates based on the representation of their arguments. We use the relation links defined on the previous sensor to retrieve the `w2v` properties on each argument and concat them in the `forward` function of the **FunctionalSensor**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3M5fbEkRIyL"
      },
      "source": [
        "pair['emb'] = FunctionalSensor(\n",
        "    rel_pair_phrase1.reversed('w2v'), rel_pair_phrase2.reversed('w2v'),\n",
        "    forward=lambda arg1, arg2: torch.cat((arg1, arg2), dim=-1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaMfnTmJRIyL"
      },
      "source": [
        "Then, we define our classifiers on top of the pair `emb` properties to decide about the type of each pair"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEZskmeJRIyM"
      },
      "source": [
        "pair[work_for] = ModuleLearner('emb', module=Classifier(FEATURE_DIM*2))\n",
        "pair[located_in] = ModuleLearner('emb', module=Classifier(FEATURE_DIM*2))\n",
        "pair[live_in] = ModuleLearner('emb', module=Classifier(FEATURE_DIM*2))\n",
        "pair[orgbase_on] = ModuleLearner('emb', module=Classifier(FEATURE_DIM*2))\n",
        "pair[kill] = ModuleLearner('emb', module=Classifier(FEATURE_DIM*2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCsPGJnERIyM"
      },
      "source": [
        "Then, we read the annotation of each pair from the DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_-JzlTbRIyM"
      },
      "source": [
        "def find_relation(relation_type):\n",
        "    def find(arg1m, arg2m, data):\n",
        "        label = torch.zeros(arg1m.shape[0], dtype=torch.bool)\n",
        "        for rel, (arg1,*_), (arg2,*_) in data:\n",
        "            if rel == relation_type:\n",
        "                i, = (arg1m[:, arg1] * arg2m[:, arg2]).nonzero(as_tuple=True)\n",
        "                label[i] = True\n",
        "        return label # torch.stack((~label, label), dim=1)\n",
        "    return find\n",
        "pair[work_for] = FunctionalReaderSensor(pair[rel_pair_phrase1.reversed], pair[rel_pair_phrase2.reversed], keyword='relation', forward=find_relation('Work_For'), label=True)\n",
        "pair[located_in] = FunctionalReaderSensor(pair[rel_pair_phrase1.reversed], pair[rel_pair_phrase2.reversed], keyword='relation', forward=find_relation('Located_In'), label=True)\n",
        "pair[live_in] = FunctionalReaderSensor(pair[rel_pair_phrase1.reversed], pair[rel_pair_phrase2.reversed], keyword='relation', forward=find_relation('Live_In'), label=True)\n",
        "pair[orgbase_on] = FunctionalReaderSensor(pair[rel_pair_phrase1.reversed], pair[rel_pair_phrase2.reversed], keyword='relation', forward=find_relation('OrgBased_In'), label=True)\n",
        "pair[kill] = FunctionalReaderSensor(pair[rel_pair_phrase1.reversed], pair[rel_pair_phrase2.reversed], keyword='relation', forward=find_relation('Kill'), label=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbdt6FkiRIyM"
      },
      "source": [
        "\n",
        "After connecting all the sensors and learners to the graph, we have to define a Program instance to be able to autoamtically train and test our models. Here, we use the **POIProgram**, which execute all the properties which have multiple assignment in the graph~(multiple sensors connect) and their dependencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cnFyU_8RIyM"
      },
      "source": [
        "from domiknows.program import POIProgram, IMLProgram, SolverPOIProgram\n",
        "from domiknows.program.lossprogram import PrimalDualProgram\n",
        "from domiknows.program.model.pytorch import SolverModel\n",
        "from domiknows.program.metric import MacroAverageTracker, PRF1Tracker, PRF1Tracker, DatanodeCMMetric\n",
        "from domiknows.program.loss import NBCrossEntropyLoss, NBCrossEntropyIMLoss\n",
        "\n",
        "#ILP inference\n",
        "program = SolverPOIProgram(graph,\n",
        "                           poi=(sentence, phrase),\n",
        "                           inferTypes=['ILP', 'local/argmax'],\n",
        "                           loss=MacroAverageTracker(NBCrossEntropyLoss()),\n",
        "                           metric={'ILP':PRF1Tracker(DatanodeCMMetric()), 'argmax':PRF1Tracker(DatanodeCMMetric('local/argmax'))}\n",
        "                           )\n",
        "\n",
        "#IML inference and training\n",
        "program1 = IMLProgram(graph, poi=(sentence, phrase), inferTypes=['ILP', 'softmax'], loss=MacroAverageTracker(NBCrossEntropyLoss()), metric={'ILP':PRF1Tracker(DatanodeCMMetric()),'softmax':PRF1Tracker(DatanodeCMMetric('softmax'))})\n",
        "\n",
        "#Primal-Dual inference and training\n",
        "program2 = PrimalDualProgram(graph, SolverModel, poi=(sentence, phrase), inferTypes=['ILP', 'softmax'], loss=MacroAverageTracker(NBCrossEntropyLoss()), metric={'ILP':PRF1Tracker(DatanodeCMMetric()),'softmax':PRF1Tracker(DatanodeCMMetric('softmax'))})\n",
        "\n",
        "# No ILP\n",
        "program3 = SolverPOIProgram(graph, poi=(sentence, phrase), inferTypes=['local/argmax'], loss=MacroAverageTracker(NBCrossEntropyLoss()), metric={'argmax':PRF1Tracker(DatanodeCMMetric('local/argmax'))})\n",
        "\n",
        "# program = POIProgram(graph, poi=(sentence, phrase), loss=MacroAverageTracker(NBCrossEntropyLoss()), metric=PRF1Tracker())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHtACvVhRIyM"
      },
      "source": [
        "To start training we can call the train method on the **POIProgram** instance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPVx4Z8URIyM"
      },
      "source": [
        "program.train(list(iter(train_reader))[0:50], valid_set=list(iter(test_reader))[25:30], test_set=list(iter(test_reader))[0:5], train_epoch_num=1, Optim=lambda param: torch.optim.SGD(param, lr=.0001), device='cuda:0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eRPY7x7RIyN"
      },
      "source": [
        "program.test(list(iter(test_reader))[0:10], device=\"cuda:0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy8cicGARIyN"
      },
      "source": [
        "for datanode in program.populate(test_reader):\n",
        "    print(datanode.getAttribute(\"text\"))\n",
        "    print(datanode.getChildDataNodes(conceptName=phrase))\n",
        "    datanode.getChildDataNodes(conceptName=phrase)[0].visualize(filename=\"./datanode_image\", inference_mode=\"ILP\")\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzOEsQ5QRIyN"
      },
      "source": [
        "Image(filename='./datanode_image.png')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}