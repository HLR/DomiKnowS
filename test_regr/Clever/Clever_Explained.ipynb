{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Clevr VQA\n",
    "\n",
    "This notebook provides a step-by-step explanation of the Clevr Visual Question Answering (VQA) system implemented in `main.py`. The system uses the DomiKnowS framework to perform logic-guided VQA tasks.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The Clever VQA system is designed to answer questions about images by combining:\n",
    "1. Visual processing (using ResNet)\n",
    "2. Logical reasoning (using DomiKnowS inference program)\n",
    "\n",
    "The system can be run in two modes:\n",
    "- Regular mode: Uses a pre-trained ResNet model for feature extraction\n",
    "- Dummy mode: Uses a lightweight configuration for testing purposes\n",
    "\n",
    "Here, we use the dummy mode for demostration. Refer to the readme.md to use the regular mode.\n",
    "Let's break down the code and understand how it works.\n"
   ],
   "id": "eb207a94374e3600"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Imports and Setup\n",
    "\n",
    "First, we import the necessary libraries and set up the Python path to include the required directories. DomiKnowS needs logging to be set to info to report the progress on training.\n"
   ],
   "id": "365f8303fedc3287"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T19:44:38.684405Z",
     "start_time": "2025-07-02T19:44:27.202359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "sys.path.append('../../../')\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../')\n",
    "sys.path.append('./')\n",
    "from domiknows.sensor.pytorch import EdgeSensor, ModuleLearner\n",
    "from domiknows.sensor.pytorch.sensors import ReaderSensor, FunctionalSensor, FunctionalReaderSensor\n",
    "from domiknows.program.lossprogram import InferenceProgram\n",
    "from domiknows.program.model.pytorch import SolverModel\n",
    "from preprocess import preprocess_dataset, preprocess_folders_and_files\n",
    "from graph import create_graph\n",
    "from pathlib import Path\n",
    "from modules import ResNetPatcher, DummyLinearLearner\n",
    "import argparse, torch, logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ],
   "id": "dbcf98d9b7a23462",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file for dataNode is in: D:\\PycharmProjects\\DomiKnowS_interface\\test_regr\\Clever\\logs\\datanode.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Darius\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Darius\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Argument Parsing\n",
    "\n",
    "Next, we set up the command-line arguments that control the behavior of the program.\n"
   ],
   "id": "65b04b6d7def69b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T19:44:38.834049Z",
     "start_time": "2025-07-02T19:44:38.818187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "args = SimpleNamespace(\n",
    "    train_size=10,\n",
    "    test_size=10,\n",
    "    epochs=4,\n",
    "    lr=1e-6,\n",
    "    batch_size=1,\n",
    "    eval_only=False,\n",
    "    dummy=True,\n",
    "    tnorm=\"G\",\n",
    ")"
   ],
   "id": "3c4b4b886e5e9900",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Explanation of Arguments\n",
    "\n",
    "- `--train-size`: Number of training examples to use (default: use all available)\n",
    "- `--test-size`: Number of test examples to use (default: use all available)\n",
    "- `--epochs`: Number of training epochs (default: 4)\n",
    "- `--lr` or `--learning-rate`: Learning rate for optimization (default: 1e-6)\n",
    "- `--batch-size`: Mini-batch size for training (default: 1)\n",
    "- `--eval-only`: Flag to skip training and only evaluate a pre-trained model\n",
    "- `--dummy`: Flag to use a lightweight configuration for testing\n",
    "- `--tnorm`: T-norm to use in the InferenceProgram (choices: \"G\", \"P\", \"L\", default: \"G\")\n",
    "  - T-norms are fuzzy logic operators used for combining logical expressions\n",
    "  - \"G\" = Gödel t-norm, \"P\" = Product t-norm, \"L\" = Łukasiewicz t-norm\n"
   ],
   "id": "dedf464d6ab64c51"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "Now we prepare the dataset and create the necessary directories.\n"
   ],
   "id": "4bcb490869e9bc8f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T19:44:38.914280Z",
     "start_time": "2025-07-02T19:44:38.877985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CACHE_DIR = preprocess_folders_and_files(args.dummy)\n",
    "NUM_INSTANCES = 10\n",
    "device = \"cpu\"\n",
    "dataset = preprocess_dataset(args, NUM_INSTANCES, CACHE_DIR)"
   ],
   "id": "fb006f25e39fe963",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re-loaded dataset_cache\\instance_0.pkl\n",
      "re-loaded dataset_cache\\instance_1.pkl\n",
      "re-loaded dataset_cache\\instance_2.pkl\n",
      "re-loaded dataset_cache\\instance_3.pkl\n",
      "re-loaded dataset_cache\\instance_4.pkl\n",
      "re-loaded dataset_cache\\instance_5.pkl\n",
      "re-loaded dataset_cache\\instance_6.pkl\n",
      "re-loaded dataset_cache\\instance_7.pkl\n",
      "re-loaded dataset_cache\\instance_8.pkl\n",
      "re-loaded dataset_cache\\instance_9.pkl\n",
      "Dataset length: 10\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Graph Creation and Logic Preparation\n",
    "\n",
    "Next, we create the knowledge graph and prepare the logical executions for each instance in the dataset.\n"
   ],
   "id": "ff534f1ae4a36a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T19:44:38.967198Z",
     "start_time": "2025-07-02T19:44:38.946911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "questions_executions, graph, image, object, image_object_contains, attribute_names_dict,graph_text = create_graph(dataset,return_graph_text=True)\n",
    "\n",
    "print(f\"Created graph based on the object properties in the dataset: \\n{graph_text}\\n\\n\")\n"
   ],
   "id": "f1bba2bbf3ef4577",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created graph based on the object properties in the dataset: \n",
      "from domiknows.graph import Graph, Concept\n",
      "from domiknows.graph.logicalConstrain import ifL, andL, existsL\n",
      "\n",
      "with Graph('image_graph') as graph:\n",
      "\n",
      "\timage = Concept(name='image')\n",
      "\tobj = Concept(name='obj')\n",
      "\timage_object_contains, = image.contains(obj)\n",
      "\n",
      "\tis_gray = obj(name='is_gray')\n",
      "\tis_red = obj(name='is_red')\n",
      "\tis_blue = obj(name='is_blue')\n",
      "\tis_green = obj(name='is_green')\n",
      "\tis_brown = obj(name='is_brown')\n",
      "\tis_purple = obj(name='is_purple')\n",
      "\tis_cyan = obj(name='is_cyan')\n",
      "\tis_yellow = obj(name='is_yellow')\n",
      "\n",
      "\tis_rubber = obj(name='is_rubber')\n",
      "\tis_metal = obj(name='is_metal')\n",
      "\n",
      "\tis_cube = obj(name='is_cube')\n",
      "\tis_sphere = obj(name='is_sphere')\n",
      "\tis_cylinder = obj(name='is_cylinder')\n",
      "\n",
      "\tis_small = obj(name='is_small')\n",
      "\tis_large = obj(name='is_large')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The root concept is an image which contains multiple objects. Each object has properties such as color, material, shape, and size. Based on these graph we can create logical executable programs for each question. For example for the first two questions, their logical executions are created as bellow:",
   "id": "8a391008aa9c493d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T19:44:42.075672Z",
     "start_time": "2025-07-02T19:44:42.060525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(2):\n",
    "    print(\"Question: \",dataset[i][\"question_raw\"])\n",
    "    print(\"Logical Expression: \",questions_executions[i])\n",
    "    print(\"Answer: \",dataset[i][\"answer\"])\n",
    "    print(\"----------------------------------------\")"
   ],
   "id": "9c9f52a1cdb3aa2f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  Are any tiny purple rubber balls visible?\n",
      "Logical Expression:  existsL(\n",
      "\t\t\tandL(\n",
      "\t\t\t\tis_small(\"prop0\"),\n",
      "\t\t\t\tandL(\n",
      "\t\t\t\t\tis_purple(\"prop1\"),\n",
      "\t\t\t\t\tandL(\n",
      "\t\t\t\t\t\tis_rubber(\"prop2\"),\n",
      "\t\t\t\t\t\tis_sphere(\"prop3\")\n",
      "\t\t\t\t\t)\n",
      "\t\t\t\t)\n",
      "\t\t\t)\n",
      "\t\t)\n",
      "\t\n",
      "Answer:  False\n",
      "----------------------------------------\n",
      "Question:  Is there a big matte ball?\n",
      "Logical Expression:  existsL(\n",
      "\t\t\tandL(\n",
      "\t\t\t\tis_large(\"prop0\"),\n",
      "\t\t\t\tandL(\n",
      "\t\t\t\t\tis_rubber(\"prop1\"),\n",
      "\t\t\t\t\tis_sphere(\"prop2\")\n",
      "\t\t\t\t)\n",
      "\t\t\t)\n",
      "\t\t)\n",
      "\t\n",
      "Answer:  True\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Subsequently, we load the execution form of each question and its answer into the dataset.",
   "id": "c9cdeb89c908bc9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T19:44:46.087884Z",
     "start_time": "2025-07-02T19:44:46.056355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(len(dataset)):\n",
    "    dataset[i][\"logic_str\"] = questions_executions[i]\n",
    "    dataset[i][\"logic_label\"] = torch.LongTensor([bool(dataset[i]['answer'])]).to(device)"
   ],
   "id": "64409b3495870116",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Sensor Setup\n",
    "\n",
    "Now we set up various sensors for processing images and objects from the dataset. Sensors in DomiKnowS connect concepts that are defined in the graph and read their properties from the Dataset. They also define the learable Modules.\n"
   ],
   "id": "ca3073207bd59296"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T19:44:48.131220Z",
     "start_time": "2025-07-02T19:44:48.078245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# These sensors read the pillowed image and its id from the dataset\n",
    "image[\"pil_image\"] = FunctionalReaderSensor(keyword=\"pil_image\", forward=lambda data: [data])\n",
    "image[\"image_id\"] = FunctionalReaderSensor(keyword='image_index', forward=lambda data: [data])\n",
    "\n",
    "# These sensors read the bounding boxes and the properties of the onjects from the dataseet\n",
    "\n",
    "object[\"bounding_boxes\"] = ReaderSensor(keyword=\"objects_raw\")\n",
    "object[\"properties\"] = ReaderSensor(keyword=\"all_objects\")\n",
    "\n",
    "# Edge sensor connects the objects to the image which has a contains relationship\n",
    "object[image_object_contains] = EdgeSensor(object[\"bounding_boxes\"], image[\"pil_image\"], relation=image_object_contains, forward=lambda b, _: torch.ones(len(b)).unsqueeze(-1))\n",
    "\n",
    "# For each property of an object we need to define a learner\n",
    "for attr_name, attr_variable in attribute_names_dict.items():\n",
    "    object[attr_variable] = DummyLinearLearner(image_object_contains, \"properties\", current_attribute=attr_name)\n"
   ],
   "id": "50d830a6adc79a9d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. Image sensors:\n",
    "   - `image[\"pil_image\"]`: A sensor that reads the PIL image from the dataset\n",
    "   - `image[\"image_id\"]`: A sensor that reads the image index from the dataset\n",
    "\n",
    "2. Object sensors:\n",
    "   - `object[\"bounding_boxes\"]`: A sensor that reads the bounding boxes of objects from the dataset\n",
    "   - `object[\"properties\"]`: A sensor that reads the properties of objects from the dataset\n",
    "\n",
    "\n",
    "3. Edge sensor: `object[image_object_contains]`: Creates a sensor for the relationship between images and objects\n",
    "\n",
    "5. Attribute sensors: For each attribute (color, material, shape, size), uses a dummy learner.\n",
    "\n",
    "These sensors are responsible for processing the input data and extracting features that will be used by the inference program.\n"
   ],
   "id": "530e03c1639fecc6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. Model Compilation and Program Creation\n",
    "\n",
    "Now we compile the logic and create the inference program.\n"
   ],
   "id": "2672b0dce0c43151"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T19:44:51.615807Z",
     "start_time": "2025-07-02T19:44:51.373215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = graph.compile_logic(dataset, logic_keyword='logic_str', logic_label_keyword='logic_label')\n",
    "program = InferenceProgram(graph, SolverModel, poi=[image, object, *attribute_names_dict.values(), graph.constraint], device=device, tnorm=args.tnorm)\n"
   ],
   "id": "ebd638126081a9c1",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. `graph.compile_logic(dataset, logic_keyword='logic_str', logic_label_keyword='logic_label')`:\n",
    "   - Compiles the logical expressions in the dataset\n",
    "   - Uses the \"logic_str\" field for the logical expressions and \"logic_label\" field for the labels\n",
    "   - Returns the dataset with compiled logic\n",
    "\n",
    "2. `InferenceProgram(graph, SolverModel, poi=[image, object, *attribute_names_dict.values(), graph.constraint], device=device, tnorm=args.tnorm)`:\n",
    "   - Creates an inference program with the knowledge graph\n",
    "   - Specifies the points of interest (poi) in the graph: image, object, attributes, and constraints\n",
    "   - Sets the device and t-norm for the program\n",
    "\n",
    "This step prepares the inference program that will be used for training and evaluation.\n"
   ],
   "id": "2ca7a0c46fb5a7ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 7. Training/Evaluation Loop\n",
    "\n",
    "Finally, we train the model and evaluate its performance. The training process optimizes the model parameters to minimize the loss based on logical executions, while the evaluation process measures the model's accuracy in answering questions correctly.\n",
    "\n",
    "The training is performed using:\n",
    "- Adam optimizer\n",
    "- Learning rate of 1e-6 \n",
    "- Batch size of 1\n",
    "- Training on CPU device\n",
    "- c_warmup_iters set to 0 (immediate execution learning)\n",
    "\n",
    "The preprocessed dataset includes the logical executions required for training. Since we only use executions for training (no other training methods), we start learning them immediately by setting c_warmup_iters=0.\n"
   ],
   "id": "5c88d2b383490f72"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T19:45:06.507182Z",
     "start_time": "2025-07-02T19:44:56.515856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "program.train(dataset, Optim=torch.optim.Adam, train_epoch_num=args.epochs, lr=args.lr, c_warmup_iters=0, batch_size=args.batch_size, device=device)\n",
    "\n",
    "acc = program.evaluate_condition(dataset, device=device)\n",
    "print(\"Accuracy on Test: {:.2f}\".format(acc * 100))"
   ],
   "id": "24b8fd63dacee80f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:domiknows.program.program:Epoch: 1\n",
      "INFO:domiknows.program.program:Training:\n",
      "Epoch 1 Training:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file for ilpOntSolver is in: D:\\PycharmProjects\\DomiKnowS_interface\\test_regr\\Clever\\logs\\ilpOntSolver.log\n",
      "Log file for ilpOntSolverTime is in: D:\\PycharmProjects\\DomiKnowS_interface\\test_regr\\Clever\\logs\\ilpOntSolver.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=0) = 0.023\n",
      "Epoch 1 Training:  10%|█         | 1/10 [00:00<00:05,  1.59it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=1) = 0.445\n",
      "Epoch 1 Training:  20%|██        | 2/10 [00:00<00:02,  2.82it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=2) = 0.078\n",
      "Epoch 1 Training:  30%|███       | 3/10 [00:00<00:01,  3.52it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=3) = 0.068\n",
      "Epoch 1 Training:  40%|████      | 4/10 [00:01<00:01,  3.99it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=4) = 0.176\n",
      "Epoch 1 Training:  50%|█████     | 5/10 [00:01<00:01,  4.27it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=5) = 0.200\n",
      "Epoch 1 Training:  60%|██████    | 6/10 [00:01<00:00,  4.29it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=6) = 0.176\n",
      "Epoch 1 Training:  70%|███████   | 7/10 [00:01<00:00,  4.21it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=7) = 0.021\n",
      "Epoch 1 Training:  80%|████████  | 8/10 [00:02<00:00,  4.84it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=8) = 0.150\n",
      "Epoch 1 Training:  90%|█████████ | 9/10 [00:02<00:00,  5.08it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=9) = 0.022\n",
      "Epoch 1 Training: 100%|██████████| 10/10 [00:02<00:00,  4.25it/s]\n",
      "INFO:domiknows.program.program:Epoch: 2\n",
      "INFO:domiknows.program.program:Training:\n",
      "Epoch 2 Training:   0%|          | 0/10 [00:00<?, ?it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=0) = 0.023\n",
      "Epoch 2 Training:  10%|█         | 1/10 [00:00<00:02,  4.39it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=1) = 0.445\n",
      "Epoch 2 Training:  20%|██        | 2/10 [00:00<00:01,  5.17it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=2) = 0.078\n",
      "Epoch 2 Training:  30%|███       | 3/10 [00:00<00:01,  5.15it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=3) = 0.068\n",
      "Epoch 2 Training:  40%|████      | 4/10 [00:00<00:01,  5.11it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=4) = 0.176\n",
      "Epoch 2 Training:  50%|█████     | 5/10 [00:00<00:00,  5.01it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=5) = 0.200\n",
      "Epoch 2 Training:  60%|██████    | 6/10 [00:01<00:00,  4.77it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=6) = 0.176\n",
      "Epoch 2 Training:  70%|███████   | 7/10 [00:01<00:00,  4.54it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=7) = 0.021\n",
      "Epoch 2 Training:  80%|████████  | 8/10 [00:01<00:00,  5.10it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=8) = 0.150\n",
      "Epoch 2 Training:  90%|█████████ | 9/10 [00:01<00:00,  5.19it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=9) = 0.022\n",
      "Epoch 2 Training: 100%|██████████| 10/10 [00:01<00:00,  5.12it/s]\n",
      "INFO:domiknows.program.program:Epoch: 3\n",
      "INFO:domiknows.program.program:Training:\n",
      "Epoch 3 Training:   0%|          | 0/10 [00:00<?, ?it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=0) = 0.023\n",
      "Epoch 3 Training:  10%|█         | 1/10 [00:00<00:02,  4.09it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=1) = 0.445\n",
      "Epoch 3 Training:  20%|██        | 2/10 [00:00<00:01,  4.24it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=2) = 0.078\n",
      "Epoch 3 Training:  30%|███       | 3/10 [00:00<00:01,  4.53it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=3) = 0.068\n",
      "Epoch 3 Training:  40%|████      | 4/10 [00:00<00:01,  4.76it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=4) = 0.176\n",
      "Epoch 3 Training:  50%|█████     | 5/10 [00:01<00:01,  4.81it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=5) = 0.200\n",
      "Epoch 3 Training:  60%|██████    | 6/10 [00:01<00:00,  4.75it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=6) = 0.176\n",
      "Epoch 3 Training:  70%|███████   | 7/10 [00:01<00:00,  4.44it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=7) = 0.021\n",
      "Epoch 3 Training:  80%|████████  | 8/10 [00:01<00:00,  4.93it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=8) = 0.150\n",
      "Epoch 3 Training:  90%|█████████ | 9/10 [00:01<00:00,  5.09it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=9) = 0.022\n",
      "Epoch 3 Training: 100%|██████████| 10/10 [00:02<00:00,  4.92it/s]\n",
      "INFO:domiknows.program.program:Epoch: 4\n",
      "INFO:domiknows.program.program:Training:\n",
      "Epoch 4 Training:   0%|          | 0/10 [00:00<?, ?it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=0) = 0.023\n",
      "Epoch 4 Training:  10%|█         | 1/10 [00:00<00:02,  4.12it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=1) = 0.445\n",
      "Epoch 4 Training:  20%|██        | 2/10 [00:00<00:01,  5.09it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=2) = 0.078\n",
      "Epoch 4 Training:  30%|███       | 3/10 [00:00<00:01,  4.92it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=3) = 0.068\n",
      "Epoch 4 Training:  40%|████      | 4/10 [00:00<00:01,  4.96it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=4) = 0.176\n",
      "Epoch 4 Training:  50%|█████     | 5/10 [00:01<00:01,  4.91it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=5) = 0.200\n",
      "Epoch 4 Training:  60%|██████    | 6/10 [00:01<00:00,  4.75it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=6) = 0.176\n",
      "Epoch 4 Training:  70%|███████   | 7/10 [00:01<00:00,  4.56it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=7) = 0.021\n",
      "Epoch 4 Training:  80%|████████  | 8/10 [00:01<00:00,  5.13it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=8) = 0.150\n",
      "Epoch 4 Training:  90%|█████████ | 9/10 [00:01<00:00,  5.22it/s]INFO:domiknows.program.program:closs is not zero\n",
      "INFO:domiknows.program.program:loss (i=9) = 0.022\n",
      "Epoch 4 Training: 100%|██████████| 10/10 [00:01<00:00,  5.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test: 100.00\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
