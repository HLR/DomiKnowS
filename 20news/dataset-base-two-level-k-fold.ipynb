{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "638a9703-0de2-48ca-ae1f-bfd7ab82f8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/rajabyfa/.cache/huggingface/datasets/rungalileo___csv/rungalileo--20_Newsgroups_Fixed-edf414ecc72dd622/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.025790691375732422,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f8c1911e5a245728174e5483fd4928d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"rungalileo/20_Newsgroups_Fixed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4434d38f-3d86-46ee-a932-30d36a541528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_dataset(dataset, key):\n",
    "    labels = {}\n",
    "    for item in dataset[key]:\n",
    "        if item['label'] not in labels:\n",
    "            labels[item['label']] = 0\n",
    "        labels[item['label']] += 1\n",
    "    print(labels)\n",
    "    before_len = len(dataset[key])\n",
    "    print(before_len)\n",
    "    dataset[key] = dataset[key].filter(lambda example: example['label'] and example['label'] != \"None\" and example['text'] and len(example[\"text\"]) >= 10)\n",
    "    after_len = len(dataset[key])\n",
    "    print(after_len)\n",
    "    print(\"the number of removed items : \", before_len - after_len)\n",
    "    labels = {}\n",
    "    for item in dataset[key]:\n",
    "        if item['label'] not in labels:\n",
    "            labels[item['label']] = 0\n",
    "        labels[item['label']] += 1\n",
    "    print(labels)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dda9036-9c16-4668-9996-d51a006cae2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/rajabyfa/.cache/huggingface/datasets/rungalileo___csv/rungalileo--20_Newsgroups_Fixed-edf414ecc72dd622/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-22327e0021383721.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rec.autos': 539, 'comp.sys.mac.hardware': 537, 'comp.graphics': 551, 'sci.space': 564, 'talk.politics.guns': 526, 'sci.med': 572, 'comp.sys.ibm.pc.hardware': 562, 'comp.os.ms-windows.misc': 555, 'rec.motorcycles': 551, 'talk.religion.misc': 339, 'None': 650, 'misc.forsale': 565, 'alt.atheism': 449, 'sci.electronics': 563, 'comp.windows.x': 576, 'rec.sport.hockey': 559, 'rec.sport.baseball': 547, 'soc.religion.christian': 582, 'talk.politics.mideast': 521, 'talk.politics.misc': 438, 'sci.crypt': 568}\n",
      "11314\n",
      "10664\n",
      "the number of removed items :  650\n",
      "{'rec.autos': 539, 'comp.sys.mac.hardware': 537, 'comp.graphics': 551, 'sci.space': 564, 'talk.politics.guns': 526, 'sci.med': 572, 'comp.sys.ibm.pc.hardware': 562, 'comp.os.ms-windows.misc': 555, 'rec.motorcycles': 551, 'talk.religion.misc': 339, 'misc.forsale': 565, 'alt.atheism': 449, 'sci.electronics': 563, 'comp.windows.x': 576, 'rec.sport.hockey': 559, 'rec.sport.baseball': 547, 'soc.religion.christian': 582, 'talk.politics.mideast': 521, 'talk.politics.misc': 438, 'sci.crypt': 568}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/rajabyfa/.cache/huggingface/datasets/rungalileo___csv/rungalileo--20_Newsgroups_Fixed-edf414ecc72dd622/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-ea989db5d94eb33f.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rec.autos': 354, 'comp.windows.x': 370, 'None': 513, 'talk.politics.mideast': 353, 'talk.religion.misc': 230, 'sci.med': 371, 'soc.religion.christian': 380, 'comp.graphics': 370, 'comp.os.ms-windows.misc': 369, 'rec.motorcycles': 361, 'alt.atheism': 290, 'comp.sys.mac.hardware': 361, 'misc.forsale': 368, 'talk.politics.guns': 337, 'sci.space': 368, 'comp.sys.ibm.pc.hardware': 374, 'sci.crypt': 360, 'rec.sport.baseball': 366, 'rec.sport.hockey': 378, 'talk.politics.misc': 292, 'sci.electronics': 367}\n",
      "7532\n",
      "7019\n",
      "the number of removed items :  513\n",
      "{'rec.autos': 354, 'comp.windows.x': 370, 'talk.politics.mideast': 353, 'talk.religion.misc': 230, 'sci.med': 371, 'soc.religion.christian': 380, 'comp.graphics': 370, 'comp.os.ms-windows.misc': 369, 'rec.motorcycles': 361, 'alt.atheism': 290, 'comp.sys.mac.hardware': 361, 'misc.forsale': 368, 'talk.politics.guns': 337, 'sci.space': 368, 'comp.sys.ibm.pc.hardware': 374, 'sci.crypt': 360, 'rec.sport.baseball': 366, 'rec.sport.hockey': 378, 'talk.politics.misc': 292, 'sci.electronics': 367}\n"
     ]
    }
   ],
   "source": [
    "dataset = trim_dataset(dataset, \"train\")\n",
    "dataset = trim_dataset(dataset, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "112ed2e1-7db9-4c43-8fce-004b092c5824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# First make the kfold object\n",
    "folds = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Now make our splits based off of the labels. \n",
    "# We can use `np.zeros()` here since it only works off of indices, we really care about the labels\n",
    "splits = folds.split(np.zeros(dataset[\"train\"].num_rows), dataset[\"train\"][\"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b7477e4-be4d-44ff-bd2c-795a4207c0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "# dataset2 = copy.deepcopy(dataset1)\n",
    "new_datasets = [copy.deepcopy(dataset) for i in range(5)]\n",
    "i = 0\n",
    "for train_ids, val_ids in splits:\n",
    "    new_datasets[i][\"validation\"] = new_datasets[i][\"train\"].select(val_ids)\n",
    "    new_datasets[i][\"train\"] = new_datasets[i][\"train\"].select(train_ids)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80c8ffdf-15b8-4cad-bc64-668faf224f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8531\n",
      "2133\n",
      "8531\n",
      "2133\n",
      "8531\n",
      "2133\n",
      "8531\n",
      "2133\n",
      "8532\n",
      "2132\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(len(new_datasets[i]['train']))\n",
    "    print(len(new_datasets[i]['validation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f336c28-c601-410d-8475-7cbe94056058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.022329092025756836,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)olve/main/vocab.json",
       "rate": null,
       "total": 898823,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bad5183eb9e4ea49986c400c60558ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019351482391357422,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)olve/main/merges.txt",
       "rate": null,
       "total": 456318,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3324f53dbc47f681b929f08a582973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018192291259765625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)lve/main/config.json",
       "rate": null,
       "total": 481,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300e5af013be40ee9002b15aed00c915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, BertTokenizer\n",
    "\n",
    "rtokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af6bdfbd-8f94-4e16-809e-bce704240ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp.graphics\n",
    "# comp.os.ms-windows.misc\n",
    "# comp.sys.ibm.pc.hardware\n",
    "# comp.sys.mac.hardware\n",
    "# comp.windows.x\n",
    "# rec.autos\n",
    "# rec.motorcycles\n",
    "# rec.sport.baseball\n",
    "# rec.sport.hockey\n",
    "# sci.crypt\n",
    "# <sci.electronics\n",
    "# sci.med\n",
    "# sci.space\n",
    "# misc.forsale\n",
    "# talk.politics.misc\n",
    "# talk.politics.guns\n",
    "# talk.politics.mideast\n",
    "# talk.religion.misc\n",
    "# alt.atheism\n",
    "# soc.religion.christian\n",
    "# None\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def collate_label_set(data):\n",
    "    level1 = [\n",
    "        \"comp.os\", \"comp.sys\", \"comp.windows\", \"comp.graphics\", \"rec.motorcycles\", \"rec.sport\", \"rec.autos\", \"talk.religion\",\n",
    "        \"sci.electronics\", \"sci.med\", \"sci.space\", \"misc.forsale\", \"talk.politics\", \"sci.crypt\", \"alt.atheism\", \"soc.religion\"\n",
    "    ]\n",
    "    level2_pass = {\n",
    "        \"comp.windows\", \"comp.os\", \"talk.religion\", \"soc.religion\"\n",
    "    }\n",
    "    level2 = [\n",
    "        \"misc\", \"guns\", \"ibm\", \"mac\", \"baseball\", \"hockey\", \"mideast\", \"None\"\n",
    "    ]\n",
    "    for item in data:\n",
    "        if item['text'] is None:\n",
    "            item['text'] = \" \"\n",
    "        try:\n",
    "            label = item['label']\n",
    "            if not label:\n",
    "                label = \"None\"\n",
    "                item['level1'] = level1.index(label)\n",
    "                item['level2'] = level2.index(\"None\")\n",
    "            else:\n",
    "                label = label.split(\".\")\n",
    "                label_two = \".\".join(label[:2])\n",
    "                if label_two not in level1:\n",
    "                    print(label[0])\n",
    "                else:\n",
    "                    item['level1'] = level1.index(label_two)\n",
    "                if len(label) > 2:\n",
    "                    if label_two in level2_pass:\n",
    "                        item['level2'] = level2.index(\"None\")\n",
    "                    else:\n",
    "                        if label[2] not in level2:\n",
    "                            print(label[2])\n",
    "                            item['level2'] = level2.index(\"None\")\n",
    "                        else:\n",
    "                            item['level2'] = level2.index(label[2])\n",
    "                else:\n",
    "                    item['level2'] = level2.index(\"None\")\n",
    "        except:\n",
    "            print(label, item['text'])\n",
    "            raise\n",
    "            \n",
    "    final_data = {\"id\": None, \"text\": None, \"level1\": None, \"level2\": None}\n",
    "    final_data['id'] = torch.tensor([item['id'] for item in data])\n",
    "    final_data['text'] = [item['text'] for item in data]\n",
    "    final_data['level1'] = torch.tensor([item['level1'] for item in data])\n",
    "    final_data['level2'] = torch.tensor([item['level2'] for item in data])\n",
    "    try:\n",
    "        x = rtokenizer.batch_encode_plus(final_data['text'], return_tensors=\"pt\", padding=\"longest\", max_length=512, truncation=True)\n",
    "        # x = tokenizer.batch_encode_plus(final_data['text'], return_tensors=\"pt\", padding=\"longest\", max_length=512, truncation=True)\n",
    "    except:\n",
    "        print(final_data['text'])\n",
    "        raise\n",
    "    for key in x:\n",
    "        final_data[key] = x[key]\n",
    "        \n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "53629d27-91da-47de-922f-ec32c5064ca8",
   "metadata": {},
   "source": [
    "level1 = { \n",
    "    \"comp\": 0, \"rec\": 0, \"sci\": 0, \"misc\": 0, \"talk\": 0, \"alt\": 0, \"soc\": 0, \"None\": 0\n",
    "}\n",
    "level2_keys = {\n",
    "        \"os\", \"sys\", \"windows\", \"graphics\", \"motorcycles\", \"sport\", \"autos\", \"religion\",\n",
    "        \"electronics\", \"med\", \"space\", \"forsale\", \"politics\", \"religion\", \"crypt\", \"None\"\n",
    "}\n",
    "level2 = {}\n",
    "for _k in level2_keys:\n",
    "    level2[_k] = 0\n",
    "    \n",
    "level3_keys = {\n",
    "    \"misc\", \"guns\", \"ibm\", \"mac\", \"baseball\", \"hockey\", \"mideast\", \"None\"\n",
    "}\n",
    "level3 = {}\n",
    "for _k in level3_keys:\n",
    "    level3[_k] = 0\n",
    "    \n",
    "for x in loader:\n",
    "    # print(x[0].keys())\n",
    "    for y in x:\n",
    "        try:\n",
    "            level1[y['level1']] += 1\n",
    "            level2[y['level2']] += 1\n",
    "            level3[y['level3']] += 1\n",
    "        except:\n",
    "            print(y['label'])\n",
    "            raise\n",
    "    \n",
    "print(level1)\n",
    "print(level2)\n",
    "print(level3)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "999b88fd-ea5e-4e5a-80c4-b061f51b7d91",
   "metadata": {},
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ebbd70ae-e7eb-4c7a-a289-63813ba1054b",
   "metadata": {},
   "source": [
    "next(iter(loader))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4f378861-8b15-412d-8dcb-55a3584ec15f",
   "metadata": {},
   "source": [
    "outputs.pooler_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d242d03f-3b86-49ba-bf57-bfd0677cb953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NewsRepModule(nn.Module):\n",
    "    def __init__(self, roberta):\n",
    "        super().__init__()\n",
    "        self.roberta = roberta\n",
    "        self.drop_layer = nn.Dropout(p=0.6)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = output.pooler_output\n",
    "        logits = self.drop_layer(logits)\n",
    "        return logits\n",
    "\n",
    "class Level2Calssification(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.classification = nn.Linear(768, 8)\n",
    "\n",
    "    def forward(self, logits):\n",
    "        _out = self.classification(logits)\n",
    "        return _out\n",
    "    \n",
    "class Level1Calssification(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.classification = nn.Linear(768, 50)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.classification2 = nn.Linear(50, 16)\n",
    "        \n",
    "\n",
    "    def forward(self, logits):\n",
    "        _out = self.classification(logits)\n",
    "        _out = self.relu(_out)\n",
    "        _out = self.classification2(_out)\n",
    "        return _out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f372dc43-2ccc-47cf-ba83-117774597e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5558aa69-42a0-4713-a1a9-0504be102207",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in loader:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1c4af2c-ed04-4203-9bf0-25856253dd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 237/237 [03:25<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of epoch 0 is 649.3665305376053 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:20<00:00,  2.88it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7483885571670206 0.6635132493849467 0.8332638649490944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 237/237 [03:22<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of epoch 1 is 339.4353061914444 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:20<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7998012379733095 0.7374006921857913 0.8622017837608276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 237/237 [03:22<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of epoch 2 is 226.0697201192379 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:20<00:00,  2.94it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8202970057793944 0.7691149425678199 0.8714790689909688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 237/237 [03:22<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of epoch 3 is 170.75048798322678 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:20<00:00,  2.95it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8122885073644767 0.7649965343344891 0.8595804803944642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 237/237 [03:22<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of epoch 4 is 133.7368974685669 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:20<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8269942439471852 0.7803422151912767 0.8736462727030938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 237/237 [03:22<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of epoch 5 is 106.93085798621178 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:20<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.821395047041676 0.7739308221288926 0.8688592719544592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 237/237 [03:22<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of epoch 6 is 89.13210582733154 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:20<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.812924457381158 0.764773795849358 0.8610751189129582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 237/237 [03:22<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of epoch 7 is 75.42759406939149 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:20<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8343678716133391 0.7901469148235889 0.8785888284030893\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, RobertaModel, BertModel\n",
    "import json\n",
    "import os\n",
    "\n",
    "import random\n",
    "seed = 23\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "level1 = [\n",
    "    \"comp.os\", \"comp.sys\", \"comp.windows\", \"comp.graphics\", \"rec.motorcycles\", \"rec.sport\", \"rec.autos\", \"talk.religion\",\n",
    "    \"sci.electronics\", \"sci.med\", \"sci.space\", \"misc.forsale\", \"talk.politics\", \"sci.crypt\", \"alt.atheism\", \"soc.religion\"\n",
    "]\n",
    "level2 = [\n",
    "    \"misc\", \"guns\", \"ibm\", \"mac\", \"baseball\", \"hockey\", \"mideast\", \"None\"\n",
    "]\n",
    "\n",
    "best_performances = []\n",
    "for split in range(1):\n",
    "    loader = DataLoader(new_datasets[split]['train'], batch_size=36, collate_fn=collate_label_set)\n",
    "    val_loader = DataLoader(new_datasets[split]['validation'], batch_size=36, collate_fn=collate_label_set)\n",
    "    device = \"cuda:2\"\n",
    "    # rep_model = NewsRepModule(BertModel.from_pretrained(\"bert-base-uncased\"))\n",
    "    rep_model = NewsRepModule(RobertaModel.from_pretrained(\"roberta-base\"))\n",
    "    rep_model = rep_model.to(device)\n",
    "\n",
    "    level1_classification = Level1Calssification().to(device)\n",
    "    level2_classification = Level2Calssification().to(device)\n",
    "    \n",
    "    params = list(rep_model.parameters()) + list(level1_classification.parameters())\n",
    "    params = list(params) + list(level2_classification.parameters())\n",
    "    optim = torch.optim.AdamW(params, lr=4e-5)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_performance = 0\n",
    "    best_performance_details = None\n",
    "    \n",
    "    for epoch in range(8):\n",
    "        rep_model.train()\n",
    "        level1_classification.train()\n",
    "        level2_classification.train()\n",
    "        total_loss = 0\n",
    "        for train_batch in tqdm(loader):\n",
    "            try:\n",
    "                rep = rep_model(train_batch['input_ids'].to(device),\n",
    "                                               train_batch['attention_mask'].to(device))\n",
    "                level1 = level1_classification(rep)\n",
    "                level2 = level2_classification(rep)\n",
    "\n",
    "            except:\n",
    "                print(train_batch['text'])\n",
    "                raise\n",
    "            try:\n",
    "                loss = 0 \n",
    "                loss += criterion(level1, train_batch['level1'].long().to(device))\n",
    "                loss += criterion(level2, train_batch['level2'].long().to(device))\n",
    "                total_loss += loss.item()\n",
    "                loss.backward()\n",
    "            except:\n",
    "                print(level1, train_batch['level1'])\n",
    "                print(level2, train_batch['level2'])\n",
    "                raise\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "        print(f\"The loss of epoch {epoch} is {total_loss} \\n\")\n",
    "\n",
    "        rep_model.eval()\n",
    "        level1_classification.eval()\n",
    "        level2_classification.eval()\n",
    "        all_preds = {'level1': [], 'level2': []}\n",
    "        all_gt = {'level1': [], 'level2': []}\n",
    "        \n",
    "        for train_batch in tqdm(val_loader):\n",
    "            rep = rep_model(train_batch['input_ids'].to(device),\n",
    "                                                   train_batch['attention_mask'].to(device))\n",
    "            level1 = level1_classification(rep)\n",
    "            level2 = level2_classification(rep)\n",
    "            level1 = level1.argmax(-1)\n",
    "            level2 = level2.argmax(-1)\n",
    "            all_gt['level1'].extend(train_batch['level1'].cpu().detach().tolist())\n",
    "            all_gt['level2'].extend(train_batch['level2'].cpu().detach().tolist())\n",
    "            all_preds['level1'].extend(level1.cpu().detach().tolist())\n",
    "            all_preds['level2'].extend(level2.cpu().detach().tolist())\n",
    "\n",
    "            \n",
    "        l1_pr, l1_rec, l1_f1, l1_sup = precision_recall_fscore_support(np.array(all_gt['level1']), np.array(all_preds['level1']))\n",
    "        l2_pr, l2_rec, l2_f1, l2_sup = precision_recall_fscore_support(np.array(all_gt['level2']), np.array(all_preds['level2']))\n",
    "        level1_aggregate = (torch.from_numpy(l1_sup) * torch.from_numpy(l1_f1)).sum().item() / torch.from_numpy(l1_sup).sum().item()\n",
    "        level2_aggregate = (torch.from_numpy(l2_sup) * torch.from_numpy(l2_f1)).sum().item() / torch.from_numpy(l2_sup).sum().item()\n",
    "        score = (level1_aggregate + level2_aggregate) / 2\n",
    "        print(score, level1_aggregate, level2_aggregate)\n",
    "        if score > best_performance:\n",
    "            best_performance = score\n",
    "            best_performance_details = [torch.from_numpy(l1_pr), torch.from_numpy(l1_rec), \n",
    "                                        torch.from_numpy(l1_f1), torch.from_numpy(l1_sup),\n",
    "                                        torch.from_numpy(l2_pr), torch.from_numpy(l2_rec),\n",
    "                                        torch.from_numpy(l2_f1), torch.from_numpy(l2_sup),\n",
    "                                       level1_aggregate, level2_aggregate]\n",
    "            torch.save(rep_model.state_dict(), f\"rep_model2_base_{seed}.pt\")\n",
    "            torch.save(level1_classification.state_dict(), f\"level1_classification2_base_{seed}.pt\")\n",
    "            torch.save(level2_classification.state_dict(), f\"level2_classification2_base_{seed}.pt\")\n",
    "    if len(best_performances):\n",
    "        for _ind in range(len(best_performances)):\n",
    "            best_performances[_ind] = best_performances[_ind] + best_performance_details[_ind]\n",
    "    else:\n",
    "        best_performances = best_performance_details\n",
    "\n",
    "for _ind in range(len(best_performances)):\n",
    "    best_performances[_ind] = best_performances[_ind] / 5\n",
    "\n",
    "torch.save(best_performances, f\"average_performance_{seed}.pt\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6e467092-bd6b-40ed-a555-ca3567993b66",
   "metadata": {},
   "source": [
    "torch.save(rep_model.state_dict(), \"rep_model2_base.pt\")\n",
    "torch.save(level1_classification.state_dict(), \"level1_classification2_base.pt\")\n",
    "torch.save(level2_classification.state_dict(), \"level2_classification2_base.pt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "574112e7-8a54-4eea-85b2-d62f9f19c6df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level1_classification_path = f\"level1_classification2_base_{seed}.pt\"\n",
    "level1_classification.load_state_dict(torch.load(level1_classification_path, map_location=device))\n",
    "\n",
    "level2_classification_path = f\"level2_classification2_base_{seed}.pt\"\n",
    "level2_classification.load_state_dict(torch.load(level2_classification_path, map_location=device))\n",
    "\n",
    "rep_model_path = f\"rep_model2_base_{seed}.pt\"\n",
    "rep_model.load_state_dict(torch.load(rep_model_path, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15018955-6150-4fe9-ae9c-891cd0e98165",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 220/220 [01:04<00:00,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7817352899273401\n",
      "0.8694970793560336\n",
      "0.7817352899273401\n",
      "0.7553839902478667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "test_loader = DataLoader(new_datasets[split]['test'], batch_size=32, collate_fn=collate_label_set)\n",
    "\n",
    "rep_model.eval()\n",
    "level1_classification.eval()\n",
    "level2_classification.eval()\n",
    "# for dataload in [loader, test_loader]:\n",
    "for dataload in [test_loader]:\n",
    "    level1_correct, level2_correct = 0, 0\n",
    "    level1_correct_actual, level2_correct_actual = 0, 0\n",
    "    level1_total, level2_total = 0, 0\n",
    "    level1_total_actual, level2_total_actual = 0, 0\n",
    "    for train_batch in tqdm(dataload):\n",
    "        rep = rep_model(train_batch['input_ids'].to(device),\n",
    "                                               train_batch['attention_mask'].to(device))\n",
    "        level1 = level1_classification(rep)\n",
    "        level2 = level2_classification(rep)\n",
    "        level1 = level1.argmax(-1)\n",
    "        level2 = level2.argmax(-1)\n",
    "\n",
    "        level1_correct += (level1 == train_batch['level1'].long().to(device)).sum().item()\n",
    "        level1_total += train_batch['level1'].shape[0]\n",
    "        level1_correct_actual += ((level1 == train_batch['level1'].long().to(device)) & (train_batch['level1'].long().to(device) != 16)).sum().item()\n",
    "        level1_total_actual += (train_batch['level1'].long().to(device) != 16).sum().item()\n",
    "\n",
    "        level2_correct += (level2 == train_batch['level2'].long().to(device)).sum().item()\n",
    "        level2_total += train_batch['level2'].shape[0]\n",
    "        level2_correct_actual += ((level2 == train_batch['level2'].long().to(device)) & (train_batch['level2'].long().to(device) != 7)).sum().item()\n",
    "        level2_total_actual += (train_batch['level2'].long().to(device) != 7).sum().item()\n",
    "\n",
    "    print(level1_correct/level1_total)\n",
    "    print(level2_correct/level2_total)\n",
    "    print(level1_correct_actual/level1_total_actual)\n",
    "    print(level2_correct_actual/level2_total_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "208090b1-15bc-4919-9b9b-3c9002a8b128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "performance = torch.load(\"average_performance.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "078f0ce5-2f9a-4d4c-9c56-129f470acf21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.6895, 0.7998, 0.8308, 0.7274, 0.7668, 0.9598, 0.7902, 0.1177, 0.7301,\n",
       "         0.8964, 0.7986, 0.8041, 0.8223, 0.8103, 0.5584, 0.6624],\n",
       "        dtype=torch.float64),\n",
       " tensor([0.6919, 0.8255, 0.8420, 0.6733, 0.7495, 0.9485, 0.8089, 0.0383, 0.6501,\n",
       "         0.8724, 0.8599, 0.7947, 0.9044, 0.8152, 0.5500, 0.8215],\n",
       "        dtype=torch.float64),\n",
       " tensor([0.6810, 0.8102, 0.8345, 0.6973, 0.7577, 0.9541, 0.7990, 0.0475, 0.6869,\n",
       "         0.8835, 0.8266, 0.7986, 0.8609, 0.8114, 0.5521, 0.7321],\n",
       "        dtype=torch.float64),\n",
       " tensor([111.0000, 219.8000, 115.2000, 110.2000, 110.2000, 221.2000, 107.8000,\n",
       "          67.8000, 112.6000, 114.4000, 112.8000, 113.0000, 297.0000, 113.6000,\n",
       "          89.8000, 116.4000]),\n",
       " tensor([0.7223, 0.7400, 0.6812, 0.8323, 0.9566, 0.9504, 0.8921, 0.9351],\n",
       "        dtype=torch.float64),\n",
       " tensor([0.7375, 0.7908, 0.6603, 0.7413, 0.9141, 0.9249, 0.8714, 0.9439],\n",
       "        dtype=torch.float64),\n",
       " tensor([0.7291, 0.7614, 0.6675, 0.7811, 0.9346, 0.9374, 0.8810, 0.9394],\n",
       "        dtype=torch.float64),\n",
       " tensor([  87.6000,  105.2000,  112.4000,  107.4000,  109.4000,  111.8000,\n",
       "          104.2000, 1394.8000]),\n",
       " 0.7759999487952466,\n",
       " 0.8964713107140089]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e2f4dc1-6cda-43a0-95d3-9cf371bfd255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8153, dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(performance[-3] * performance[-4])[:-1].sum() / performance[-3][:-1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44051c50-40e9-4a46-aa34-17f7b5a9ec6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7760, dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(performance[-7] * performance[-8]).sum() / performance[-7].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520e76d8-7176-437d-b56e-220a0af33341",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
