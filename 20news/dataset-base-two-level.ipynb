{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "638a9703-0de2-48ca-ae1f-bfd7ab82f8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/rungalileo--20_Newsgroups_Fixed to /home/rajabyfa/.cache/huggingface/datasets/rungalileo___csv/rungalileo--20_Newsgroups_Fixed-edf414ecc72dd622/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02124786376953125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading data files",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "423f1f465e5e4f788cbda7f97e779dd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015056133270263672,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Extracting data files",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78f776eb281e4331a66e3f492f7c16a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016515731811523438,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Generating train split",
       "rate": null,
       "total": 0,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016553401947021484,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Generating test split",
       "rate": null,
       "total": 0,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/rajabyfa/.cache/huggingface/datasets/rungalileo___csv/rungalileo--20_Newsgroups_Fixed-edf414ecc72dd622/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015752315521240234,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "335875956e53444d970d0ad8715b31e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"rungalileo/20_Newsgroups_Fixed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4434d38f-3d86-46ee-a932-30d36a541528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_dataset(dataset, key):\n",
    "    labels = {}\n",
    "    for item in dataset[key]:\n",
    "        if item['label'] not in labels:\n",
    "            labels[item['label']] = 0\n",
    "        labels[item['label']] += 1\n",
    "    print(labels)\n",
    "    before_len = len(dataset[key])\n",
    "    print(before_len)\n",
    "    dataset[key] = dataset[key].filter(lambda example: example['label'] and example['label'] != \"None\" and example['text'] and len(example[\"text\"]) >= 10)\n",
    "    after_len = len(dataset[key])\n",
    "    print(after_len)\n",
    "    print(\"the number of removed items : \", before_len - after_len)\n",
    "    labels = {}\n",
    "    for item in dataset[key]:\n",
    "        if item['label'] not in labels:\n",
    "            labels[item['label']] = 0\n",
    "        labels[item['label']] += 1\n",
    "    print(labels)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dda9036-9c16-4668-9996-d51a006cae2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rec.autos': 539, 'comp.sys.mac.hardware': 537, 'comp.graphics': 551, 'sci.space': 564, 'talk.politics.guns': 526, 'sci.med': 572, 'comp.sys.ibm.pc.hardware': 562, 'comp.os.ms-windows.misc': 555, 'rec.motorcycles': 551, 'talk.religion.misc': 339, 'None': 650, 'misc.forsale': 565, 'alt.atheism': 449, 'sci.electronics': 563, 'comp.windows.x': 576, 'rec.sport.hockey': 559, 'rec.sport.baseball': 547, 'soc.religion.christian': 582, 'talk.politics.mideast': 521, 'talk.politics.misc': 438, 'sci.crypt': 568}\n",
      "11314\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019908666610717773,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Filter",
       "rate": null,
       "total": 11314,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/11314 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10664\n",
      "the number of removed items :  650\n",
      "{'rec.autos': 539, 'comp.sys.mac.hardware': 537, 'comp.graphics': 551, 'sci.space': 564, 'talk.politics.guns': 526, 'sci.med': 572, 'comp.sys.ibm.pc.hardware': 562, 'comp.os.ms-windows.misc': 555, 'rec.motorcycles': 551, 'talk.religion.misc': 339, 'misc.forsale': 565, 'alt.atheism': 449, 'sci.electronics': 563, 'comp.windows.x': 576, 'rec.sport.hockey': 559, 'rec.sport.baseball': 547, 'soc.religion.christian': 582, 'talk.politics.mideast': 521, 'talk.politics.misc': 438, 'sci.crypt': 568}\n",
      "{'rec.autos': 354, 'comp.windows.x': 370, 'None': 513, 'talk.politics.mideast': 353, 'talk.religion.misc': 230, 'sci.med': 371, 'soc.religion.christian': 380, 'comp.graphics': 370, 'comp.os.ms-windows.misc': 369, 'rec.motorcycles': 361, 'alt.atheism': 290, 'comp.sys.mac.hardware': 361, 'misc.forsale': 368, 'talk.politics.guns': 337, 'sci.space': 368, 'comp.sys.ibm.pc.hardware': 374, 'sci.crypt': 360, 'rec.sport.baseball': 366, 'rec.sport.hockey': 378, 'talk.politics.misc': 292, 'sci.electronics': 367}\n",
      "7532\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017632246017456055,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Filter",
       "rate": null,
       "total": 7532,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/7532 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7019\n",
      "the number of removed items :  513\n",
      "{'rec.autos': 354, 'comp.windows.x': 370, 'talk.politics.mideast': 353, 'talk.religion.misc': 230, 'sci.med': 371, 'soc.religion.christian': 380, 'comp.graphics': 370, 'comp.os.ms-windows.misc': 369, 'rec.motorcycles': 361, 'alt.atheism': 290, 'comp.sys.mac.hardware': 361, 'misc.forsale': 368, 'talk.politics.guns': 337, 'sci.space': 368, 'comp.sys.ibm.pc.hardware': 374, 'sci.crypt': 360, 'rec.sport.baseball': 366, 'rec.sport.hockey': 378, 'talk.politics.misc': 292, 'sci.electronics': 367}\n"
     ]
    }
   ],
   "source": [
    "dataset = trim_dataset(dataset, \"train\")\n",
    "dataset = trim_dataset(dataset, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f336c28-c601-410d-8475-7cbe94056058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.023295879364013672,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)solve/main/vocab.txt",
       "rate": null,
       "total": 231508,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9111f6675e584231b649cc48d9fc3077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020143747329711914,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)okenizer_config.json",
       "rate": null,
       "total": 28,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c0eb3b84ee3464ca074f98d24b79a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018930673599243164,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)lve/main/config.json",
       "rate": null,
       "total": 570,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc79d75fb6449a5b52b920a0811859e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, BertTokenizer\n",
    "\n",
    "# tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af6bdfbd-8f94-4e16-809e-bce704240ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp.graphics\n",
    "# comp.os.ms-windows.misc\n",
    "# comp.sys.ibm.pc.hardware\n",
    "# comp.sys.mac.hardware\n",
    "# comp.windows.x\n",
    "# rec.autos\n",
    "# rec.motorcycles\n",
    "# rec.sport.baseball\n",
    "# rec.sport.hockey\n",
    "# sci.crypt\n",
    "# <sci.electronics\n",
    "# sci.med\n",
    "# sci.space\n",
    "# misc.forsale\n",
    "# talk.politics.misc\n",
    "# talk.politics.guns\n",
    "# talk.politics.mideast\n",
    "# talk.religion.misc\n",
    "# alt.atheism\n",
    "# soc.religion.christian\n",
    "# None\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def collate_label_set(data):\n",
    "    level1 = [\n",
    "        \"comp.os\", \"comp.sys\", \"comp.windows\", \"comp.graphics\", \"rec.motorcycles\", \"rec.sport\", \"rec.autos\", \"talk.religion\",\n",
    "        \"sci.electronics\", \"sci.med\", \"sci.space\", \"misc.forsale\", \"talk.politics\", \"sci.crypt\", \"alt.atheism\", \"soc.religion\"\n",
    "    ]\n",
    "    level2_pass = {\n",
    "        \"comp.windows\", \"comp.os\", \"talk.religion\", \"soc.religion\"\n",
    "    }\n",
    "    level2 = [\n",
    "        \"misc\", \"guns\", \"ibm\", \"mac\", \"baseball\", \"hockey\", \"mideast\", \"None\"\n",
    "    ]\n",
    "    for item in data:\n",
    "        if item['text'] is None:\n",
    "            item['text'] = \" \"\n",
    "        try:\n",
    "            label = item['label']\n",
    "            if not label:\n",
    "                label = \"None\"\n",
    "                item['level1'] = level1.index(label)\n",
    "                item['level2'] = level2.index(\"None\")\n",
    "            else:\n",
    "                label = label.split(\".\")\n",
    "                label_two = \".\".join(label[:2])\n",
    "                if label_two not in level1:\n",
    "                    print(label[0])\n",
    "                else:\n",
    "                    item['level1'] = level1.index(label_two)\n",
    "                if len(label) > 2:\n",
    "                    if label_two in level2_pass:\n",
    "                        item['level2'] = level2.index(\"None\")\n",
    "                    else:\n",
    "                        if label[2] not in level2:\n",
    "                            print(label[2])\n",
    "                            item['level2'] = level2.index(\"None\")\n",
    "                        else:\n",
    "                            item['level2'] = level2.index(label[2])\n",
    "                else:\n",
    "                    item['level2'] = level2.index(\"None\")\n",
    "        except:\n",
    "            print(label, item['text'])\n",
    "            raise\n",
    "            \n",
    "    final_data = {\"id\": None, \"text\": None, \"level1\": None, \"level2\": None}\n",
    "    final_data['id'] = torch.tensor([item['id'] for item in data])\n",
    "    final_data['text'] = [item['text'] for item in data]\n",
    "    final_data['level1'] = torch.tensor([item['level1'] for item in data])\n",
    "    final_data['level2'] = torch.tensor([item['level2'] for item in data])\n",
    "    try:\n",
    "        x = tokenizer.batch_encode_plus(final_data['text'], return_tensors=\"pt\", padding=\"longest\", max_length=512, truncation=True)\n",
    "    except:\n",
    "        print(final_data['text'])\n",
    "        raise\n",
    "    for key in x:\n",
    "        final_data[key] = x[key]\n",
    "        \n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe8a6838-5543-4faf-8bc9-16daf7897a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "loader = DataLoader(dataset['train'], batch_size=36, collate_fn=collate_label_set)\n",
    "test_loader = DataLoader(dataset['test'], batch_size=36, collate_fn=collate_label_set)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "53629d27-91da-47de-922f-ec32c5064ca8",
   "metadata": {},
   "source": [
    "level1 = { \n",
    "    \"comp\": 0, \"rec\": 0, \"sci\": 0, \"misc\": 0, \"talk\": 0, \"alt\": 0, \"soc\": 0, \"None\": 0\n",
    "}\n",
    "level2_keys = {\n",
    "        \"os\", \"sys\", \"windows\", \"graphics\", \"motorcycles\", \"sport\", \"autos\", \"religion\",\n",
    "        \"electronics\", \"med\", \"space\", \"forsale\", \"politics\", \"religion\", \"crypt\", \"None\"\n",
    "}\n",
    "level2 = {}\n",
    "for _k in level2_keys:\n",
    "    level2[_k] = 0\n",
    "    \n",
    "level3_keys = {\n",
    "    \"misc\", \"guns\", \"ibm\", \"mac\", \"baseball\", \"hockey\", \"mideast\", \"None\"\n",
    "}\n",
    "level3 = {}\n",
    "for _k in level3_keys:\n",
    "    level3[_k] = 0\n",
    "    \n",
    "for x in loader:\n",
    "    # print(x[0].keys())\n",
    "    for y in x:\n",
    "        try:\n",
    "            level1[y['level1']] += 1\n",
    "            level2[y['level2']] += 1\n",
    "            level3[y['level3']] += 1\n",
    "        except:\n",
    "            print(y['label'])\n",
    "            raise\n",
    "    \n",
    "print(level1)\n",
    "print(level2)\n",
    "print(level3)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "999b88fd-ea5e-4e5a-80c4-b061f51b7d91",
   "metadata": {},
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ebbd70ae-e7eb-4c7a-a289-63813ba1054b",
   "metadata": {},
   "source": [
    "next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dcf132a-e17b-4f98-8395-739d8fbe45e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01964712142944336,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading pytorch_model.bin",
       "rate": null,
       "total": 440473133,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "110218f20817483c91ab233b864437c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, RobertaModel, BertModel\n",
    "\n",
    "model_roberta = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "# item = next(iter(loader))\n",
    "# outputs = model_roberta(item['input_ids'], item['attention_mask'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4f378861-8b15-412d-8dcb-55a3584ec15f",
   "metadata": {},
   "source": [
    "outputs.pooler_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d242d03f-3b86-49ba-bf57-bfd0677cb953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NewsRepModule(nn.Module):\n",
    "    def __init__(self, roberta):\n",
    "        super().__init__()\n",
    "        self.roberta = roberta\n",
    "        self.drop_layer = nn.Dropout(p=0.6)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = output.pooler_output\n",
    "        logits = self.drop_layer(logits)\n",
    "        return logits\n",
    "\n",
    "class Level2Calssification(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.classification = nn.Linear(768, 8)\n",
    "\n",
    "    def forward(self, logits):\n",
    "        _out = self.classification(logits)\n",
    "        return _out\n",
    "    \n",
    "class Level1Calssification(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.classification = nn.Linear(768, 50)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.classification2 = nn.Linear(50, 16)\n",
    "        \n",
    "\n",
    "    def forward(self, logits):\n",
    "        _out = self.classification(logits)\n",
    "        _out = self.relu(_out)\n",
    "        _out = self.classification2(_out)\n",
    "        return _out\n",
    "\n",
    "\n",
    "device = \"cuda:2\"\n",
    "rep_model = NewsRepModule(model_roberta)\n",
    "rep_model = rep_model.to(device)\n",
    "\n",
    "level1_classification = Level1Calssification().to(device)\n",
    "level2_classification = Level2Calssification().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f372dc43-2ccc-47cf-ba83-117774597e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(rep_model.parameters()) + list(level1_classification.parameters())\n",
    "params = list(params) + list(level2_classification.parameters())\n",
    "optim = torch.optim.AdamW(params, lr=2e-5)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5558aa69-42a0-4713-a1a9-0504be102207",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in loader:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1c4af2c-ed04-4203-9bf0-25856253dd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [04:36<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of epoch 0 is 983.8378772735596 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [04:38<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of epoch 1 is 584.7913056612015 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [04:38<00:00,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of epoch 2 is 372.373140335083 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for epoch in range(4):\n",
    "    rep_model.train()\n",
    "    level1_classification.train()\n",
    "    level2_classification.train()\n",
    "    total_loss = 0\n",
    "    for train_batch in tqdm(loader):\n",
    "        try:\n",
    "            rep = rep_model(train_batch['input_ids'].to(device),\n",
    "                                           train_batch['attention_mask'].to(device))\n",
    "            level1 = level1_classification(rep)\n",
    "            level2 = level2_classification(rep)\n",
    "            \n",
    "        except:\n",
    "            print(train_batch['text'])\n",
    "            raise\n",
    "        try:\n",
    "            loss = 0 \n",
    "            loss += criterion(level1, train_batch['level1'].long().to(device))\n",
    "            loss += criterion(level2, train_batch['level2'].long().to(device))\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "        except:\n",
    "            print(level1, train_batch['level1'])\n",
    "            print(level2, train_batch['level2'])\n",
    "            raise\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "    print(f\"The loss of epoch {epoch} is {total_loss} \\n\")\n",
    "    \n",
    "#     rep_model.eval()\n",
    "#     level1_classification.eval()\n",
    "#     level2_classification.eval()\n",
    "#     level3_classification.eval()\n",
    "#     level1_correct, level2_correct, level3_correct = 0, 0, 0\n",
    "#     level1_correct_actual, level2_correct_actual, level3_correct_actual = 0, 0, 0\n",
    "#     level1_total, level2_total, level3_total = 0, 0, 0\n",
    "#     level1_total_actual, level2_total_actual, level3_total_actual = 0, 0, 0\n",
    "#     for train_batch in tqdm(test_loader):\n",
    "#         rep = rep_model(train_batch['input_ids'].to(device),\n",
    "#                                                train_batch['attention_mask'].to(device))\n",
    "#         level1 = level1_classification(rep)\n",
    "#         level2 = level2_classification(rep)\n",
    "#         level3 = level3_classification(rep)\n",
    "#         level1 = level1.argmax(-1)\n",
    "#         level2 = level2.argmax(-1)\n",
    "#         level3 = level3.argmax(-1)\n",
    "\n",
    "#         level1_correct += (level1 == train_batch['level1'].long().to(device)).sum().item()\n",
    "#         level1_total += train_batch['level1'].shape[0]\n",
    "#         level1_correct_actual += ((level1 == train_batch['level1'].long().to(device)) & (train_batch['level1'].long().to(device) != 7)).sum().item()\n",
    "#         level1_total_actual += (train_batch['level1'].long().to(device) != 7).sum().item()\n",
    "\n",
    "#         level2_correct += (level2 == train_batch['level2'].long().to(device)).sum().item()\n",
    "#         level2_total += train_batch['level2'].shape[0]\n",
    "#         level2_correct_actual += ((level2 == train_batch['level2'].long().to(device)) & (train_batch['level2'].long().to(device) != 14)).sum().item()\n",
    "#         level2_total_actual += (train_batch['level2'].long().to(device) != 14).sum().item()\n",
    "\n",
    "\n",
    "#         level3_correct += (level3 == train_batch['level3'].long().to(device)).sum().item()\n",
    "#         level3_total += train_batch['level3'].shape[0]\n",
    "#         level3_correct_actual += ((level3 == train_batch['level3'].long().to(device)) & (train_batch['level3'].long().to(device) != 7)).sum().item()\n",
    "#         level3_total_actual += (train_batch['level3'].long().to(device) != 7).sum().item()\n",
    "        \n",
    "#     print(level1_correct/level1_total)\n",
    "#     print(level2_correct/level2_total)\n",
    "#     print(level3_correct/level3_total)\n",
    "#     print(level1_correct_actual/level1_total_actual)\n",
    "#     print(level2_correct_actual/level2_total_actual)\n",
    "#     print(level3_correct_actual/level3_total_actual)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04f1640c-ae49-47ee-8402-6c07810f2841",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(rep_model.state_dict(), \"rep_model2_base.pt\")\n",
    "torch.save(level1_classification.state_dict(), \"level1_classification2_base.pt\")\n",
    "torch.save(level2_classification.state_dict(), \"level2_classification2_base.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c601c32-5186-4e43-b4cc-1888a269bd38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level1_classification_path = \"level1_classification2_base.pt\"\n",
    "level1_classification.load_state_dict(torch.load(level1_classification_path, map_location=device))\n",
    "\n",
    "level2_classification_path = \"level2_classification2_base.pt\"\n",
    "level2_classification.load_state_dict(torch.load(level2_classification_path, map_location=device))\n",
    "\n",
    "rep_model_path = \"rep_model2_base.pt\"\n",
    "rep_model.load_state_dict(torch.load(rep_model_path, map_location=device))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15018955-6150-4fe9-ae9c-891cd0e98165",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [02:10<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8480870217554388\n",
      "0.9652100525131283\n",
      "0.8480870217554388\n",
      "0.9168021680216802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195/195 [01:23<00:00,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.754096025074797\n",
      "0.8704943724177233\n",
      "0.754096025074797\n",
      "0.7293783015034538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "rep_model.eval()\n",
    "level1_classification.eval()\n",
    "level2_classification.eval()\n",
    "for dataload in [loader, test_loader]:\n",
    "    level1_correct, level2_correct = 0, 0\n",
    "    level1_correct_actual, level2_correct_actual = 0, 0\n",
    "    level1_total, level2_total = 0, 0\n",
    "    level1_total_actual, level2_total_actual = 0, 0\n",
    "    for train_batch in tqdm(dataload):\n",
    "        rep = rep_model(train_batch['input_ids'].to(device),\n",
    "                                               train_batch['attention_mask'].to(device))\n",
    "        level1 = level1_classification(rep)\n",
    "        level2 = level2_classification(rep)\n",
    "        level1 = level1.argmax(-1)\n",
    "        level2 = level2.argmax(-1)\n",
    "\n",
    "        level1_correct += (level1 == train_batch['level1'].long().to(device)).sum().item()\n",
    "        level1_total += train_batch['level1'].shape[0]\n",
    "        level1_correct_actual += ((level1 == train_batch['level1'].long().to(device)) & (train_batch['level1'].long().to(device) != 16)).sum().item()\n",
    "        level1_total_actual += (train_batch['level1'].long().to(device) != 16).sum().item()\n",
    "\n",
    "        level2_correct += (level2 == train_batch['level2'].long().to(device)).sum().item()\n",
    "        level2_total += train_batch['level2'].shape[0]\n",
    "        level2_correct_actual += ((level2 == train_batch['level2'].long().to(device)) & (train_batch['level2'].long().to(device) != 7)).sum().item()\n",
    "        level2_total_actual += (train_batch['level2'].long().to(device) != 7).sum().item()\n",
    "\n",
    "    print(level1_correct/level1_total)\n",
    "    print(level2_correct/level2_total)\n",
    "    print(level1_correct_actual/level1_total_actual)\n",
    "    print(level2_correct_actual/level2_total_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7662bc35-2441-469a-88b3-69c0bace068d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6, device='cuda:6')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(level1 == train_batch['level1'].long().to(device)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f5ae6af-7de0-4ee8-8139-1f9e8371640c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12, 12, 11, 10,  1,  5, 11,  7], device='cuda:6')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "208090b1-15bc-4919-9b9b-3c9002a8b128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12, 12,  6, 10,  1,  5, 11, 15])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batch['level2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "078f0ce5-2f9a-4d4c-9c56-129f470acf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp.graphics\n",
    "# comp.os.ms-windows.misc\n",
    "# comp.sys.ibm.pc.hardware\n",
    "# comp.sys.mac.hardware\n",
    "# comp.windows.x\n",
    "# rec.autos\n",
    "# rec.motorcycles\n",
    "# rec.sport.baseball\n",
    "# rec.sport.hockey\n",
    "# sci.crypt\n",
    "# <sci.electronics\n",
    "# sci.med\n",
    "# sci.space\n",
    "# misc.forsale\n",
    "# talk.politics.misc\n",
    "# talk.politics.guns\n",
    "# talk.politics.mideast\n",
    "# talk.religion.misc\n",
    "# alt.atheism\n",
    "# soc.religion.christian\n",
    "# None\n",
    "level1 = [ \n",
    "    \"comp\", \"rec\", \"sci\", \"misc\", \"talk\", \"alt\", \"soc\", \"None\"\n",
    "]\n",
    "level2 = [\n",
    "    \"os\", \"sys\", \"windows\", \"graphics\", \"motorcycles\", \"sport\", \"autos\", \"religion\",\n",
    "    \"electronics\", \"med\", \"space\", \"forsale\", \"politics\", \"crypt\", \"None\"\n",
    "]\n",
    "level2_pass = {\n",
    "    \"soc\", \"alt\" \n",
    "}\n",
    "level3_pass = {\n",
    "    \"windows\", \"os\", \"religion\"\n",
    "}\n",
    "level3 = [\n",
    "    \"misc\", \"guns\", \"ibm\", \"mac\", \"baseball\", \"hockey\", \"mideast\", \"None\"\n",
    "]\n",
    "\n",
    "hierarchy = {\"comp\": {\"graphics\", \"os\", \"sys\", \"windows\"}, \"rec\": {\"auto\", \"motorcycles\", \"sport\"},\n",
    "            \"sci\": {\"crypt\", \"electronics\", \"med\", \"space\"}, \"misc\": {\"forsale\"}, \n",
    "             \"talk\": {\"politics\", \"religion\"}, \"alt\": {}, \"soc\": {}, \"None\": {},\n",
    "             \"windows\": {}, \"os\": {}, \"religion\": {}, \"politics\": {\"misc\", \"guns\", \"mideast\"},\n",
    "             \"sys\": {\"ibm\", \"mac\"}, \"sport\": {\"hockey\", \"baseball\"}\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2f4dc1-6cda-43a0-95d3-9cf371bfd255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
