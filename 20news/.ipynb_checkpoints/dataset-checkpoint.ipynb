{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "638a9703-0de2-48ca-ae1f-bfd7ab82f8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/rajabyfa/.cache/huggingface/datasets/rungalileo___csv/rungalileo--20_Newsgroups_Fixed-edf414ecc72dd622/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.024613142013549805,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5bfd1920bd848c0ac80ec1c9f6e5d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"rungalileo/20_Newsgroups_Fixed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6b346b8-8594-4e00-97a1-b31d6d7634e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_dataset(dataset, key):\n",
    "    labels = {}\n",
    "    for item in dataset[key]:\n",
    "        if item['label'] not in labels:\n",
    "            labels[item['label']] = 0\n",
    "        labels[item['label']] += 1\n",
    "    print(labels)\n",
    "    before_len = len(dataset[key])\n",
    "    print(before_len)\n",
    "    dataset[key] = dataset[key].filter(lambda example: example['text'] and len(example[\"text\"]) >= 10)\n",
    "    after_len = len(dataset[key])\n",
    "    print(after_len)\n",
    "    print(\"the number of removed items : \", before_len - after_len)\n",
    "    labels = {}\n",
    "    for item in dataset[key]:\n",
    "        if item['label'] not in labels:\n",
    "            labels[item['label']] = 0\n",
    "        labels[item['label']] += 1\n",
    "    print(labels)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e7f95aeb-55e7-4284-86ac-9b353c218371",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/rajabyfa/.cache/huggingface/datasets/rungalileo___csv/rungalileo--20_Newsgroups_Fixed-edf414ecc72dd622/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-8f3933326eb4f5c9.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rec.autos': 539, 'comp.sys.mac.hardware': 537, 'comp.graphics': 551, 'sci.space': 564, 'talk.politics.guns': 526, 'sci.med': 572, 'comp.sys.ibm.pc.hardware': 562, 'comp.os.ms-windows.misc': 555, 'rec.motorcycles': 551, 'talk.religion.misc': 339, None: 650, 'misc.forsale': 565, 'alt.atheism': 449, 'sci.electronics': 563, 'comp.windows.x': 576, 'rec.sport.hockey': 559, 'rec.sport.baseball': 547, 'soc.religion.christian': 582, 'talk.politics.mideast': 521, 'talk.politics.misc': 438, 'sci.crypt': 568}\n",
      "11314\n",
      "10998\n",
      "the number of removed items :  316\n",
      "{'rec.autos': 539, 'comp.sys.mac.hardware': 537, 'comp.graphics': 551, 'sci.space': 564, 'talk.politics.guns': 526, 'sci.med': 572, 'comp.sys.ibm.pc.hardware': 562, 'comp.os.ms-windows.misc': 555, 'rec.motorcycles': 551, 'talk.religion.misc': 339, 'misc.forsale': 565, 'alt.atheism': 449, 'sci.electronics': 563, 'comp.windows.x': 576, 'rec.sport.hockey': 559, 'rec.sport.baseball': 547, 'soc.religion.christian': 582, 'talk.politics.mideast': 521, 'talk.politics.misc': 438, 'sci.crypt': 568, None: 334}\n"
     ]
    }
   ],
   "source": [
    "dataset = trim_dataset(dataset, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f01211f2-eb4c-401f-99e8-5722a7e7dfa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rec.autos': 354, 'comp.windows.x': 370, None: 513, 'talk.politics.mideast': 353, 'talk.religion.misc': 230, 'sci.med': 371, 'soc.religion.christian': 380, 'comp.graphics': 370, 'comp.os.ms-windows.misc': 369, 'rec.motorcycles': 361, 'alt.atheism': 290, 'comp.sys.mac.hardware': 361, 'misc.forsale': 368, 'talk.politics.guns': 337, 'sci.space': 368, 'comp.sys.ibm.pc.hardware': 374, 'sci.crypt': 360, 'rec.sport.baseball': 366, 'rec.sport.hockey': 378, 'talk.politics.misc': 292, 'sci.electronics': 367}\n",
      "7532\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019716739654541016,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Filter",
       "rate": null,
       "total": 7532,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/7532 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7304\n",
      "the number of removed items :  228\n",
      "{'rec.autos': 354, 'comp.windows.x': 370, None: 285, 'talk.politics.mideast': 353, 'talk.religion.misc': 230, 'sci.med': 371, 'soc.religion.christian': 380, 'comp.graphics': 370, 'comp.os.ms-windows.misc': 369, 'rec.motorcycles': 361, 'alt.atheism': 290, 'comp.sys.mac.hardware': 361, 'misc.forsale': 368, 'talk.politics.guns': 337, 'sci.space': 368, 'comp.sys.ibm.pc.hardware': 374, 'sci.crypt': 360, 'rec.sport.baseball': 366, 'rec.sport.hockey': 378, 'talk.politics.misc': 292, 'sci.electronics': 367}\n"
     ]
    }
   ],
   "source": [
    "dataset = trim_dataset(dataset, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f336c28-c601-410d-8475-7cbe94056058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af6bdfbd-8f94-4e16-809e-bce704240ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp.graphics\n",
    "# comp.os.ms-windows.misc\n",
    "# comp.sys.ibm.pc.hardware\n",
    "# comp.sys.mac.hardware\n",
    "# comp.windows.x\n",
    "# rec.autos\n",
    "# rec.motorcycles\n",
    "# rec.sport.baseball\n",
    "# rec.sport.hockey\n",
    "# sci.crypt\n",
    "# <sci.electronics\n",
    "# sci.med\n",
    "# sci.space\n",
    "# misc.forsale\n",
    "# talk.politics.misc\n",
    "# talk.politics.guns\n",
    "# talk.politics.mideast\n",
    "# talk.religion.misc\n",
    "# alt.atheism\n",
    "# soc.religion.christian\n",
    "# None\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def collate_label_set(data):\n",
    "    level1 = [ \n",
    "        \"comp\", \"rec\", \"sci\", \"misc\", \"talk\", \"alt\", \"soc\", \"None\"\n",
    "    ]\n",
    "    level2 = [\n",
    "        \"os\", \"sys\", \"windows\", \"graphics\", \"motorcycles\", \"sport\", \"autos\", \"religion\",\n",
    "        \"electronics\", \"med\", \"space\", \"forsale\", \"politics\", \"crypt\", \"None\"\n",
    "    ]\n",
    "    level2_pass = {\n",
    "        \"soc\", \"alt\" \n",
    "    }\n",
    "    level3_pass = {\n",
    "        \"windows\", \"os\", \"religion\"\n",
    "    }\n",
    "    level3 = [\n",
    "        \"misc\", \"guns\", \"ibm\", \"mac\", \"baseball\", \"hockey\", \"mideast\", \"None\"\n",
    "    ]\n",
    "    for item in data:\n",
    "        if item['text'] is None:\n",
    "            item['text'] = \" \"\n",
    "        try:\n",
    "            label = item['label']\n",
    "            if not label:\n",
    "                label = \"None\"\n",
    "                item['level1'] = level1.index(label)\n",
    "                item['level2'] = level2.index(\"None\")\n",
    "                item['level3'] = level3.index(\"None\")\n",
    "            else:\n",
    "                label = label.split(\".\")\n",
    "                if label[0] not in level1:\n",
    "                    print(label[0])\n",
    "                item['level1'] = level1.index(label[0])\n",
    "                if len(label) > 1:\n",
    "                    if label[0] in level2_pass:\n",
    "                        item['level2'] = level2.index(\"None\")\n",
    "                        item['level3'] = level3.index(\"None\")\n",
    "                    else:\n",
    "                        if label[1] not in level2:\n",
    "                            print(label[1])\n",
    "                            item['level2'] = level2.index(\"None\")\n",
    "                            item['level3'] = level3.index(\"None\")\n",
    "                        else:\n",
    "                            item['level2'] = level2.index(label[1])\n",
    "                            if len(label) > 2:\n",
    "                                if label[1] in level3_pass:\n",
    "                                    item['level3'] = level3.index(\"None\")\n",
    "                                else:\n",
    "                                    if label[2] not in level3:\n",
    "                                        print(label[2])\n",
    "                                        item['level3'] = level3.index(\"None\")\n",
    "                                    else:\n",
    "                                        item['level3'] = level3.index(label[2])\n",
    "                            else:\n",
    "                                item['level3'] = level3.index(\"None\")\n",
    "                else:\n",
    "                    item['level2'] = level2.index(\"None\")\n",
    "                    item['level3'] = level3.index(\"None\")\n",
    "        except:\n",
    "            print(label, item['text'])\n",
    "            raise\n",
    "            \n",
    "    final_data = {\"id\": None, \"text\": None, \"level1\": None, \"level2\": None, \"level3\": None}\n",
    "    final_data['id'] = torch.tensor([item['id'] for item in data])\n",
    "    final_data['text'] = [item['text'] for item in data]\n",
    "    final_data['level1'] = torch.tensor([item['level1'] for item in data])\n",
    "    final_data['level2'] = torch.tensor([item['level2'] for item in data])\n",
    "    final_data['level3'] = torch.tensor([item['level3'] for item in data])\n",
    "    try:\n",
    "        x = tokenizer.batch_encode_plus(final_data['text'], return_tensors=\"pt\", padding=\"longest\", max_length=512, truncation=True)\n",
    "    except:\n",
    "        print(final_data['text'])\n",
    "        raise\n",
    "    for key in x:\n",
    "        final_data[key] = x[key]\n",
    "        \n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe8a6838-5543-4faf-8bc9-16daf7897a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "loader = DataLoader(dataset['train'], batch_size=24, pin_memory=True, collate_fn=collate_label_set)\n",
    "test_loader = DataLoader(dataset['test'], batch_size=12, collate_fn=collate_label_set)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "53629d27-91da-47de-922f-ec32c5064ca8",
   "metadata": {},
   "source": [
    "level1 = { \n",
    "    \"comp\": 0, \"rec\": 0, \"sci\": 0, \"misc\": 0, \"talk\": 0, \"alt\": 0, \"soc\": 0, \"None\": 0\n",
    "}\n",
    "level2_keys = {\n",
    "        \"os\", \"sys\", \"windows\", \"graphics\", \"motorcycles\", \"sport\", \"autos\", \"religion\",\n",
    "        \"electronics\", \"med\", \"space\", \"forsale\", \"politics\", \"religion\", \"crypt\", \"None\"\n",
    "}\n",
    "level2 = {}\n",
    "for _k in level2_keys:\n",
    "    level2[_k] = 0\n",
    "    \n",
    "level3_keys = {\n",
    "    \"misc\", \"guns\", \"ibm\", \"mac\", \"baseball\", \"hockey\", \"mideast\", \"None\"\n",
    "}\n",
    "level3 = {}\n",
    "for _k in level3_keys:\n",
    "    level3[_k] = 0\n",
    "    \n",
    "for x in loader:\n",
    "    # print(x[0].keys())\n",
    "    for y in x:\n",
    "        try:\n",
    "            level1[y['level1']] += 1\n",
    "            level2[y['level2']] += 1\n",
    "            level3[y['level3']] += 1\n",
    "        except:\n",
    "            print(y['label'])\n",
    "            raise\n",
    "    \n",
    "print(level1)\n",
    "print(level2)\n",
    "print(level3)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "999b88fd-ea5e-4e5a-80c4-b061f51b7d91",
   "metadata": {},
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ebbd70ae-e7eb-4c7a-a289-63813ba1054b",
   "metadata": {},
   "source": [
    "next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dcf132a-e17b-4f98-8395-739d8fbe45e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, RobertaModel\n",
    "\n",
    "model_roberta = RobertaModel.from_pretrained(\"roberta-large\")\n",
    "# item = next(iter(loader))\n",
    "# outputs = model_roberta(item['input_ids'], item['attention_mask'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4f378861-8b15-412d-8dcb-55a3584ec15f",
   "metadata": {},
   "source": [
    "outputs.pooler_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d242d03f-3b86-49ba-bf57-bfd0677cb953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NewsRepModule(nn.Module):\n",
    "    def __init__(self, roberta):\n",
    "        super().__init__()\n",
    "        self.roberta = roberta\n",
    "        self.drop_layer = nn.Dropout(p=0.3)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = output.pooler_output\n",
    "        logits = self.drop_layer(logits)\n",
    "        return logits\n",
    "\n",
    "class Level1Calssification(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.classification = nn.Linear(1024, 8)\n",
    "\n",
    "    def forward(self, logits):\n",
    "        _out = self.classification(logits)\n",
    "        return _out\n",
    "    \n",
    "class Level2Calssification(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.rep = nn.Linear(1024, 100)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.classification = nn.Linear(100, 15)\n",
    "        self.drop_layer = nn.Dropout(p=0.3)\n",
    "        \n",
    "\n",
    "    def forward(self, logits):\n",
    "        _out = self.rep(logits)\n",
    "        _out = self.relu(_out)\n",
    "        _out = self.drop_layer(_out)\n",
    "        _out = self.classification(_out)\n",
    "        return _out\n",
    "    \n",
    "class Level3Calssification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.classification = nn.Linear(1024, 8)\n",
    "\n",
    "    def forward(self, logits):\n",
    "        _out = self.classification(logits)\n",
    "        return _out\n",
    "\n",
    "\n",
    "device = \"cuda:6\"\n",
    "rep_model = NewsRepModule(model_roberta)\n",
    "rep_model = rep_model.to(device)\n",
    "\n",
    "level1_classification = Level1Calssification().to(device)\n",
    "level2_classification = Level2Calssification().to(device)\n",
    "level3_classification = Level3Calssification().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f372dc43-2ccc-47cf-ba83-117774597e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(rep_model.parameters()) + list(level1_classification.parameters())\n",
    "params = list(params) + list(level2_classification.parameters()) + list(level3_classification.parameters())\n",
    "optim = torch.optim.AdamW(params, lr=2e-5)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5558aa69-42a0-4713-a1a9-0504be102207",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in loader:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1c4af2c-ed04-4203-9bf0-25856253dd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [12:54<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of epoch 0 is 187.2539407853037 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 628/628 [03:03<00:00,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8499734466277217\n",
      "0.7919543281996814\n",
      "0.880509824747743\n",
      "0.8505485111839294\n",
      "0.7963458812411404\n",
      "0.7805770012190166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for epoch in range(1):\n",
    "    rep_model.train()\n",
    "    level1_classification.train()\n",
    "    level2_classification.train()\n",
    "    level3_classification.train()\n",
    "    total_loss = 0\n",
    "    for train_batch in tqdm(loader):\n",
    "        try:\n",
    "            rep = rep_model(train_batch['input_ids'].to(device),\n",
    "                                           train_batch['attention_mask'].to(device))\n",
    "            level1 = level1_classification(rep)\n",
    "            level2 = level2_classification(rep)\n",
    "            level3 = level3_classification(rep)\n",
    "            \n",
    "        except:\n",
    "            print(train_batch['text'])\n",
    "            raise\n",
    "        try:\n",
    "            loss = 0 \n",
    "            loss += criterion(level1, train_batch['level1'].long().to(device))\n",
    "            loss += criterion(level2, train_batch['level2'].long().to(device))\n",
    "            loss += criterion(level3, train_batch['level3'].long().to(device))\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "        except:\n",
    "            print(level1, train_batch['level1'])\n",
    "            print(level2, train_batch['level2'])\n",
    "            print(level3, train_batch['level3'])\n",
    "            raise\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "    print(f\"The loss of epoch {epoch} is {total_loss} \\n\")\n",
    "    \n",
    "    rep_model.eval()\n",
    "    level1_classification.eval()\n",
    "    level2_classification.eval()\n",
    "    level3_classification.eval()\n",
    "    level1_correct, level2_correct, level3_correct = 0, 0, 0\n",
    "    level1_correct_actual, level2_correct_actual, level3_correct_actual = 0, 0, 0\n",
    "    level1_total, level2_total, level3_total = 0, 0, 0\n",
    "    level1_total_actual, level2_total_actual, level3_total_actual = 0, 0, 0\n",
    "    for train_batch in tqdm(test_loader):\n",
    "        rep = rep_model(train_batch['input_ids'].to(device),\n",
    "                                               train_batch['attention_mask'].to(device))\n",
    "        level1 = level1_classification(rep)\n",
    "        level2 = level2_classification(rep)\n",
    "        level3 = level3_classification(rep)\n",
    "        level1 = level1.argmax(-1)\n",
    "        level2 = level2.argmax(-1)\n",
    "        level3 = level3.argmax(-1)\n",
    "\n",
    "        level1_correct += (level1 == train_batch['level1'].long().to(device)).sum().item()\n",
    "        level1_total += train_batch['level1'].shape[0]\n",
    "        level1_correct_actual += ((level1 == train_batch['level1'].long().to(device)) & (train_batch['level1'].long().to(device) != 7)).sum().item()\n",
    "        level1_total_actual += (train_batch['level1'].long().to(device) != 7).sum().item()\n",
    "\n",
    "        level2_correct += (level2 == train_batch['level2'].long().to(device)).sum().item()\n",
    "        level2_total += train_batch['level2'].shape[0]\n",
    "        level2_correct_actual += ((level2 == train_batch['level2'].long().to(device)) & (train_batch['level2'].long().to(device) != 14)).sum().item()\n",
    "        level2_total_actual += (train_batch['level2'].long().to(device) != 14).sum().item()\n",
    "\n",
    "\n",
    "        level3_correct += (level3 == train_batch['level3'].long().to(device)).sum().item()\n",
    "        level3_total += train_batch['level3'].shape[0]\n",
    "        level3_correct_actual += ((level3 == train_batch['level3'].long().to(device)) & (train_batch['level3'].long().to(device) != 7)).sum().item()\n",
    "        level3_total_actual += (train_batch['level3'].long().to(device) != 7).sum().item()\n",
    "        \n",
    "    print(level1_correct/level1_total)\n",
    "    print(level2_correct/level2_total)\n",
    "    print(level3_correct/level3_total)\n",
    "    print(level1_correct_actual/level1_total_actual)\n",
    "    print(level2_correct_actual/level2_total_actual)\n",
    "    print(level3_correct_actual/level3_total_actual)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04f1640c-ae49-47ee-8402-6c07810f2841",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(rep_model.state_dict(), \"rep_model.pt\")\n",
    "torch.save(level1_classification.state_dict(), \"level1_classification.pt\")\n",
    "torch.save(level2_classification.state_dict(), \"level2_classification.pt\")\n",
    "torch.save(level3_classification.state_dict(), \"level3_classification.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c601c32-5186-4e43-b4cc-1888a269bd38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level1_classification_path = \"level1_classification.pt\"\n",
    "level1_classification.load_state_dict(torch.load(level1_classification_path, map_location=device))\n",
    "\n",
    "level2_classification_path = \"level2_classification.pt\"\n",
    "level2_classification.load_state_dict(torch.load(level2_classification_path, map_location=device))\n",
    "\n",
    "level3_classification_path = \"level3_classification.pt\"\n",
    "level3_classification.load_state_dict(torch.load(level3_classification_path, map_location=device))\n",
    "\n",
    "rep_model_path = \"rep_model.pt\"\n",
    "rep_model.load_state_dict(torch.load(rep_model_path, map_location=device))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83366a07-cead-4cda-9314-309782b8bc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(dataset['test'], batch_size=12, collate_fn=collate_label_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15018955-6150-4fe9-ae9c-891cd0e98165",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 628/628 [03:01<00:00,  3.46it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "rep_model.eval()\n",
    "level1_classification.eval()\n",
    "level2_classification.eval()\n",
    "level3_classification.eval()\n",
    "level1_correct, level2_correct, level3_correct = 0, 0, 0\n",
    "level1_correct_actual, level2_correct_actual, level3_correct_actual = 0, 0, 0\n",
    "level1_total, level2_total, level3_total = 0, 0, 0\n",
    "level1_total_actual, level2_total_actual, level3_total_actual = 0, 0, 0\n",
    "for train_batch in tqdm(test_loader):\n",
    "    rep = rep_model(train_batch['input_ids'].to(device),\n",
    "                                           train_batch['attention_mask'].to(device))\n",
    "    level1 = level1_classification(rep)\n",
    "    level2 = level2_classification(rep)\n",
    "    level3 = level3_classification(rep)\n",
    "    level1 = level1.argmax(-1)\n",
    "    level2 = level2.argmax(-1)\n",
    "    level3 = level3.argmax(-1)\n",
    "    \n",
    "    level1_correct += (level1 == train_batch['level1'].long().to(device)).sum().item()\n",
    "    level1_total += train_batch['level1'].shape[0]\n",
    "    level1_correct_actual += ((level1 == train_batch['level1'].long().to(device)) & (train_batch['level1'].long().to(device) != 7)).sum().item()\n",
    "    level1_total_actual += (train_batch['level1'].long().to(device) != 7).sum().item()\n",
    "    \n",
    "    level2_correct += (level2 == train_batch['level2'].long().to(device)).sum().item()\n",
    "    level2_total += train_batch['level2'].shape[0]\n",
    "    level2_correct_actual += ((level2 == train_batch['level2'].long().to(device)) & (train_batch['level2'].long().to(device) != 14)).sum().item()\n",
    "    level2_total_actual += (train_batch['level2'].long().to(device) != 14).sum().item()\n",
    "    \n",
    "    \n",
    "    level3_correct += (level3 == train_batch['level3'].long().to(device)).sum().item()\n",
    "    level3_total += train_batch['level3'].shape[0]\n",
    "    level3_correct_actual += ((level3 == train_batch['level3'].long().to(device)) & (train_batch['level3'].long().to(device) != 7)).sum().item()\n",
    "    level3_total_actual += (train_batch['level3'].long().to(device) != 7).sum().item()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fcda898-5d08-4e31-b5ca-4ea1201e2bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.854753053637812\n",
      "0.7966011683483802\n",
      "0.8838289962825279\n",
      "0.8519732155577717\n",
      "0.7906756969601512\n",
      "0.7509142624949208\n"
     ]
    }
   ],
   "source": [
    "print(level1_correct/level1_total)\n",
    "print(level2_correct/level2_total)\n",
    "print(level3_correct/level3_total)\n",
    "print(level1_correct_actual/level1_total_actual)\n",
    "print(level2_correct_actual/level2_total_actual)\n",
    "print(level3_correct_actual/level3_total_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7662bc35-2441-469a-88b3-69c0bace068d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6, device='cuda:6')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(level1 == train_batch['level1'].long().to(device)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f5ae6af-7de0-4ee8-8139-1f9e8371640c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12, 12, 11, 10,  1,  5, 11,  7], device='cuda:6')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "208090b1-15bc-4919-9b9b-3c9002a8b128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12, 12,  6, 10,  1,  5, 11, 15])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batch['level2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "078f0ce5-2f9a-4d4c-9c56-129f470acf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp.graphics\n",
    "# comp.os.ms-windows.misc\n",
    "# comp.sys.ibm.pc.hardware\n",
    "# comp.sys.mac.hardware\n",
    "# comp.windows.x\n",
    "# rec.autos\n",
    "# rec.motorcycles\n",
    "# rec.sport.baseball\n",
    "# rec.sport.hockey\n",
    "# sci.crypt\n",
    "# <sci.electronics\n",
    "# sci.med\n",
    "# sci.space\n",
    "# misc.forsale\n",
    "# talk.politics.misc\n",
    "# talk.politics.guns\n",
    "# talk.politics.mideast\n",
    "# talk.religion.misc\n",
    "# alt.atheism\n",
    "# soc.religion.christian\n",
    "# None\n",
    "level1 = [ \n",
    "    \"comp\", \"rec\", \"sci\", \"misc\", \"talk\", \"alt\", \"soc\", \"None\"\n",
    "]\n",
    "level2 = [\n",
    "    \"os\", \"sys\", \"windows\", \"graphics\", \"motorcycles\", \"sport\", \"autos\", \"religion\",\n",
    "    \"electronics\", \"med\", \"space\", \"forsale\", \"politics\", \"crypt\", \"None\"\n",
    "]\n",
    "level2_pass = {\n",
    "    \"soc\", \"alt\" \n",
    "}\n",
    "level3_pass = {\n",
    "    \"windows\", \"os\", \"religion\"\n",
    "}\n",
    "level3 = [\n",
    "    \"misc\", \"guns\", \"ibm\", \"mac\", \"baseball\", \"hockey\", \"mideast\", \"None\"\n",
    "]\n",
    "\n",
    "hierarchy = {\"comp\": {\"graphics\", \"os\", \"sys\", \"windows\"}, \"rec\": {\"auto\", \"motorcycles\", \"sport\"},\n",
    "            \"sci\": {\"crypt\", \"electronics\", \"med\", \"space\"}, \"misc\": {\"forsale\"}, \n",
    "             \"talk\": {\"politics\", \"religion\"}, \"alt\": {}, \"soc\": {}, \"None\": {},\n",
    "             \"windows\": {}, \"os\": {}, \"religion\": {}, \"politics\": {\"misc\", \"guns\", \"mideast\"},\n",
    "             \"sys\": {\"ibm\", \"mac\"}, \"sport\": {\"hockey\", \"baseball\"}\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2f4dc1-6cda-43a0-95d3-9cf371bfd255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
