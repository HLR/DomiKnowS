{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "638a9703-0de2-48ca-ae1f-bfd7ab82f8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/rajabyfa/.cache/huggingface/datasets/rungalileo___csv/rungalileo--20_Newsgroups_Fixed-edf414ecc72dd622/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.025790691375732422,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f8c1911e5a245728174e5483fd4928d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"rungalileo/20_Newsgroups_Fixed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4434d38f-3d86-46ee-a932-30d36a541528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_dataset(dataset, key):\n",
    "    labels = {}\n",
    "    for item in dataset[key]:\n",
    "        if item['label'] not in labels:\n",
    "            labels[item['label']] = 0\n",
    "        labels[item['label']] += 1\n",
    "    print(labels)\n",
    "    before_len = len(dataset[key])\n",
    "    print(before_len)\n",
    "    dataset[key] = dataset[key].filter(lambda example: example['label'] and example['label'] != \"None\" and example['text'] and len(example[\"text\"]) >= 10)\n",
    "    after_len = len(dataset[key])\n",
    "    print(after_len)\n",
    "    print(\"the number of removed items : \", before_len - after_len)\n",
    "    labels = {}\n",
    "    for item in dataset[key]:\n",
    "        if item['label'] not in labels:\n",
    "            labels[item['label']] = 0\n",
    "        labels[item['label']] += 1\n",
    "    print(labels)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dda9036-9c16-4668-9996-d51a006cae2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/rajabyfa/.cache/huggingface/datasets/rungalileo___csv/rungalileo--20_Newsgroups_Fixed-edf414ecc72dd622/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-22327e0021383721.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rec.autos': 539, 'comp.sys.mac.hardware': 537, 'comp.graphics': 551, 'sci.space': 564, 'talk.politics.guns': 526, 'sci.med': 572, 'comp.sys.ibm.pc.hardware': 562, 'comp.os.ms-windows.misc': 555, 'rec.motorcycles': 551, 'talk.religion.misc': 339, 'None': 650, 'misc.forsale': 565, 'alt.atheism': 449, 'sci.electronics': 563, 'comp.windows.x': 576, 'rec.sport.hockey': 559, 'rec.sport.baseball': 547, 'soc.religion.christian': 582, 'talk.politics.mideast': 521, 'talk.politics.misc': 438, 'sci.crypt': 568}\n",
      "11314\n",
      "10664\n",
      "the number of removed items :  650\n",
      "{'rec.autos': 539, 'comp.sys.mac.hardware': 537, 'comp.graphics': 551, 'sci.space': 564, 'talk.politics.guns': 526, 'sci.med': 572, 'comp.sys.ibm.pc.hardware': 562, 'comp.os.ms-windows.misc': 555, 'rec.motorcycles': 551, 'talk.religion.misc': 339, 'misc.forsale': 565, 'alt.atheism': 449, 'sci.electronics': 563, 'comp.windows.x': 576, 'rec.sport.hockey': 559, 'rec.sport.baseball': 547, 'soc.religion.christian': 582, 'talk.politics.mideast': 521, 'talk.politics.misc': 438, 'sci.crypt': 568}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/rajabyfa/.cache/huggingface/datasets/rungalileo___csv/rungalileo--20_Newsgroups_Fixed-edf414ecc72dd622/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-ea989db5d94eb33f.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rec.autos': 354, 'comp.windows.x': 370, 'None': 513, 'talk.politics.mideast': 353, 'talk.religion.misc': 230, 'sci.med': 371, 'soc.religion.christian': 380, 'comp.graphics': 370, 'comp.os.ms-windows.misc': 369, 'rec.motorcycles': 361, 'alt.atheism': 290, 'comp.sys.mac.hardware': 361, 'misc.forsale': 368, 'talk.politics.guns': 337, 'sci.space': 368, 'comp.sys.ibm.pc.hardware': 374, 'sci.crypt': 360, 'rec.sport.baseball': 366, 'rec.sport.hockey': 378, 'talk.politics.misc': 292, 'sci.electronics': 367}\n",
      "7532\n",
      "7019\n",
      "the number of removed items :  513\n",
      "{'rec.autos': 354, 'comp.windows.x': 370, 'talk.politics.mideast': 353, 'talk.religion.misc': 230, 'sci.med': 371, 'soc.religion.christian': 380, 'comp.graphics': 370, 'comp.os.ms-windows.misc': 369, 'rec.motorcycles': 361, 'alt.atheism': 290, 'comp.sys.mac.hardware': 361, 'misc.forsale': 368, 'talk.politics.guns': 337, 'sci.space': 368, 'comp.sys.ibm.pc.hardware': 374, 'sci.crypt': 360, 'rec.sport.baseball': 366, 'rec.sport.hockey': 378, 'talk.politics.misc': 292, 'sci.electronics': 367}\n"
     ]
    }
   ],
   "source": [
    "dataset = trim_dataset(dataset, \"train\")\n",
    "dataset = trim_dataset(dataset, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "112ed2e1-7db9-4c43-8fce-004b092c5824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# First make the kfold object\n",
    "folds = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Now make our splits based off of the labels. \n",
    "# We can use `np.zeros()` here since it only works off of indices, we really care about the labels\n",
    "splits = folds.split(np.zeros(dataset[\"train\"].num_rows), dataset[\"train\"][\"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b7477e4-be4d-44ff-bd2c-795a4207c0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "# dataset2 = copy.deepcopy(dataset1)\n",
    "new_datasets = [copy.deepcopy(dataset) for i in range(5)]\n",
    "i = 0\n",
    "for train_ids, val_ids in splits:\n",
    "    new_datasets[i][\"validation\"] = new_datasets[i][\"train\"].select(val_ids)\n",
    "    new_datasets[i][\"train\"] = new_datasets[i][\"train\"].select(train_ids)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80c8ffdf-15b8-4cad-bc64-668faf224f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8531\n",
      "2133\n",
      "8531\n",
      "2133\n",
      "8531\n",
      "2133\n",
      "8531\n",
      "2133\n",
      "8532\n",
      "2132\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(len(new_datasets[i]['train']))\n",
    "    print(len(new_datasets[i]['validation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f336c28-c601-410d-8475-7cbe94056058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.022329092025756836,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)olve/main/vocab.json",
       "rate": null,
       "total": 898823,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bad5183eb9e4ea49986c400c60558ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019351482391357422,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)olve/main/merges.txt",
       "rate": null,
       "total": 456318,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3324f53dbc47f681b929f08a582973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018192291259765625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)lve/main/config.json",
       "rate": null,
       "total": 481,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300e5af013be40ee9002b15aed00c915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, BertTokenizer\n",
    "\n",
    "rtokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af6bdfbd-8f94-4e16-809e-bce704240ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp.graphics\n",
    "# comp.os.ms-windows.misc\n",
    "# comp.sys.ibm.pc.hardware\n",
    "# comp.sys.mac.hardware\n",
    "# comp.windows.x\n",
    "# rec.autos\n",
    "# rec.motorcycles\n",
    "# rec.sport.baseball\n",
    "# rec.sport.hockey\n",
    "# sci.crypt\n",
    "# <sci.electronics\n",
    "# sci.med\n",
    "# sci.space\n",
    "# misc.forsale\n",
    "# talk.politics.misc\n",
    "# talk.politics.guns\n",
    "# talk.politics.mideast\n",
    "# talk.religion.misc\n",
    "# alt.atheism\n",
    "# soc.religion.christian\n",
    "# None\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def collate_label_set(data):\n",
    "    level1 = [\n",
    "        \"comp.os\", \"comp.sys\", \"comp.windows\", \"comp.graphics\", \"rec.motorcycles\", \"rec.sport\", \"rec.autos\", \"talk.religion\",\n",
    "        \"sci.electronics\", \"sci.med\", \"sci.space\", \"misc.forsale\", \"talk.politics\", \"sci.crypt\", \"alt.atheism\", \"soc.religion\"\n",
    "    ]\n",
    "    level2_pass = {\n",
    "        \"comp.windows\", \"comp.os\", \"talk.religion\", \"soc.religion\"\n",
    "    }\n",
    "    level2 = [\n",
    "        \"misc\", \"guns\", \"ibm\", \"mac\", \"baseball\", \"hockey\", \"mideast\", \"None\"\n",
    "    ]\n",
    "    for item in data:\n",
    "        if item['text'] is None:\n",
    "            item['text'] = \" \"\n",
    "        try:\n",
    "            label = item['label']\n",
    "            if not label:\n",
    "                label = \"None\"\n",
    "                item['level1'] = level1.index(label)\n",
    "                item['level2'] = level2.index(\"None\")\n",
    "            else:\n",
    "                label = label.split(\".\")\n",
    "                label_two = \".\".join(label[:2])\n",
    "                if label_two not in level1:\n",
    "                    print(label[0])\n",
    "                else:\n",
    "                    item['level1'] = level1.index(label_two)\n",
    "                if len(label) > 2:\n",
    "                    if label_two in level2_pass:\n",
    "                        item['level2'] = level2.index(\"None\")\n",
    "                    else:\n",
    "                        if label[2] not in level2:\n",
    "                            print(label[2])\n",
    "                            item['level2'] = level2.index(\"None\")\n",
    "                        else:\n",
    "                            item['level2'] = level2.index(label[2])\n",
    "                else:\n",
    "                    item['level2'] = level2.index(\"None\")\n",
    "        except:\n",
    "            print(label, item['text'])\n",
    "            raise\n",
    "            \n",
    "    final_data = {\"id\": None, \"text\": None, \"level1\": None, \"level2\": None}\n",
    "    final_data['id'] = torch.tensor([item['id'] for item in data])\n",
    "    final_data['text'] = [item['text'] for item in data]\n",
    "    final_data['level1'] = torch.tensor([item['level1'] for item in data])\n",
    "    final_data['level2'] = torch.tensor([item['level2'] for item in data])\n",
    "    try:\n",
    "        x = rtokenizer.batch_encode_plus(final_data['text'], return_tensors=\"pt\", padding=\"longest\", max_length=512, truncation=True)\n",
    "        # x = tokenizer.batch_encode_plus(final_data['text'], return_tensors=\"pt\", padding=\"longest\", max_length=512, truncation=True)\n",
    "    except:\n",
    "        print(final_data['text'])\n",
    "        raise\n",
    "    for key in x:\n",
    "        final_data[key] = x[key]\n",
    "        \n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "53629d27-91da-47de-922f-ec32c5064ca8",
   "metadata": {},
   "source": [
    "level1 = { \n",
    "    \"comp\": 0, \"rec\": 0, \"sci\": 0, \"misc\": 0, \"talk\": 0, \"alt\": 0, \"soc\": 0, \"None\": 0\n",
    "}\n",
    "level2_keys = {\n",
    "        \"os\", \"sys\", \"windows\", \"graphics\", \"motorcycles\", \"sport\", \"autos\", \"religion\",\n",
    "        \"electronics\", \"med\", \"space\", \"forsale\", \"politics\", \"religion\", \"crypt\", \"None\"\n",
    "}\n",
    "level2 = {}\n",
    "for _k in level2_keys:\n",
    "    level2[_k] = 0\n",
    "    \n",
    "level3_keys = {\n",
    "    \"misc\", \"guns\", \"ibm\", \"mac\", \"baseball\", \"hockey\", \"mideast\", \"None\"\n",
    "}\n",
    "level3 = {}\n",
    "for _k in level3_keys:\n",
    "    level3[_k] = 0\n",
    "    \n",
    "for x in loader:\n",
    "    # print(x[0].keys())\n",
    "    for y in x:\n",
    "        try:\n",
    "            level1[y['level1']] += 1\n",
    "            level2[y['level2']] += 1\n",
    "            level3[y['level3']] += 1\n",
    "        except:\n",
    "            print(y['label'])\n",
    "            raise\n",
    "    \n",
    "print(level1)\n",
    "print(level2)\n",
    "print(level3)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "999b88fd-ea5e-4e5a-80c4-b061f51b7d91",
   "metadata": {},
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ebbd70ae-e7eb-4c7a-a289-63813ba1054b",
   "metadata": {},
   "source": [
    "next(iter(loader))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4f378861-8b15-412d-8dcb-55a3584ec15f",
   "metadata": {},
   "source": [
    "outputs.pooler_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d242d03f-3b86-49ba-bf57-bfd0677cb953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NewsRepModule(nn.Module):\n",
    "    def __init__(self, roberta):\n",
    "        super().__init__()\n",
    "        self.roberta = roberta\n",
    "        self.drop_layer = nn.Dropout(p=0.6)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = output.pooler_output\n",
    "        logits = self.drop_layer(logits)\n",
    "        return logits\n",
    "\n",
    "class Level2Calssification(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.classification = nn.Linear(768, 8)\n",
    "\n",
    "    def forward(self, logits):\n",
    "        _out = self.classification(logits)\n",
    "        return _out\n",
    "    \n",
    "class Level1Calssification(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.classification = nn.Linear(768, 50)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.classification2 = nn.Linear(50, 16)\n",
    "        \n",
    "\n",
    "    def forward(self, logits):\n",
    "        _out = self.classification(logits)\n",
    "        _out = self.relu(_out)\n",
    "        _out = self.classification2(_out)\n",
    "        return _out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f372dc43-2ccc-47cf-ba83-117774597e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5558aa69-42a0-4713-a1a9-0504be102207",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in loader:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1c4af2c-ed04-4203-9bf0-25856253dd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 237/237 [03:47<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of epoch 0 is 961.8842594623566 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:27<00:00,  2.22it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.291650160128909 0.06669457934626981 0.5166057409115482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 237/237 [03:47<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of epoch 1 is 896.5941321849823 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:26<00:00,  2.23it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31722218907458843 0.1178386372376287 0.5166057409115482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 51/237 [00:50<03:05,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0471,  2.0763,  0.9252,  0.4568,  0.1709,  0.6851,  0.4324, -1.0061,\n",
      "          0.5066, -0.1681, -0.5087,  0.8721, -0.7548, -0.4013, -1.4347, -1.0724],\n",
      "        [-0.0667,  0.3697, -0.0183,  0.3837,  0.3546,  1.1377,  0.2387, -0.8909,\n",
      "          0.2979,  0.2504,  0.0343, -0.2451, -0.0173,  0.0258, -0.5088, -0.5534],\n",
      "        [-0.4024, -0.4358, -0.4286, -0.1873,  0.1797,  1.0994, -0.1572, -0.4629,\n",
      "          0.0030,  0.2402,  0.0451, -0.7440,  0.7826,  0.3680, -0.0294, -0.1259],\n",
      "        [ 1.2691,  2.7833,  1.2126,  0.9618,  0.5316,  0.7189,  1.0209, -1.0551,\n",
      "          0.4109,  0.0802, -0.6276,  1.5067, -1.0767, -0.2754, -1.8959, -1.3322],\n",
      "        [-0.5247, -0.5816, -0.6660, -0.2801,  0.3507,  0.9749, -0.4136, -0.1213,\n",
      "         -0.1321,  0.4730,  0.1599, -0.8771,  1.0068,  0.4408,  0.1395, -0.0162],\n",
      "        [-0.2151, -0.1602, -0.4742, -0.0805,  0.4255,  1.0705,  0.0407, -0.7654,\n",
      "          0.0772,  0.1973,  0.2812, -0.4481,  0.3008,  0.3416,  0.0737, -0.4396],\n",
      "        [ 1.0604,  2.4106,  1.1265,  0.6588,  0.2987,  0.5222,  0.5563, -0.5970,\n",
      "          0.4397, -0.0829, -0.5201,  1.0721, -0.9532, -0.2987, -1.3340, -1.1058],\n",
      "        [-0.5830, -0.7062, -0.5947, -0.3888,  0.1507,  0.4373, -0.3434,  0.1494,\n",
      "         -0.5012,  0.2455,  0.3170, -0.8681,  1.4441,  0.5827,  0.3540,  0.5320],\n",
      "        [ 0.3981,  0.6931, -0.0084,  0.4614,  0.1702,  0.7455,  0.2595, -0.8026,\n",
      "          0.7349,  0.2490, -0.2658,  0.2143, -0.6880, -0.4011, -0.4873, -0.7075],\n",
      "        [ 0.8949,  1.1874,  0.5540,  0.9023,  0.1548,  0.8811,  0.3767, -1.2926,\n",
      "          0.3509,  0.1168, -0.3717,  0.4506, -0.7928, -0.2772, -1.1043, -0.7937],\n",
      "        [-0.4969, -0.0146, -0.3229, -0.2533,  0.4540,  0.8316, -0.0156, -0.8248,\n",
      "          0.0062,  0.5379,  0.1198, -0.5522,  0.4993,  0.1627, -0.2185, -0.3283],\n",
      "        [-0.3745, -0.3691, -0.5304, -0.0865,  0.5914,  0.9697, -0.0414, -0.4212,\n",
      "         -0.1369,  0.4614,  0.3040, -0.6134,  0.4901,  0.3668,  0.1270, -0.2936],\n",
      "        [ 0.9009,  2.5872,  1.0596,  0.7883,  0.3600,  0.4130,  0.6214, -0.4671,\n",
      "          0.3947, -0.0224, -0.5515,  1.0658, -1.0162, -0.1485, -1.2832, -0.9301],\n",
      "        [-0.4928, -0.7199, -0.7854, -0.4457,  0.3990,  1.0210, -0.3005,  0.0060,\n",
      "         -0.4805,  0.1983,  0.3943, -0.8025,  1.0271,  0.7262,  0.5399,  0.3286],\n",
      "        [-0.7255, -1.0269, -0.9470, -0.7123, -0.0171,  0.8280, -0.7662,  0.0263,\n",
      "         -0.8588,  0.5464,  0.1397, -0.9154,  1.6785,  0.8361,  0.7239,  0.7933],\n",
      "        [-0.6841, -0.6789, -0.9332, -0.7100, -0.1214,  0.2385, -0.3837,  0.5836,\n",
      "         -1.0133,  0.3505,  0.1566, -0.7583,  2.3174,  1.0156,  0.5029,  1.2475],\n",
      "        [-0.0569, -0.0136, -0.1175,  0.2517,  0.2613,  0.8857,  0.1299, -0.5705,\n",
      "          0.1785,  0.0915,  0.1227, -0.2482,  0.0353,  0.0923, -0.3296, -0.2614],\n",
      "        [ 1.0191,  2.2070,  1.0501,  1.1470,  0.3099,  0.2911,  0.7416, -0.9001,\n",
      "          0.1971,  0.3474, -0.1538,  1.0698, -1.3649, -0.0715, -1.2727, -1.0337],\n",
      "        [-0.3216, -0.3116, -0.3735,  0.0134,  0.3385,  1.0901,  0.0764, -0.3344,\n",
      "         -0.2946,  0.3351,  0.3494, -0.5791,  0.7579,  0.6237,  0.0959, -0.0221],\n",
      "        [ 0.1606,  0.6508, -0.1842,  0.1988,  0.5178,  1.2338,  0.2960, -0.9586,\n",
      "          0.4854,  0.0172,  0.0039,  0.0716, -0.2386, -0.0148, -0.5228, -0.7362],\n",
      "        [-0.2840, -0.2849, -0.4315,  0.1087,  0.4208,  1.0132,  0.1420, -0.6154,\n",
      "         -0.0197,  0.2579,  0.1287, -0.4198,  0.4072,  0.2385, -0.0455, -0.1331],\n",
      "        [ 0.7533,  1.4854,  0.6325,  0.7148,  0.1964,  0.8732,  0.4889, -1.1273,\n",
      "          0.3775, -0.0443, -0.1298,  0.4972, -0.5972, -0.2027, -1.0748, -0.8602],\n",
      "        [ 0.0216,  0.2402, -0.1949,  0.2479,  0.2781,  0.8772,  0.4037, -0.6461,\n",
      "          0.2006,  0.1766,  0.0071, -0.2339, -0.0452,  0.0299, -0.1882, -0.2311],\n",
      "        [ 1.1121,  2.1851,  0.8346,  0.5367,  0.1937,  0.6541,  0.4528, -0.5588,\n",
      "          0.7084, -0.2003, -0.8161,  1.2480, -0.9503, -0.4933, -1.2151, -0.9639],\n",
      "        [-0.4976, -1.1251, -0.8024, -0.2655,  0.1913,  0.6769, -0.0697,  0.4559,\n",
      "         -0.5998,  0.2862,  0.2303, -0.9290,  1.2411,  0.7917,  0.5133,  0.5941],\n",
      "        [-0.2223, -0.1002, -0.3882,  0.1626,  0.3783,  1.0817,  0.1065, -0.7233,\n",
      "          0.2595,  0.3813, -0.0159, -0.4462,  0.1912,  0.1596, -0.1729, -0.3862],\n",
      "        [-0.7978, -0.9904, -0.6940, -0.4479,  0.2468,  0.5924, -0.2898,  0.2025,\n",
      "         -0.6244,  0.3902,  0.4943, -0.9415,  1.6872,  0.9835,  0.5502,  0.4602],\n",
      "        [ 0.3310,  0.4372, -0.2353,  0.3453,  0.4428,  1.1138,  0.1120, -0.7871,\n",
      "          0.5287,  0.1377, -0.0935,  0.1021, -0.2851, -0.0467, -0.2863, -0.8123],\n",
      "        [-0.7466, -1.1701, -0.7916, -0.4419,  0.2137,  0.6677, -0.4356,  0.6643,\n",
      "         -0.5988,  0.3757,  0.3948, -1.2277,  1.7998,  0.8271,  0.4408,  0.8130],\n",
      "        [ 0.9907,  2.1795,  0.9069,  0.8480,  0.0559,  0.6482,  0.3414, -0.7986,\n",
      "          0.5460, -0.1472, -0.4665,  0.6115, -0.9755, -0.5210, -1.4337, -0.9690],\n",
      "        [-0.4181, -0.3992, -0.3858,  0.0104,  0.3796,  0.9902, -0.0968, -0.6140,\n",
      "          0.0092,  0.2486,  0.1198, -0.5290,  0.4932,  0.2587,  0.0128, -0.3092],\n",
      "        [ 1.1299,  2.6294,  1.1244,  0.6535,  0.1820,  0.4809,  0.4143, -0.9662,\n",
      "          0.4223, -0.0812, -0.6472,  0.9315, -0.9179, -0.3294, -1.4604, -1.0022],\n",
      "        [ 0.7837,  1.4323,  0.6421,  0.7668,  0.1963,  0.8050,  0.4721, -1.0943,\n",
      "          0.6448,  0.1843, -0.3878,  0.5675, -0.8330, -0.2214, -0.9221, -0.9124],\n",
      "        [-0.6437, -0.5322, -0.6460, -0.7369, -0.3524,  0.0744, -0.4049,  0.3825,\n",
      "         -0.8627,  0.6092, -0.1070, -0.9323,  2.3144,  0.6075,  0.3147,  1.2039],\n",
      "        [ 0.3821,  0.8884,  0.0908,  0.6793,  0.3888,  1.1509,  0.4534, -0.9835,\n",
      "          0.4884, -0.1019, -0.1614,  0.3785, -0.4968,  0.0720, -0.6406, -0.7686],\n",
      "        [ 1.0046,  2.2009,  1.0286,  0.3972,  0.4060,  0.7325,  0.2447, -0.8108,\n",
      "          0.7469, -0.4596, -0.4315,  1.0066, -1.1350, -0.3717, -1.3229, -0.9590]],\n",
      "       device='cuda:2', grad_fn=<AddmmBackward0>) tensor([ 8,  9,  5,  1,  9,  5, 11, 12,  6,  2,  8, 11,  8, 15,  5, 12,  1,  3,\n",
      "         5, 10, 11,  8,  5, 11,  5,  4, 15,  2, 12,  0,  6,  1,  8, 12,  5,  1])\n",
      "tensor([[-0.7153, -1.0424,  0.9309,  0.8945, -0.6687,  0.5271, -1.4390,  3.1347],\n",
      "        [-0.3755, -0.9941, -0.0584, -0.4814, -0.1647,  0.7060, -1.1994,  2.8059],\n",
      "        [-0.6839, -0.6497, -1.7639, -1.6239,  0.2707,  1.2702, -0.5712,  3.0190],\n",
      "        [-1.8851, -1.2818,  2.2466,  2.1558, -0.0540, -0.3513, -2.0062,  3.3073],\n",
      "        [ 0.2284,  0.1270, -2.2319, -1.5611,  0.1061,  0.2448, -0.5921,  2.6494],\n",
      "        [-1.5533,  0.2296, -1.1960, -1.0982,  0.5658,  1.2904, -0.9783,  2.5069],\n",
      "        [-0.9355, -1.4967,  2.6943,  1.6578, -0.2771, -0.5215, -1.2018,  2.7320],\n",
      "        [-0.3033, -0.0563, -1.6881, -1.7725,  0.1346,  0.1982, -0.6645,  2.4013],\n",
      "        [-1.6028, -0.8312,  0.1032, -0.0047,  0.0978,  0.2543, -1.7858,  2.4862],\n",
      "        [-2.0035, -1.9684,  1.0689,  0.0073,  0.2695,  0.7170, -1.6697,  2.9590],\n",
      "        [-0.6398, -0.4029, -1.2887, -1.6365,  0.3189,  1.1202, -1.4537,  2.8739],\n",
      "        [ 0.4323, -0.9978, -1.8906, -1.2768,  0.6087,  0.2655, -1.6939,  2.1642],\n",
      "        [-0.7139, -0.9550,  2.8670,  0.9593, -0.1375, -0.0503, -2.4136,  2.6866],\n",
      "        [-0.3058, -0.4635, -1.9249, -2.2224,  0.2028,  0.3602, -1.1649,  2.6720],\n",
      "        [ 0.5796,  0.6145, -2.5847, -2.2160, -0.0581, -0.2710, -0.1479,  2.2581],\n",
      "        [ 0.7095,  0.2080, -2.1844, -2.1962, -0.6283, -0.7014,  1.2432,  1.3762],\n",
      "        [-0.4080, -1.1550, -1.0612, -0.4624,  0.8985,  0.3834, -2.1782,  2.4952],\n",
      "        [-1.4499, -1.4977,  2.2377,  1.9281,  0.0783, -0.4506, -1.0129,  3.6566],\n",
      "        [ 0.0413, -0.2505, -1.5082, -1.6148,  0.2305,  0.7643, -1.0898,  2.4918],\n",
      "        [-0.4216, -0.8769, -0.1513, -0.6526,  1.1989,  0.9199, -1.3870,  2.8888],\n",
      "        [-0.2998, -0.7217, -1.4540, -1.7617,  0.1814,  0.5985, -0.9337,  2.5049],\n",
      "        [-1.3036, -2.0090,  1.1416,  0.2004,  0.5550,  0.9612, -1.6102,  3.1260],\n",
      "        [-1.4552, -1.0340, -1.0399, -0.9238,  0.9886,  0.9176, -1.2723,  2.9104],\n",
      "        [-1.1308, -0.9683,  2.6863,  1.8766, -0.4509, -0.3980, -1.6876,  3.4897],\n",
      "        [ 0.2317, -0.0505, -1.4839, -2.3606,  0.4892,  0.2021, -0.5664,  2.3578],\n",
      "        [-0.8702, -0.5298, -1.0473, -1.1169, -0.0283,  0.9097, -1.3379,  2.8892],\n",
      "        [ 0.2026, -0.1484, -1.5552, -2.1541, -0.1684,  0.3311, -0.8795,  2.3684],\n",
      "        [-0.8245, -0.7384,  0.0249, -0.5020,  0.4642,  0.8329, -1.1440,  3.3714],\n",
      "        [-0.1213,  0.7765, -2.5045, -2.0007, -0.2653,  0.0817,  0.2806,  2.8113],\n",
      "        [-1.2283, -1.1989,  2.0660,  1.6608, -0.7964, -0.2033, -0.9265,  2.9413],\n",
      "        [-0.7726, -0.1888, -1.1231, -0.6789,  0.5422,  1.2569, -1.4713,  2.6936],\n",
      "        [-1.2119, -1.1141,  2.4942,  1.9481, -1.1760,  0.0206, -1.2824,  1.7740],\n",
      "        [-0.7201, -2.0454,  0.3197,  0.3886,  0.6852,  0.5637, -2.4912,  3.3203],\n",
      "        [ 0.5953,  1.2922, -2.0571, -1.8762, -1.5271, -1.0151,  2.1627,  1.7310],\n",
      "        [-0.1870, -1.4853,  0.2173, -0.4446,  0.2414,  0.6000, -1.9187,  3.7552],\n",
      "        [-1.5825, -1.2154,  2.0887,  1.6369,  0.3484,  0.0859, -2.0160,  3.3884]],\n",
      "       device='cuda:2', grad_fn=<AddmmBackward0>) tensor([7, 7, 4, 2, 7, 5, 7, 0, 7, 7, 7, 7, 7, 7, 4, 0, 2, 7, 4, 7, 7, 7, 5, 7,\n",
      "        4, 7, 7, 7, 1, 7, 7, 3, 7, 0, 4, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m criterion(level2, train_batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel2\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m     65\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 66\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28mprint\u001b[39m(level1, train_batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel1\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, RobertaModel, BertModel\n",
    "import json\n",
    "import os\n",
    "\n",
    "import random\n",
    "seed = 23\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "level1 = [\n",
    "    \"comp.os\", \"comp.sys\", \"comp.windows\", \"comp.graphics\", \"rec.motorcycles\", \"rec.sport\", \"rec.autos\", \"talk.religion\",\n",
    "    \"sci.electronics\", \"sci.med\", \"sci.space\", \"misc.forsale\", \"talk.politics\", \"sci.crypt\", \"alt.atheism\", \"soc.religion\"\n",
    "]\n",
    "level2 = [\n",
    "    \"misc\", \"guns\", \"ibm\", \"mac\", \"baseball\", \"hockey\", \"mideast\", \"None\"\n",
    "]\n",
    "\n",
    "best_performances = []\n",
    "for split in range(1):\n",
    "    loader = DataLoader(new_datasets[split]['train'], batch_size=36, collate_fn=collate_label_set)\n",
    "    val_loader = DataLoader(new_datasets[split]['validation'], batch_size=36, collate_fn=collate_label_set)\n",
    "    device = \"cuda:2\"\n",
    "    # rep_model = NewsRepModule(BertModel.from_pretrained(\"bert-base-uncased\"))\n",
    "    rep_model = NewsRepModule(RobertaModel.from_pretrained(\"roberta-base\"))\n",
    "    rep_model = rep_model.to(device)\n",
    "\n",
    "    level1_classification = Level1Calssification().to(device)\n",
    "    level2_classification = Level2Calssification().to(device)\n",
    "    \n",
    "    params = list(rep_model.parameters()) + list(level1_classification.parameters())\n",
    "    params = list(params) + list(level2_classification.parameters())\n",
    "    optim = torch.optim.AdamW(params, lr=4e-5)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_performance = 0\n",
    "    best_performance_details = None\n",
    "    \n",
    "    for epoch in range(8):\n",
    "        rep_model.train()\n",
    "        level1_classification.train()\n",
    "        level2_classification.train()\n",
    "        total_loss = 0\n",
    "        for train_batch in tqdm(loader):\n",
    "            try:\n",
    "                rep = rep_model(train_batch['input_ids'].to(device),\n",
    "                                               train_batch['attention_mask'].to(device))\n",
    "                level1 = level1_classification(rep)\n",
    "                level2 = level2_classification(rep)\n",
    "\n",
    "            except:\n",
    "                print(train_batch['text'])\n",
    "                raise\n",
    "            try:\n",
    "                loss = 0 \n",
    "                loss += criterion(level1, train_batch['level1'].long().to(device))\n",
    "                loss += criterion(level2, train_batch['level2'].long().to(device))\n",
    "                total_loss += loss.item()\n",
    "                loss.backward()\n",
    "            except:\n",
    "                print(level1, train_batch['level1'])\n",
    "                print(level2, train_batch['level2'])\n",
    "                raise\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "        print(f\"The loss of epoch {epoch} is {total_loss} \\n\")\n",
    "\n",
    "        rep_model.eval()\n",
    "        level1_classification.eval()\n",
    "        level2_classification.eval()\n",
    "        all_preds = {'level1': [], 'level2': []}\n",
    "        all_gt = {'level1': [], 'level2': []}\n",
    "        \n",
    "        for train_batch in tqdm(val_loader):\n",
    "            rep = rep_model(train_batch['input_ids'].to(device),\n",
    "                                                   train_batch['attention_mask'].to(device))\n",
    "            level1 = level1_classification(rep)\n",
    "            level2 = level2_classification(rep)\n",
    "            level1 = level1.argmax(-1)\n",
    "            level2 = level2.argmax(-1)\n",
    "            all_gt['level1'].extend(train_batch['level1'].cpu().detach().tolist())\n",
    "            all_gt['level2'].extend(train_batch['level2'].cpu().detach().tolist())\n",
    "            all_preds['level1'].extend(level1.cpu().detach().tolist())\n",
    "            all_preds['level2'].extend(level2.cpu().detach().tolist())\n",
    "\n",
    "            \n",
    "        l1_pr, l1_rec, l1_f1, l1_sup = precision_recall_fscore_support(np.array(all_gt['level1']), np.array(all_preds['level1']))\n",
    "        l2_pr, l2_rec, l2_f1, l2_sup = precision_recall_fscore_support(np.array(all_gt['level2']), np.array(all_preds['level2']))\n",
    "        level1_aggregate = (torch.from_numpy(l1_sup) * torch.from_numpy(l1_f1)).sum().item() / torch.from_numpy(l1_sup).sum().item()\n",
    "        level2_aggregate = (torch.from_numpy(l2_sup) * torch.from_numpy(l2_f1)).sum().item() / torch.from_numpy(l2_sup).sum().item()\n",
    "        score = (level1_aggregate + level2_aggregate) / 2\n",
    "        print(score, level1_aggregate, level2_aggregate)\n",
    "        if score > best_performance:\n",
    "            best_performance = score\n",
    "            best_performance_details = [torch.from_numpy(l1_pr), torch.from_numpy(l1_rec), \n",
    "                                        torch.from_numpy(l1_f1), torch.from_numpy(l1_sup),\n",
    "                                        torch.from_numpy(l2_pr), torch.from_numpy(l2_rec),\n",
    "                                        torch.from_numpy(l2_f1), torch.from_numpy(l2_sup),\n",
    "                                       level1_aggregate, level2_aggregate]\n",
    "            torch.save(rep_model.state_dict(), f\"rep_model2_base_{seed}.pt\")\n",
    "            torch.save(level1_classification.state_dict(), f\"level1_classification2_base_{seed}.pt\")\n",
    "            torch.save(level2_classification.state_dict(), f\"level2_classification2_base_{seed}.pt\")\n",
    "    if len(best_performances):\n",
    "        for _ind in range(len(best_performances)):\n",
    "            best_performances[_ind] = best_performances[_ind] + best_performance_details[_ind]\n",
    "    else:\n",
    "        best_performances = best_performance_details\n",
    "\n",
    "for _ind in range(len(best_performances)):\n",
    "    best_performances[_ind] = best_performances[_ind] / 5\n",
    "\n",
    "torch.save(best_performances, f\"average_performance_{seed}.pt\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6e467092-bd6b-40ed-a555-ca3567993b66",
   "metadata": {},
   "source": [
    "torch.save(rep_model.state_dict(), \"rep_model2_base.pt\")\n",
    "torch.save(level1_classification.state_dict(), \"level1_classification2_base.pt\")\n",
    "torch.save(level2_classification.state_dict(), \"level2_classification2_base.pt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "574112e7-8a54-4eea-85b2-d62f9f19c6df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level1_classification_path = f\"level1_classification2_base_{seed}.pt\"\n",
    "level1_classification.load_state_dict(torch.load(level1_classification_path, map_location=device))\n",
    "\n",
    "level2_classification_path = f\"level2_classification2_base_{seed}.pt\"\n",
    "level2_classification.load_state_dict(torch.load(level2_classification_path, map_location=device))\n",
    "\n",
    "rep_model_path = f\"rep_model2_base_{seed}.pt\"\n",
    "rep_model.load_state_dict(torch.load(rep_model_path, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15018955-6150-4fe9-ae9c-891cd0e98165",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 220/220 [01:32<00:00,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7711924775609061\n",
      "0.8659353184214276\n",
      "0.7711924775609061\n",
      "0.7578220235676554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "test_loader = DataLoader(new_datasets[split]['test'], batch_size=32, collate_fn=collate_label_set)\n",
    "\n",
    "rep_model.eval()\n",
    "level1_classification.eval()\n",
    "level2_classification.eval()\n",
    "# for dataload in [loader, test_loader]:\n",
    "for dataload in [test_loader]:\n",
    "    level1_correct, level2_correct = 0, 0\n",
    "    level1_correct_actual, level2_correct_actual = 0, 0\n",
    "    level1_total, level2_total = 0, 0\n",
    "    level1_total_actual, level2_total_actual = 0, 0\n",
    "    for train_batch in tqdm(dataload):\n",
    "        rep = rep_model(train_batch['input_ids'].to(device),\n",
    "                                               train_batch['attention_mask'].to(device))\n",
    "        level1 = level1_classification(rep)\n",
    "        level2 = level2_classification(rep)\n",
    "        level1 = level1.argmax(-1)\n",
    "        level2 = level2.argmax(-1)\n",
    "\n",
    "        level1_correct += (level1 == train_batch['level1'].long().to(device)).sum().item()\n",
    "        level1_total += train_batch['level1'].shape[0]\n",
    "        level1_correct_actual += ((level1 == train_batch['level1'].long().to(device)) & (train_batch['level1'].long().to(device) != 16)).sum().item()\n",
    "        level1_total_actual += (train_batch['level1'].long().to(device) != 16).sum().item()\n",
    "\n",
    "        level2_correct += (level2 == train_batch['level2'].long().to(device)).sum().item()\n",
    "        level2_total += train_batch['level2'].shape[0]\n",
    "        level2_correct_actual += ((level2 == train_batch['level2'].long().to(device)) & (train_batch['level2'].long().to(device) != 7)).sum().item()\n",
    "        level2_total_actual += (train_batch['level2'].long().to(device) != 7).sum().item()\n",
    "\n",
    "    print(level1_correct/level1_total)\n",
    "    print(level2_correct/level2_total)\n",
    "    print(level1_correct_actual/level1_total_actual)\n",
    "    print(level2_correct_actual/level2_total_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "208090b1-15bc-4919-9b9b-3c9002a8b128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "performance = torch.load(\"average_performance.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "078f0ce5-2f9a-4d4c-9c56-129f470acf21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.6895, 0.7998, 0.8308, 0.7274, 0.7668, 0.9598, 0.7902, 0.1177, 0.7301,\n",
       "         0.8964, 0.7986, 0.8041, 0.8223, 0.8103, 0.5584, 0.6624],\n",
       "        dtype=torch.float64),\n",
       " tensor([0.6919, 0.8255, 0.8420, 0.6733, 0.7495, 0.9485, 0.8089, 0.0383, 0.6501,\n",
       "         0.8724, 0.8599, 0.7947, 0.9044, 0.8152, 0.5500, 0.8215],\n",
       "        dtype=torch.float64),\n",
       " tensor([0.6810, 0.8102, 0.8345, 0.6973, 0.7577, 0.9541, 0.7990, 0.0475, 0.6869,\n",
       "         0.8835, 0.8266, 0.7986, 0.8609, 0.8114, 0.5521, 0.7321],\n",
       "        dtype=torch.float64),\n",
       " tensor([111.0000, 219.8000, 115.2000, 110.2000, 110.2000, 221.2000, 107.8000,\n",
       "          67.8000, 112.6000, 114.4000, 112.8000, 113.0000, 297.0000, 113.6000,\n",
       "          89.8000, 116.4000]),\n",
       " tensor([0.7223, 0.7400, 0.6812, 0.8323, 0.9566, 0.9504, 0.8921, 0.9351],\n",
       "        dtype=torch.float64),\n",
       " tensor([0.7375, 0.7908, 0.6603, 0.7413, 0.9141, 0.9249, 0.8714, 0.9439],\n",
       "        dtype=torch.float64),\n",
       " tensor([0.7291, 0.7614, 0.6675, 0.7811, 0.9346, 0.9374, 0.8810, 0.9394],\n",
       "        dtype=torch.float64),\n",
       " tensor([  87.6000,  105.2000,  112.4000,  107.4000,  109.4000,  111.8000,\n",
       "          104.2000, 1394.8000]),\n",
       " 0.7759999487952466,\n",
       " 0.8964713107140089]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e2f4dc1-6cda-43a0-95d3-9cf371bfd255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8153, dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(performance[-3] * performance[-4])[:-1].sum() / performance[-3][:-1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44051c50-40e9-4a46-aa34-17f7b5a9ec6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7760, dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(performance[-7] * performance[-8]).sum() / performance[-7].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520e76d8-7176-437d-b56e-220a0af33341",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
