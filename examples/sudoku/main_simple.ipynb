{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "existing-schema",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hfaghihi/Framework/new/DomiKnowS/examples\n",
      "root Folder Absoloute path:  /home/hfaghihi/Framework/new/DomiKnowS\n"
     ]
    }
   ],
   "source": [
    "import os,sys,inspect\n",
    "import json\n",
    "import torch\n",
    "currentdir = os.path.dirname(os.getcwd())\n",
    "print(currentdir)\n",
    "# parent_dir = os.path.abspath(os.path.join(currentdir, os.pardir))\n",
    "root = os.path.dirname(currentdir)\n",
    "print(\"root Folder Absoloute path: \", root)\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(root)\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "import __main__\n",
    "\n",
    "__main__.__file__=\"main.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "recorded-enhancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "from regr.data.reader import RegrReader\n",
    "import torch\n",
    "\n",
    "\n",
    "class SudokuReader(RegrReader):\n",
    "    def parse_file(self):\n",
    "        base  = 3\n",
    "        side  = base*base\n",
    "\n",
    "        # pattern for a baseline valid solution\n",
    "        def pattern(r,c): return (base*(r%base)+r//base+c)%side\n",
    "\n",
    "        # randomize rows, columns and numbers (of valid base pattern)\n",
    "        from random import sample\n",
    "        def shuffle(s): return sample(s,len(s)) \n",
    "        rBase = range(base) \n",
    "        rows  = [ g*base + r for g in shuffle(rBase) for r in shuffle(rBase) ] \n",
    "        cols  = [ g*base + c for g in shuffle(rBase) for c in shuffle(rBase) ]\n",
    "        nums  = shuffle(range(1,base*base+1))\n",
    "\n",
    "        # produce board using randomized baseline pattern\n",
    "        board = [ [nums[pattern(r,c)] for c in cols] for r in rows ]\n",
    "        squares = side*side\n",
    "        empties = squares * 3//4\n",
    "        for p in sample(range(squares),empties):\n",
    "            board[p//side][p%side] = 0\n",
    "        board = torch.tensor(board)\n",
    "    \n",
    "        return [{\"board\": board}]\n",
    "    \n",
    "    def getidval(self, item):\n",
    "        return [1]\n",
    "    def getwhole_sudokuval(self, item):\n",
    "        return item['board']\n",
    "            \n",
    "    \n",
    "    def getsizeval(self, item):\n",
    "        return 9, 9\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "economic-seattle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': [1], 'size': (9, 9), 'whole_sudoku': tensor([[0, 1, 0, 0, 0, 3, 0, 9, 4],\n",
      "        [0, 4, 0, 2, 8, 1, 7, 5, 0],\n",
      "        [7, 0, 0, 9, 0, 0, 0, 2, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 9, 7, 0, 0, 0, 0, 0, 5],\n",
      "        [0, 0, 0, 0, 1, 0, 0, 0, 9],\n",
      "        [0, 0, 0, 0, 0, 7, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "tensor([[0, 1],\n",
      "        [0, 5],\n",
      "        [0, 7],\n",
      "        [0, 8],\n",
      "        [1, 1],\n",
      "        [1, 3],\n",
      "        [1, 4],\n",
      "        [1, 5],\n",
      "        [1, 6],\n",
      "        [1, 7],\n",
      "        [2, 0],\n",
      "        [2, 3],\n",
      "        [2, 7],\n",
      "        [2, 8],\n",
      "        [4, 1],\n",
      "        [4, 2],\n",
      "        [4, 8],\n",
      "        [5, 4],\n",
      "        [5, 8],\n",
      "        [6, 5],\n",
      "        [7, 2]])\n",
      "(tensor([0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 4, 4, 4, 5, 5, 6, 7]), tensor([1, 5, 7, 8, 1, 3, 4, 5, 6, 7, 0, 3, 7, 8, 1, 2, 8, 4, 8, 5, 2]))\n",
      "tensor([1, 3, 9, 4, 4, 2, 8, 1, 7, 5, 7, 9, 2, 1, 9, 7, 5, 1, 9, 7, 1])\n"
     ]
    }
   ],
   "source": [
    "trainreader = SudokuReader(\"randn\", type=\"raw\")\n",
    "item = next(iter(trainreader))\n",
    "print(item)\n",
    "indices = (item['whole_sudoku'] != 0).nonzero()\n",
    "print(indices)\n",
    "print(torch.where(item['whole_sudoku'] != 0))\n",
    "print(item['whole_sudoku'][indices[:, 0], indices[:, 1]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "offshore-destination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file for dataNode is in: /home/hfaghihi/Framework/new/DomiKnowS/examples/sudoku/logs/datanode.log\n",
      "col1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "main.py:26: UserWarning: Please use OrderedDict rather than dict to prevent unpredictable order of arguments.For this instance, OrderedDict([('arg1', 'empty_entry'), ('arg2', 'empty_entry')]) is used.\n",
      "  \n",
      "main.py:31: UserWarning: Please use OrderedDict rather than dict to prevent unpredictable order of arguments.For this instance, OrderedDict([('col1', 'empty_entry'), ('col2', 'empty_entry')]) is used.\n",
      "  return [1]\n",
      "main.py:36: UserWarning: Please use OrderedDict rather than dict to prevent unpredictable order of arguments.For this instance, OrderedDict([('entry1', 'empty_entry'), ('entry2', 'empty_entry')]) is used.\n",
      "  # pattern for a baseline valid solution\n"
     ]
    }
   ],
   "source": [
    "from regr.graph import Graph, Concept, Relation\n",
    "from regr.graph.logicalConstrain import orL, andL, existsL, notL, atLeastL, atMostL, ifL, nandL, V, exactL, fixedL, eqL\n",
    "from regr.graph import EnumConcept\n",
    "\n",
    "\n",
    "Graph.clear()\n",
    "Concept.clear()\n",
    "Relation.clear()\n",
    "\n",
    "with Graph('global') as graph:\n",
    "    sudoku = Concept(\"sodoku\")\n",
    "    \n",
    "#     empty_entries = Concept(name=\"empty_entries\")\n",
    "#     fixed_entries = Concept(name=\"fixed_entries\")\n",
    "    \n",
    "#     (sudoku_empty, sudoku_fixed) = sudoku.has_a(empty_entries, fixed_entries)\n",
    "    \n",
    "    empty_entry = Concept(name='empty_entry')\n",
    "    (empty_rel, ) = sudoku.contains(empty_entry)\n",
    "    \n",
    "#     fixed_entry = Concept(name='fixed_entry')\n",
    "#     (fixed_rel, ) = fixed_entries.contains(fixed_entry)\n",
    "    \n",
    "    same_row = Concept(name=\"same_row\")\n",
    "#     same_row_mixed = Concept(name=\"same_row_mixed\")\n",
    "    (same_row_arg1, same_row_arg2) = same_row.has_a(arg1=empty_entry, arg2=empty_entry)\n",
    "#     (same_row_mixed_arg1, same_row_mixed_arg2) = same_row_mixed.has_a(arg1=empty_entry, arg2=fixed_entry)\n",
    "    \n",
    "    same_col = Concept(name=\"same_col\")\n",
    "#     same_col_mixed = Concept(name=\"same_col_mixed\")\n",
    "    (same_col_arg1, same_col_arg2) = same_col.has_a(col1=empty_entry, col2=empty_entry)\n",
    "    print(same_col_arg1)\n",
    "#     (same_col_mixed_arg1, same_col_mixed_arg2) = same_col_mixed.has_a(arg1=empty_entry, arg2=fixed_entry)\n",
    "\n",
    "    same_table = Concept(name=\"same_table\")\n",
    "    (same_table_arg1, same_table_arg2) = same_table.has_a(entry1=empty_entry, entry2=empty_entry)\n",
    "    \n",
    "    empty_entry_label = empty_entry(name=\"empty_entry_label\", ConceptClass=EnumConcept, values=[\"v1\", \"v2\", \"v3\", \"v4\", \"v5\", \"v6\", \"v7\", \"v8\", \"v9\"])\n",
    "\n",
    "\n",
    "    ### Constraints\n",
    "    # entry = concept(name=\"entry\")\n",
    "    # entry[\"given\"] = ReaderSensor(keyword=\"given\")\n",
    "    # entry_label= entry(name=\"label\")\n",
    "    # fixedL(entry_label(\"x\", eqL(entry, \"given\", {True})))\n",
    "    \n",
    "    fixedL(empty_entry_label(\"x\", eqL(empty_entry, \"fixed\", {True})))\n",
    "    \n",
    "    #fixedL(empty_entry_label(\"x\", path=('x', eqL(empty_entry, \"fixed\", {True}))))\n",
    "\n",
    "    \n",
    "    for val in [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]:\n",
    "        ### No same number in the same row between empty entries and empty entries\n",
    "        ifL(getattr(empty_entry_label, f'v{val}')('x'), \n",
    "            notL(\n",
    "                existsL(\n",
    "                    andL(\n",
    "                        same_row('z', path=(\"x\", same_row_arg1.reversed)), \n",
    "                        getattr(empty_entry_label, f'v{val}')('y', path=(\"z\", same_row_arg2))\n",
    "                ))\n",
    "        ))\n",
    "        \n",
    "        ### No same number in the same column between empty entries and empty entries\n",
    "        ifL(getattr(empty_entry_label, f'v{val}')('x'), \n",
    "            notL(\n",
    "                existsL(\n",
    "                    andL(\n",
    "                        same_col('z', path=(\"x\", same_col_arg1.reversed)), \n",
    "                        getattr(empty_entry_label, f'v{val}')('y', path=(\"z\", same_col_arg2))\n",
    "                ))\n",
    "        ))\n",
    "        \n",
    "        ### No same number in the same table between empty entries and empty entries\n",
    "        ifL(getattr(empty_entry_label, f'v{val}')('x'), \n",
    "            notL(\n",
    "                existsL(\n",
    "                    andL(\n",
    "                        same_table('z', path=(\"x\", same_table_arg1.reversed)), \n",
    "                        getattr(empty_entry_label, f'v{val}')('y', path=(\"z\", same_table_arg2))\n",
    "                ))\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "closed-donna",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Conv2dSame(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, bias=True, padding_layer=torch.nn.ReflectionPad2d):\n",
    "        \"\"\"It only support square kernels and stride=1, dilation=1, groups=1.\"\"\"\n",
    "        super(Conv2dSame, self).__init__()\n",
    "        ka = kernel_size // 2\n",
    "        kb = ka - 1 if kernel_size % 2 == 0 else ka\n",
    "        self.net = nn.Sequential(\n",
    "            padding_layer((ka,kb,ka,kb)),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, bias=bias),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "class SudokuSolver(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.W = torch.nn.Parameter(torch.rand((81,9)))\n",
    "        \n",
    "    def __call__(self, X):\n",
    "        \n",
    "        return self.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "complicated-leadership",
   "metadata": {},
   "outputs": [],
   "source": [
    "from regr.sensor.pytorch.sensors import FunctionalSensor, JointSensor, ReaderSensor, FunctionalReaderSensor\n",
    "from regr.sensor.pytorch.learners import ModuleLearner\n",
    "from regr.sensor.pytorch.relation_sensors import CompositionCandidateSensor, CompositionCandidateSensor\n",
    "from regr.sensor.pytorch.query_sensor import DataNodeReaderSensor\n",
    "\n",
    "class JointFunctionalReaderSensor(JointSensor, FunctionalReaderSensor):\n",
    "    pass\n",
    "\n",
    "\n",
    "# def getempties(*prev, data):\n",
    "#     rows, cols = torch.where(data == 0)\n",
    "#     rel = torch.ones(1, 1)\n",
    "#     return [rows], [cols]\n",
    "    \n",
    "def getfixed(*prev, data):\n",
    "    rows, cols = torch.where(data != 0)\n",
    "    fix = torch.zeros(data.shape)\n",
    "    vals = torch.ones(data.shape) * -1\n",
    "    for i, j in zip(rows.detach().tolist(), cols.detach().tolist()):\n",
    "        fix[i][j] = 1\n",
    "        vals[i][j] = data[i][j]\n",
    "        \n",
    "        \n",
    "    return fix.reshape(fix.shape[0]*fix.shape[1]), vals.reshape(vals.shape[0]*vals.shape[1])\n",
    "\n",
    "def makeSoduko(*prev, data):\n",
    "    num_rows = data[0]\n",
    "    num_cols = data[1]\n",
    "    rows = torch.arange(num_rows).unsqueeze(-1)\n",
    "    rows = rows.repeat(1,num_cols).reshape(num_rows*num_cols)\n",
    "    \n",
    "    cols = torch.arange(num_rows)\n",
    "    cols = cols.unsqueeze(0).repeat(num_rows, 1).reshape(num_rows*num_cols)\n",
    "    \n",
    "    rel = torch.ones(data[0]*data[1], 1)\n",
    "    \n",
    "    return rows, cols, rel\n",
    "\n",
    "def getlabel(*prev, data):\n",
    "    rows, cols = torch.where(data != 0)\n",
    "    vals = torch.ones(data.shape) * -100\n",
    "    for i, j in zip(rows.detach().tolist(), cols.detach().tolist()):\n",
    "        vals[i][j] = data[i][j] - 1\n",
    "    \n",
    "#     print(vals.reshape(vals.shape[0]*vals.shape[1]))\n",
    "#     print(vals.reshape(vals.shape[0]*vals.shape[1]).shape)\n",
    "        \n",
    "    return vals.reshape(vals.shape[0]*vals.shape[1])\n",
    "    \n",
    "    \n",
    "def createSudoku(*prev, data):\n",
    "    return [1]\n",
    "\n",
    "sudoku['index'] = FunctionalReaderSensor(keyword='size', forward=createSudoku)\n",
    "    \n",
    "empty_entry['rows', 'cols', empty_rel] = JointFunctionalReaderSensor(sudoku['index'], keyword='size', forward=makeSoduko)\n",
    "empty_entry['fixed', 'val'] = JointFunctionalReaderSensor('rows', 'cols', empty_rel, keyword='whole_sudoku', forward=getfixed)\n",
    "\n",
    "empty_entry[empty_entry_label] = ModuleLearner('val', module=SudokuSolver())\n",
    "empty_entry[empty_entry_label] = FunctionalReaderSensor(keyword='whole_sudoku', label=True, forward=getlabel)\n",
    "\n",
    "def filter_col(*inputs, col1, col2):\n",
    "    if col1.getAttribute('cols').item() == col2.getAttribute('cols').item() and col1.instanceID != col2.instanceID:\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "same_col[same_col_arg1.reversed, same_col_arg2.reversed] = CompositionCandidateSensor(\n",
    "    empty_entry['cols'],\n",
    "    relations=(same_col_arg1.reversed, same_col_arg2.reversed),\n",
    "    forward=filter_col)\n",
    "\n",
    "def filter_row(*inputs, arg1, arg2):\n",
    "    if arg1.getAttribute('rows').item() == arg2.getAttribute('rows').item() and arg1.instanceID != arg2.instanceID:\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "same_row[same_row_arg1.reversed, same_row_arg2.reversed] = CompositionCandidateSensor(\n",
    "    empty_entry['rows'],\n",
    "    relations=(same_row_arg1.reversed, same_row_arg2.reversed),\n",
    "    forward=filter_row)\n",
    "\n",
    "\n",
    "def filter_table(*inputs, entry1, entry2):\n",
    "    if entry1.instanceID != entry2.instanceID:\n",
    "        if int(entry1.getAttribute('rows').item() / 3) == int(entry2.getAttribute('rows').item() / 3) and int(entry1.getAttribute('cols').item() / 3) == int(entry2.getAttribute('cols').item() / 3):\n",
    "            return True\n",
    "    return False\n",
    "    \n",
    "same_table[same_table_arg1.reversed, same_table_arg2.reversed] = CompositionCandidateSensor(\n",
    "    empty_entry['rows'], empty_entry['cols'],\n",
    "    relations=(same_table_arg1.reversed, same_table_arg2.reversed),\n",
    "    forward=filter_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "statewide-hypothesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "from regr.program import POIProgram, SolverPOIProgram, IMLProgram, CallbackProgram\n",
    "from regr.program.callbackprogram import ProgramStorageCallback\n",
    "from regr.program.metric import MacroAverageTracker, PRF1Tracker, DatanodeCMMetric\n",
    "from regr.program.lossprogram import SampleLossProgram\n",
    "from regr.program.loss import NBCrossEntropyLoss, NBCrossEntropyIMLoss\n",
    "from regr.program.model.pytorch import SolverModel\n",
    "\n",
    "program1 = SolverPOIProgram(\n",
    "        graph, poi=(sudoku, empty_entry, ), inferTypes=['local/argmax'],\n",
    "        loss=MacroAverageTracker(NBCrossEntropyLoss()),\n",
    "#         metric={\n",
    "#             'argmax': PRF1Tracker(DatanodeCMMetric('local/argmax'))}\n",
    ")\n",
    "\n",
    "program = SampleLossProgram(\n",
    "        graph, SolverModel,\n",
    "        poi=(sudoku, empty_entry, ),\n",
    "        inferTypes=['local/argmax'],\n",
    "        # inferTypes=['ILP', 'local/argmax'],\n",
    "#         metric={\n",
    "#             'argmax': PRF1Tracker(DatanodeCMMetric('local/argmax'))},\n",
    "\n",
    "        #metric={ 'softmax' : ValueTracker(prediction_softmax),\n",
    "        #       'ILP': PRF1Tracker(DatanodeCMMetric()),\n",
    "        #        'argmax': PRF1Tracker(DatanodeCMMetric('local/argmax'))\n",
    "        #       },\n",
    "#         loss=MacroAverageTracker(NBCrossEntropyLoss()),\n",
    "        \n",
    "        sample = True,\n",
    "        sampleSize=1000, \n",
    "        sampleGlobalLoss = True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.utils import io\n",
    "\n",
    "# with io.capture_output() as captured:\n",
    "program1.train(trainreader, train_epoch_num=50,\n",
    "              Optim=lambda param: torch.optim.SGD(param, lr=0.1), device='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "imported-appendix",
   "metadata": {},
   "outputs": [],
   "source": [
    "for datanode in program.populate(trainreader):\n",
    "#     print(datanode)\n",
    "    \n",
    "    entries = datanode.getChildDataNodes(conceptName=empty_entry)\n",
    "    for entry in entries:\n",
    "#         print(entry.getAttribute('rows'))\n",
    "#         print(entry.getAttribute('cols'))\n",
    "#         print(entry.getAttribute('fixed'))\n",
    "#         print(entry.getAttribute('val'))\n",
    "#         print(entry.getAttribute(empty_entry_label, 'local/argmax'))\n",
    "        t = entry.getAttribute(empty_entry_label, 'local/argmax')\n",
    "#         print((t == 1).nonzero(as_tuple=True)[0].item() + 1)\n",
    "        predicted = (t == 1).nonzero(as_tuple=True)[0].item() + 1\n",
    "        if entry.getAttribute('fixed').item() == 1:\n",
    "            assert entry.getAttribute('val').item() == predicted\n",
    "#         print(\"---\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "regulation-marker",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:regr.program.program:Epoch: 1\n",
      "INFO:regr.program.program:Training:\n",
      "Epoch 1 Training: 100%|██████████| 1/1 [00:18<00:00, 18.21s/it]\n",
      "INFO:regr.program.program:Epoch: 2\n",
      "INFO:regr.program.program:Training:\n",
      "Epoch 2 Training: 100%|██████████| 1/1 [00:18<00:00, 18.30s/it]\n",
      "INFO:regr.program.program:Epoch: 3\n",
      "INFO:regr.program.program:Training:\n",
      "Epoch 3 Training:   0%|          | 0/1 [00:11<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/Framework/new/DomiKnowS/examples/sudoku/main.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# with io.capture_output() as captured:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m program.train(trainreader, train_epoch_num=50, c_warmup_iters=0, \n\u001b[0;32m----> 5\u001b[0;31m               Optim=lambda param: torch.optim.SGD(param, lr=0.01), device='auto')\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/new/DomiKnowS/regr/program/lossprogram.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_set, valid_set, test_set, c_lr, c_momentum, c_warmup_iters, c_freq, c_freq_increase, c_freq_increase_freq, c_lr_decay, c_lr_decay_param, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mc_lr_decay_param\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc_lr_decay_param\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mc_session\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc_session\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             **kwargs)\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     def train_epoch(\n",
      "\u001b[0;32m~/Framework/new/DomiKnowS/regr/program/program.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_set, valid_set, test_set, device, train_epoch_num, test_every_epoch, Optim, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch: %d'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Validation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtest_every_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/new/DomiKnowS/regr/program/program.py\u001b[0m in \u001b[0;36mcall_epoch\u001b[0;34m(self, name, dataset, epoch_fn, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mdesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mf'Epoch {self.epoch} {name}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0mconsume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/new/DomiKnowS/regr/utils.py\u001b[0m in \u001b[0;36mconsume\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconsume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconsume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/new/DomiKnowS/regr/program/lossprogram.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, dataset, c_lr, c_warmup_iters, c_freq_increase, c_freq_increase_freq, c_lr_decay, c_lr_decay_param, c_session, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m                 \u001b[0mcloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmloss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/new/DomiKnowS/regr/program/model/lossModel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, builder, build)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# Call the loss calculation returns a dictionary, keys are matching the constraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mconstr_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatanode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculateLcLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampleSize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampleSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mlmbd_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/new/DomiKnowS/regr/graph/dataNode.py\u001b[0m in \u001b[0;36mcalculateLcLoss\u001b[0;34m(self, tnorm, sample, sampleSize)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferLocal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1136\u001b[0;31m         \u001b[0mlcResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyilpOntSolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculateLcLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampleSize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampleSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlcResult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/new/DomiKnowS/regr/solver/gurobiILPOntSolver.py\u001b[0m in \u001b[0;36mcalculateLcLoss\u001b[0;34m(self, dn, tnorm, sample, sampleSize)\u001b[0m\n\u001b[1;32m   1178\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mlc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlcLosses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlcLosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lossData'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m                             \u001b[0;31m#isGlobal = False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.utils import io\n",
    "\n",
    "# with io.capture_output() as captured:\n",
    "program.train(trainreader, train_epoch_num=50, c_warmup_iters=0, \n",
    "              Optim=lambda param: torch.optim.SGD(param, lr=0.01), device='auto')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "classified-pharmacology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sodoku 0\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "2\n",
      "---\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "1\n",
      "---\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "9\n",
      "---\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "7\n",
      "---\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "1\n",
      "---\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "7\n",
      "---\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "2\n",
      "---\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(7, device='cuda:0')\n",
      "7\n",
      "---\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "7\n",
      "---\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "3\n",
      "---\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "3\n",
      "---\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "3\n",
      "---\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "3\n",
      "---\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "7\n",
      "---\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "6\n",
      "---\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "3\n",
      "---\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(7, device='cuda:0')\n",
      "2\n",
      "---\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "6\n",
      "---\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "5\n",
      "---\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "2\n",
      "---\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "9\n",
      "---\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "6\n",
      "---\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "1\n",
      "---\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "9\n",
      "---\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "7\n",
      "---\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(7, device='cuda:0')\n",
      "2\n",
      "---\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "4\n",
      "---\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "6\n",
      "---\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "1\n",
      "---\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "4\n",
      "---\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "9\n",
      "---\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "3\n",
      "---\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "7\n",
      "---\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "5\n",
      "---\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(7, device='cuda:0')\n",
      "7\n",
      "---\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "7\n",
      "---\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "6\n",
      "---\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "5\n",
      "---\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "6\n",
      "---\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "1\n",
      "---\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "2\n",
      "---\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "8\n",
      "---\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "9\n",
      "---\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(7, device='cuda:0')\n",
      "2\n",
      "---\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "9\n",
      "---\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "4\n",
      "---\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "9\n",
      "---\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "9\n",
      "---\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "3\n",
      "---\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "9\n",
      "---\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "3\n",
      "---\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "1\n",
      "---\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(7, device='cuda:0')\n",
      "8\n",
      "---\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "8\n",
      "---\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "6\n",
      "---\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "2\n",
      "---\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "1\n",
      "---\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "9\n",
      "---\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "3\n",
      "---\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "1\n",
      "---\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "6\n",
      "---\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(7, device='cuda:0')\n",
      "9\n",
      "---\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "9\n",
      "---\n",
      "tensor(7, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "6\n",
      "---\n",
      "tensor(7, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "3\n",
      "---\n",
      "tensor(7, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "3\n",
      "---\n",
      "tensor(7, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "8\n",
      "---\n",
      "tensor(7, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "3\n",
      "---\n",
      "tensor(7, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "4\n",
      "---\n",
      "tensor(7, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "4\n",
      "---\n",
      "tensor(7, device='cuda:0')\n",
      "tensor(7, device='cuda:0')\n",
      "5\n",
      "---\n",
      "tensor(7, device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "3\n",
      "---\n",
      "tensor(8, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "9\n",
      "---\n",
      "tensor(8, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "1\n",
      "---\n",
      "tensor(8, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "7\n",
      "---\n",
      "tensor(8, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "4\n",
      "---\n",
      "tensor(8, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "2\n",
      "---\n",
      "tensor(8, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "8\n",
      "---\n",
      "tensor(8, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "3\n",
      "---\n",
      "tensor(8, device='cuda:0')\n",
      "tensor(7, device='cuda:0')\n",
      "4\n",
      "---\n",
      "tensor(8, device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "4\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for datanode in program.populate(trainreader):\n",
    "    print(datanode)\n",
    "    table = torch.zeros(9, 9)\n",
    "    \n",
    "    entries = datanode.getChildDataNodes(conceptName=empty_entry)\n",
    "    for entry in entries:\n",
    "        print(entry.getAttribute('rows'))\n",
    "        print(entry.getAttribute('cols'))\n",
    "#         print(entry.getAttribute(empty_entry_label, 'local/argmax'))\n",
    "        t = entry.getAttribute(empty_entry_label, 'local/argmax')\n",
    "#         print((t == 1).nonzero(as_tuple=True)[0].item() + 1)\n",
    "        predicted = (t == 1).nonzero(as_tuple=True)[0].item() + 1\n",
    "        table[entry.getAttribute('rows').item()][entry.getAttribute('cols').item()] = predicted\n",
    "        print(predicted)\n",
    "        if entry.getAttribute('fixed').item() == 1:\n",
    "            assert entry.getAttribute('val').item() == predicted\n",
    "        print(\"---\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "exceptional-worse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 1., 9., 7., 1., 7., 2., 7., 7.],\n",
       "        [3., 3., 3., 3., 7., 6., 3., 2., 6.],\n",
       "        [5., 2., 9., 6., 1., 9., 7., 2., 4.],\n",
       "        [6., 1., 4., 9., 3., 7., 5., 7., 7.],\n",
       "        [6., 5., 6., 1., 2., 8., 9., 2., 9.],\n",
       "        [4., 9., 9., 3., 9., 3., 1., 8., 8.],\n",
       "        [6., 2., 1., 9., 3., 1., 6., 9., 9.],\n",
       "        [6., 3., 3., 8., 3., 4., 4., 5., 3.],\n",
       "        [9., 1., 7., 4., 2., 8., 3., 4., 4.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-neutral",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
