{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hfaghihi/Framework/DomiKnowS/examples/Propara\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "# Please change the root to an absolute or relative path to DomiKnowS root.\n",
    "# In case relative path is used, consider the printed `CWD` as current working directory.\n",
    "root = '/home/hfaghihi/Framework/DomiKnowS'\n",
    "import sys\n",
    "sys.path.append(root)\n",
    "from typing import Any, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '37',\n",
       " 'entities': ['bones'],\n",
       " 'steps': ['A plant of animal dies in a watery environment.',\n",
       "  'Is buried in mud and silt.',\n",
       "  'Soft tissues quickly decompose leaving behind hard bones or shells.',\n",
       "  'Over time sediment builds over the top and hardens into rock.',\n",
       "  'As the bone decays mineral seeps in replacing it.',\n",
       "  'Fossils are formed.'],\n",
       " 'entity_step': [[0.005079575348645449,\n",
       "   0.003536409232765436,\n",
       "   0.9913840293884277],\n",
       "  [0.0023296682629734278, 0.002440220210701227, 0.9952301979064941],\n",
       "  [0.004893037490546703, 0.004029534757137299, 0.9910774230957031],\n",
       "  [0.9432244300842285, 0.05380963161587715, 0.002965932944789529],\n",
       "  [0.9029137492179871, 0.09116195142269135, 0.005924322176724672],\n",
       "  [0.005038038361817598, 0.008660664781928062, 0.9863013029098511],\n",
       "  [0.006529272999614477, 0.009216826409101486, 0.9842538833618164]]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"updated_test_data.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regr.data.reader import RegrReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProparaReader(RegrReader):\n",
    "    def parse_file(self):\n",
    "        with open(self.file, 'r') as f:\n",
    "            lines = []\n",
    "            for line in f:\n",
    "                try:\n",
    "                    if line != \"\\n\":\n",
    "                        lines.append(json.loads(str(line)))\n",
    "                except:\n",
    "                    raise\n",
    "        items = lines\n",
    "        final_dict = []\n",
    "        for item in items:\n",
    "            for i in range(len(item['participants'])):\n",
    "                instance = item.copy()\n",
    "                instance['participants'] = [item['participants'][i]]\n",
    "                instance['states'] = item['states'][i]\n",
    "                final_dict.append(instance)\n",
    "                \n",
    "        return final_dict\n",
    "    \n",
    "#     def getDataval(self, item):\n",
    "#         return item\n",
    "                \n",
    "    def getParaIDval(self, item):\n",
    "        return [item['para_id']]\n",
    "    \n",
    "    def getSentencesval(self, item):\n",
    "        data = ['step 0 goes here']\n",
    "        data.extend(item['sentence_texts'])\n",
    "        return data\n",
    "    \n",
    "    def getEntityval(self, item):\n",
    "        return item['participants']\n",
    "    \n",
    "    def getnon_existenceval(self, item):\n",
    "        values = []\n",
    "        for value in item['states']:\n",
    "            if value == \"-\":\n",
    "                values.append(1)\n",
    "            else:\n",
    "                values.append(0)\n",
    "        return values\n",
    "    \n",
    "    def getunknownval(self, item):\n",
    "        values = []\n",
    "        for value in item['states']:\n",
    "            if value == \"?\":\n",
    "                values.append(1)\n",
    "            else:\n",
    "                values.append(0)\n",
    "        return values\n",
    "    \n",
    "    def getlocationval(self, item):\n",
    "        values = []\n",
    "        for value in item['states']:\n",
    "            if value != \"?\" and value != \"-\":\n",
    "                values.append(1)\n",
    "            else:\n",
    "                values.append(0)\n",
    "        return values\n",
    "    \n",
    "    def getLocationTextval(self, item):\n",
    "        values = []\n",
    "        for value in item['states']:\n",
    "            if value != \"?\" and value != \"-\":\n",
    "                values.append(value)\n",
    "            else:\n",
    "                values.append(\"NAN\")\n",
    "        return values\n",
    "    \n",
    "    \n",
    "    \n",
    "#     def getstepsval(self, item):\n",
    "#         num_steps = len(item['steps']) + 1\n",
    "#         rel = torch.ones(num_steps,1)\n",
    "#         sentences = [\"step 0 information\"]\n",
    "#         sentences.extend(item['steps'])\n",
    "#         return rel, sentences\n",
    "    \n",
    "#     def getnon_existenceval(self, item):\n",
    "#         values = []\n",
    "#         for step in range(len(item['steps']) + 1):\n",
    "#             values.append([1 - item['entity_step'][step][2], item['entity_step'][step][2]])\n",
    "#         return torch.tensor(values)\n",
    "            \n",
    "#     def getknownval(self, item):\n",
    "#         values = []\n",
    "#         for step in range(len(item['steps']) + 1):\n",
    "#             values.append([1 - item['entity_step'][step][0], item['entity_step'][step][0]])\n",
    "#         return torch.tensor(values)\n",
    "    \n",
    "#     def getunknownval(self, item):\n",
    "#         values = []\n",
    "#         for step in range(len(item['steps']) + 1):\n",
    "#             values.append([1 - item['entity_step'][step][1], item['entity_step'][step][1]])\n",
    "#         return torch.tensor(values)\n",
    "    \n",
    "#     def getactionval(self, item):\n",
    "#         action1s = torch.diag(torch.ones(len(item['steps']) + 1) )[:-1]\n",
    "#         action2s = torch.diag(torch.ones(len(item['steps']) + 1) )[1:]\n",
    "#         raw = torch.zeros(len(item['steps']))\n",
    "#         return action1s, action2s\n",
    "    \n",
    "#     def getcreateval(self, item):\n",
    "#         actions = []\n",
    "#         prev_state = item['entity_step'][0]\n",
    "#         for sid, step in enumerate(item['steps']):\n",
    "#             o = 0\n",
    "#             c = 0\n",
    "#             d = 0\n",
    "#             o += (prev_state[0] * item['entity_step'][sid+1][0])\n",
    "#             o += (prev_state[0] * item['entity_step'][sid+1][1])\n",
    "#             o += (prev_state[1] * item['entity_step'][sid+1][0])\n",
    "#             o += (prev_state[1] * item['entity_step'][sid+1][1])\n",
    "#             o += (prev_state[2] * item['entity_step'][sid+1][2])\n",
    "#             d += (prev_state[0] * item['entity_step'][sid+1][2])\n",
    "#             d += (prev_state[1] * item['entity_step'][sid+1][2])\n",
    "#             c += (prev_state[2] * item['entity_step'][sid+1][1])\n",
    "#             c += (prev_state[2] * item['entity_step'][sid+1][0])\n",
    "#             actions.append([1-c, c])\n",
    "#             prev_state = item['entity_step'][sid+1]\n",
    "        \n",
    "#         return torch.tensor(actions)\n",
    "                    \n",
    "#     def getdestroyval(self, item):\n",
    "#         actions = []\n",
    "#         prev_state = item['entity_step'][0]\n",
    "#         for sid, step in enumerate(item['steps']):\n",
    "#             o = 0\n",
    "#             c = 0\n",
    "#             d = 0\n",
    "#             o += (prev_state[0] * item['entity_step'][sid+1][0])\n",
    "#             o += (prev_state[0] * item['entity_step'][sid+1][1])\n",
    "#             o += (prev_state[1] * item['entity_step'][sid+1][0])\n",
    "#             o += (prev_state[1] * item['entity_step'][sid+1][1])\n",
    "#             o += (prev_state[2] * item['entity_step'][sid+1][2])\n",
    "#             d += (prev_state[0] * item['entity_step'][sid+1][2])\n",
    "#             d += (prev_state[1] * item['entity_step'][sid+1][2])\n",
    "#             c += (prev_state[2] * item['entity_step'][sid+1][1])\n",
    "#             c += (prev_state[2] * item['entity_step'][sid+1][0])\n",
    "#             actions.append([1-d, d])\n",
    "#             prev_state = item['entity_step'][sid+1]\n",
    "#         return torch.tensor(actions)\n",
    "    \n",
    "#     def getotherval(self, item):\n",
    "#         actions = []\n",
    "#         prev_state = item['entity_step'][0]\n",
    "#         for sid, step in enumerate(item['steps']):\n",
    "#             o = 0\n",
    "#             c = 0\n",
    "#             d = 0\n",
    "#             o += (prev_state[0] * item['entity_step'][sid+1][0])\n",
    "#             o += (prev_state[0] * item['entity_step'][sid+1][1])\n",
    "#             o += (prev_state[1] * item['entity_step'][sid+1][0])\n",
    "#             o += (prev_state[1] * item['entity_step'][sid+1][1])\n",
    "#             o += (prev_state[2] * item['entity_step'][sid+1][2])\n",
    "#             d += (prev_state[0] * item['entity_step'][sid+1][2])\n",
    "#             d += (prev_state[1] * item['entity_step'][sid+1][2])\n",
    "#             c += (prev_state[2] * item['entity_step'][sid+1][1])\n",
    "#             c += (prev_state[2] * item['entity_step'][sid+1][0])\n",
    "#             actions.append([1-o, o])\n",
    "#             prev_state = item['entity_step'][sid+1]\n",
    "#         return torch.tensor(actions)\n",
    "    \n",
    "    def getbeforeval(self, item):\n",
    "        b1s = []\n",
    "        b2s = []\n",
    "        for step in range(len(item['states']) + 1):\n",
    "            b1 = torch.zeros(len(item['states']) + 1)\n",
    "            b1[step] = 1\n",
    "            for step1 in range(len(item['states']) + 1):\n",
    "                b2 = torch.zeros(len(item['states']) + 1)\n",
    "                b2[step1] = 1\n",
    "                b1s.append(b1)\n",
    "                b2s.append(b2)\n",
    "        return torch.stack(b1s), torch.stack(b2s)\n",
    "    \n",
    "    def getbefore_trueval(self, item):\n",
    "        num_steps = len(item['states']) + 1\n",
    "        values = torch.zeros(num_steps * num_steps)\n",
    "        for step in range(len(item['states']) + 1):\n",
    "            for step1 in range(step + 1, len(item['states']) + 1):\n",
    "                values[(step*num_steps)+step1] = 1\n",
    "        return values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Entity': ['magma'],\n",
       " 'LocationText': ['deep in the earth',\n",
       "  'deep in the earth',\n",
       "  'volcano',\n",
       "  'volcano',\n",
       "  'NAN',\n",
       "  'NAN',\n",
       "  'NAN',\n",
       "  'NAN',\n",
       "  'NAN'],\n",
       " 'ParaID': ['7'],\n",
       " 'Sentences': ['step 0 goes here',\n",
       "  'Magma rises from deep in the earth.',\n",
       "  'The magma goes into volcanos.',\n",
       "  'The volcanos pressure the magma upwards.',\n",
       "  'The pressure causes the magma to push through the surface of the volcano.',\n",
       "  'The lava cools.',\n",
       "  'The lava forms new rock.',\n",
       "  'New magma is pressured to the surface of the volcano.',\n",
       "  'The volcano bursts through the rock the formed after the last eruption.'],\n",
       " 'before_true': tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
       "         1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'before': (tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " 'location': [1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       " 'non_existence': [0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       " 'unknown': [0, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ReaderObjectsIterator = ProparaReader(\"emnlp18/grids.v1.train.json\", 'parse')\n",
    "list(iter(ReaderObjectsIterator))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file for dataNode is in: /home/hfaghihi/Framework/DomiKnowS/examples/Propara/datanode.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: Please use OrderedDict rather than dict to prevent unpredictable order of arguments.For this instance, OrderedDict([('arg1', 'text'), ('arg2', 'entity')]) is used.\n",
      "  if sys.path[0] == '':\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:32: UserWarning: Please use OrderedDict rather than dict to prevent unpredictable order of arguments.For this instance, OrderedDict([('arg1', 'step'), ('arg2', 'step')]) is used.\n"
     ]
    }
   ],
   "source": [
    "from regr.graph import Graph, Concept, Relation\n",
    "from regr.graph.logicalConstrain import orL, andL, existsL, notL, atLeastL, atMostL, ifL, nandL, eqL\n",
    "\n",
    "Graph.clear()\n",
    "Concept.clear()\n",
    "Relation.clear()\n",
    "\n",
    "with Graph('global') as graph:\n",
    "    procedure = Concept(\"procedure\")\n",
    "    text = Concept(\"text\")\n",
    "    entity = Concept(\"entity\")\n",
    "    (procedure_text, procedure_entity) = procedure.has_a(arg1=text, arg2=entity)\n",
    "    step = Concept(\"step\")\n",
    "    (text_contain_step, ) = text.contains(step)\n",
    "    \n",
    "    pair = Concept(\"pair\")\n",
    "    (pair_entity, pair_step) = pair.has_a(entity, step)\n",
    "    \n",
    "    word = Concept(\"word\")\n",
    "    (pair_contains_words, ) = pair.contains(word)\n",
    "    \n",
    "    word1 = Concept(\"word1\")\n",
    "    \n",
    "    non_existence = pair(\"non_existence\")\n",
    "    unknown_loc = pair(\"unknown_location\")\n",
    "    known_loc = pair(\"known_location\")\n",
    "    \n",
    "    triplet = Concept(\"triplet\")\n",
    "    (triplet_entity, triplet_step, triplet_word) = triplet.has_a(entity, step, word)\n",
    "    \n",
    "    before = Concept(\"before\")\n",
    "    (before_arg1, before_arg2) = before.has_a(arg1=step, arg2=step)\n",
    "    \n",
    "#     action = Concept(\"action\")\n",
    "#     (action_arg1, action_arg2) = action.has_a(arg1=step, arg2=step)\n",
    "#     create = action(name=\"create\")\n",
    "#     destroy = action(name=\"destroy\")\n",
    "#     other = action(name=\"other\")\n",
    "    \n",
    "    #LC5 : If action is create then the first step should be non_existence and the second step can be either known_loc or unknown_loc\n",
    "#     ifL(create, (\"x\", \"y\", ), andL(non_existence, (\"x\", ), orL(known_loc, (\"y\", ), unknown_loc, (\"y\", ))))\n",
    "    \n",
    "#     #LC 6 : If action is destroy, then first step should be either known_loc,or unknown_loc and the next step should be non_existence \n",
    "#     ifL(destroy, (\"x\", \"y\", ), andL(orL(known_loc, (\"x\", ), unknown_loc, (\"x\", )), non_existence, (\"y\", )))\n",
    "    \n",
    "#     #LC7 : There should be at most 1 create\n",
    "#     atMostL(1, (\"x\", ), create, (\"x\", ))\n",
    "    \n",
    "#     #LC8 : There should be at most one destroy\n",
    "#     atMostL(1, (\"x\", ), destroy, (\"x\", ))\n",
    "    \n",
    "#     #LC9 : If (x1,x2) is create and (y1, y2) is destroy, then the pair(x2,y2) in before should have the property \"check\" equal to 1.\n",
    "#     # I will have to check if this eqL works if not will update it\n",
    "#     ifL(andL(create, (\"x1\", \"x2\"), destroy, (\"y1\", \"y2\")), eqL(before, \"check\", 1), (\"x2\", \"y2\"))\n",
    "    \n",
    "#     #LC1 : An action can not be create, destroy and other at the same time\n",
    "#     nandL(create, destroy, other)\n",
    "    \n",
    "#     #LC2 : An action should at least be one of the create, destroy or other\n",
    "#     orL(create, destroy, other)\n",
    "    \n",
    "#     #LC3 : A step can not be known_loc, unknown_loc and non_existence at the same time\n",
    "#     nandL(known_loc, unknown_loc, non_existence)\n",
    "    \n",
    "#     #LC4 : A step should at least be one of known_loc, unknown_loc or non_existence\n",
    "#     orL(known_loc, unknown_loc, non_existence)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regr.sensor.pytorch.sensors import ReaderSensor, JointSensor\n",
    "from regr.sensor.pytorch.relation_sensors import EdgeSensor\n",
    "\n",
    "class EdgeReaderSensor(EdgeSensor, ReaderSensor):\n",
    "    def __init__(self, *pres, relation, mode=\"forward\", keyword=None, **kwargs):\n",
    "        super().__init__(*pres, relation=relation, mode=mode, **kwargs)\n",
    "        self.keyword = keyword\n",
    "        self.data = None\n",
    "        \n",
    "# class JoinReaderSensor(JointSensor, ReaderSensor):\n",
    "#     pass\n",
    "            \n",
    "# class JoinEdgeReaderSensor(JointSensor, EdgeReaderSensor):\n",
    "#     pass\n",
    "\n",
    "class JoinReaderSensor(JointSensor, ReaderSensor):\n",
    "    pass\n",
    "\n",
    "class JoinEdgeReaderSensor(JoinReaderSensor, EdgeSensor):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regr.sensor.pytorch.sensors import ReaderSensor, FunctionalSensor, JointSensor\n",
    "from regr.sensor.pytorch.learners import TorchLearner, ModuleLearner\n",
    "from regr.program import LearningBasedProgram\n",
    "from regr.program.model.pytorch import PoiModel\n",
    "import torch\n",
    "from torch import nn\n",
    "import functools\n",
    "import operator\n",
    "\n",
    "from regr.program.loss import NBCrossEntropyLoss\n",
    "\n",
    "def model_declaration():\n",
    "\n",
    "    graph.detach()\n",
    "\n",
    "    procedure['id'] = ReaderSensor(keyword='ParaID')\n",
    "    entity['raw'] = ReaderSensor(keyword='Entity')\n",
    "    text['raw'] = ReaderSensor(keyword=\"Sentences\")\n",
    "    word1['raw'] = ReaderSensor(keyword=\"LocationText\")\n",
    "    \n",
    "    def sentence_parser(text):\n",
    "        sentence = \"\"\n",
    "        for item in text[1:-1]:\n",
    "            sentence += str(item) + \" </s> \"\n",
    "        sentence += str(text[-1])\n",
    "        return [sentence]\n",
    "    \n",
    "    text['ready'] = FunctionalSensor(text['raw'], forward=sentence_parser)\n",
    "    \n",
    "    def boundary_finder(*inputs):\n",
    "        import re\n",
    "        output = []\n",
    "        for sentences in inputs[0]:\n",
    "            boundaries = []\n",
    "            start = 0\n",
    "            for m in re.finditer('/s'.lower(), sentences.lower()):\n",
    "                boundaries.append((start, m.start()-2))\n",
    "                start = m.end() + 2\n",
    "            boundaries.append((start, len(sentences)))\n",
    "            output.append(boundaries)\n",
    "        return output\n",
    "            \n",
    "        \n",
    "    text['boundaries'] = FunctionalSensor(text['ready'], forward=boundary_finder)\n",
    "    \n",
    "    def find_spans(*inputs):\n",
    "        import re\n",
    "        import inflect\n",
    "        engine = inflect.engine()\n",
    "        sentences = inputs[1][0]\n",
    "        boundaries = inputs[2][0]\n",
    "        prev_loc = \"\"\n",
    "        annotations = []\n",
    "        for time, loc in enumerate(inputs[0]):\n",
    "#             print(\"searching for: \", time, loc)\n",
    "            if \"'\" in loc:\n",
    "                loc = loc.replace(\" '\", \"'\")\n",
    "            all_loc = []\n",
    "            final_loc = (0, 0)\n",
    "            if loc == \"NAN\":\n",
    "                loc = \"-\"\n",
    "            elif loc != \"NAN\":\n",
    "                if loc == prev_loc:\n",
    "                    final_loc = annotations[-1][1]\n",
    "                    annotations.append((loc, final_loc))\n",
    "                    prev_loc = loc\n",
    "                    continue\n",
    "                for m in re.finditer(\" \" + loc.lower(), sentences.lower()):\n",
    "                    start = m.start()\n",
    "                    if sentences[m.start()] == \" \":\n",
    "                        start = m.start() + 1\n",
    "                    all_loc.append((start, m.end()))\n",
    "\n",
    "                if len(all_loc) == 0:\n",
    "                    for m in re.finditer(loc.lower(), sentences.lower()):\n",
    "                        start = m.start()\n",
    "                        if sentences[m.start()] == \" \":\n",
    "                            start = m.start() + 1\n",
    "                        all_loc.append((start, m.end()))\n",
    "#                 if len(all_loc) == 0:\n",
    "#                     final_loc = final_loc\n",
    "                if len(all_loc) == 0 and \"recycle\" in loc:\n",
    "                    for m in re.finditer(\" \" + loc.replace(\"recycle\", \"recycling\").lower(), sentences.lower()):\n",
    "                        start = m.start()\n",
    "                        if sentences[m.start()] == \" \":\n",
    "                            start = m.start() + 1\n",
    "                        all_loc.append((start, m.end()))\n",
    "                if len(all_loc) == 0:\n",
    "                    if loc == \"alveolus\":\n",
    "                        loc = \"alveoli\"\n",
    "                    if loc == \"sew machine\":\n",
    "                        loc = \"machine\"\n",
    "                    if loc == \"cool tower\":\n",
    "                        loc = \"cooling tower\"\n",
    "                    if loc == \"cart or on a conveyor belt\":\n",
    "                        loc = \"carts or on a conveyor belt\"\n",
    "                    if loc == \"bee leg\":\n",
    "                        loc = \"bees legs\"\n",
    "                    if loc == \"bottom of river and ocean\":\n",
    "                        loc = \"bottom of rivers and oceans\"\n",
    "                    if loc == \"body of water\":\n",
    "                        loc = \"bodies of water\"\n",
    "                    if loc == \"crack in rock\":\n",
    "                        loc = \"cracks in rocks\"\n",
    "                    if loc == \"dry ingredient .\":\n",
    "                        loc = \"dry ingredients\"\n",
    "                    if loc == \"grease cake pan\":\n",
    "                        loc = \"greased cake pan\"\n",
    "                    if loc == \"release from the atom\":\n",
    "                        loc = \"released from the atom\"\n",
    "                    if loc == \"bottom of ocean , riverbed or swamp\":\n",
    "                        loc = \"bottom of oceans, riverbeds or swamps\"\n",
    "                    if loc == \"opposite end of the cell\" or loc == \"opposite pole of the cell\":\n",
    "                        loc = \"opposite poles of the cell\"\n",
    "                    if loc == \"fat , muscle and liver cell\":\n",
    "                        loc = \"fat, muscle and liver cells\"\n",
    "                    if loc == \"turn mechanisms\":\n",
    "                        loc = \"turning mechanism\"\n",
    "                    if loc == \"surround rocks\":\n",
    "                        loc = \"sorrounding rocks\"\n",
    "                    for m in re.finditer(\" \" + loc.lower(), sentences.lower()):\n",
    "                        start = m.start()\n",
    "                        if sentences[m.start()] == \" \":\n",
    "                            start = m.start() + 1\n",
    "                        all_loc.append((start, m.end()))\n",
    "                if len(all_loc) == 0:\n",
    "                    loc = loc.replace(\" , \", \", \")\n",
    "                    for m in re.finditer(\" \" + loc.lower(), sentences.lower()):\n",
    "                        start = m.start()\n",
    "                        if sentences[m.start()] == \" \":\n",
    "                            start = m.start() + 1\n",
    "                        all_loc.append((start, m.end()))\n",
    "                if len(all_loc) == 0:\n",
    "                    loc = loc.replace(\" , \", \", \")\n",
    "                    stri = loc.split(\",\")\n",
    "                    stri_f = \"\"\n",
    "                    for item in stri:\n",
    "                        if not engine.singular_noun(item):\n",
    "                            item = engine.plural(item)\n",
    "                        stri_f += \",\" + item\n",
    "                    loc = stri_f[1:]\n",
    "                    for m in re.finditer(\" \" + loc.lower(), sentences.lower()):\n",
    "                        start = m.start()\n",
    "                        if sentences[m.start()] == \" \":\n",
    "                            start = m.start() + 1\n",
    "                        all_loc.append((start, m.end()))\n",
    "                    if len(all_loc) == 0:\n",
    "                        for m in re.finditer(loc.lower(), sentences.lower()):\n",
    "                            start = m.start()\n",
    "                            if sentences[m.start()] == \" \":\n",
    "                                start = m.start() + 1\n",
    "                            all_loc.append((start, m.end()))\n",
    "                    if len(all_loc) == 0:\n",
    "                        stri = loc.split(\"and\")\n",
    "                        stri_f = \"\"\n",
    "                        for item in stri:\n",
    "                            if not engine.singular_noun(item):\n",
    "                                item = engine.plural(item)\n",
    "                            stri_f += \"and\" + item\n",
    "                        loc = stri_f[3:]\n",
    "                        for m in re.finditer(\" \" + loc.lower(), sentences.lower()):\n",
    "                            start = m.start()\n",
    "                            if sentences[m.start()] == \" \":\n",
    "                                start = m.start() + 1\n",
    "                            all_loc.append((start, m.end()))\n",
    "                    if len(all_loc) == 0:\n",
    "                        for m in re.finditer(loc.lower(), sentences.lower()):\n",
    "                            start = m.start()\n",
    "                            if sentences[m.start()] == \" \":\n",
    "                                start = m.start() + 1\n",
    "                            all_loc.append((start, m.end()))\n",
    "                    if len(all_loc) == 0:\n",
    "                        print(\"data in hand 3: \", loc)\n",
    "                        \n",
    "                if len(all_loc) == 1 or (not time and len(all_loc) >= 1):\n",
    "                    final_loc = all_loc[0]\n",
    "                else:\n",
    "                    in_sentence_check = False\n",
    "                    if time:\n",
    "                        for can_loc in all_loc:\n",
    "                            if can_loc[0] > boundaries[time-1][0] and can_loc[1] < boundaries[time-1][1]:\n",
    "                                final_loc = can_loc\n",
    "                                in_sentence_check = True\n",
    "                                break\n",
    "                        if not in_sentence_check:\n",
    "                            if len(all_loc) == 0:\n",
    "                                selected_boundary = (0, 0)\n",
    "                            else:\n",
    "                                selected_boundary = (0, 0)\n",
    "                                for can_loc in all_loc:\n",
    "                                    if can_loc[0] < boundaries[time-1][0] and can_loc[0] > selected_boundary[0]:\n",
    "                                        selected_boundary = can_loc\n",
    "                                if selected_boundary == (0,0):\n",
    "                                    selected_boundary = all_loc[-1]\n",
    "                                    for can_loc in all_loc: \n",
    "                                         if can_loc[1] > boundaries[time-1][1] and can_loc[1] < selected_boundary[1]:\n",
    "                                                selected_boundary = can_loc\n",
    "                            final_loc = selected_boundary\n",
    "            annotations.append((loc, final_loc))\n",
    "        return annotations\n",
    "    \n",
    "    word1['annotations'] = FunctionalSensor(word1['raw'], text['ready'] ,text['boundaries'], forward=find_spans)\n",
    "    \n",
    "    \n",
    "    def sentence_separator(text):\n",
    "        mapping = torch.ones(len(text), 1)\n",
    "        return mapping, text\n",
    "    \n",
    "    step[text_contain_step, 'raw'] = JointSensor(text['raw'], forward=sentence_separator)\n",
    "    \n",
    "    \n",
    "    def procedure_candidate(*inputs):\n",
    "        import re\n",
    "        mapping1 = torch.zeros(len(inputs[0])*len(inputs[2]), len(inputs[0]))\n",
    "        for i in range(len(inputs[0])):\n",
    "            mapping1[i*len(inputs[2]):(i+1)*len(inputs[2]), i] = 1\n",
    "        \n",
    "        mapping2 = torch.zeros(len(inputs[2]) * len(inputs[0]), len(inputs[2]))\n",
    "        \n",
    "        for i in range(len(inputs[2])):\n",
    "            mapping2[i*len(inputs[0]):(i+1)*len(inputs[0]), i] = 1\n",
    "            \n",
    "        text = [\"Where is \" + str(inputs[0][0]) + \"?!</s>\" + str(inputs[1][0])] * len(inputs[2])\n",
    "        padding = []\n",
    "        for story in text:\n",
    "            for m in re.finditer('/s'.lower(), story.lower()):\n",
    "                end = m.end() + 1\n",
    "                break\n",
    "            padding.append(end)\n",
    "        return mapping1, mapping2, text, padding\n",
    "    \n",
    "    pair[pair_entity.reversed, pair_step.reversed, 'text', 'padding'] = JointSensor(entity['raw'], text['ready'], step['raw'], forward=procedure_candidate)\n",
    "    \n",
    "    \n",
    "    class RoBertaTokenizorSensor(JointSensor):\n",
    "        from transformers import RobertaTokenizerFast\n",
    "        TRANSFORMER_MODEL = 'roberta-large'\n",
    "        tokenizer = RobertaTokenizerFast.from_pretrained(TRANSFORMER_MODEL)\n",
    "\n",
    "        def roberta_extract_timestamp_sequence(self, inputs, end_time):\n",
    "            f_out = []\n",
    "            padding = 0\n",
    "            for time in range(-1, end_time - 1):\n",
    "                timestamp_id = []\n",
    "                if time == -1:\n",
    "                    check = -1\n",
    "                    for index, ids in enumerate(inputs['input_ids'][time + 1]):\n",
    "                        if ids == 2:\n",
    "                            check += 1\n",
    "                            if check == 0:\n",
    "                                padding = index + 1\n",
    "                        if check == -1:\n",
    "                            timestamp_id.append(0)\n",
    "                        elif ids == 2:\n",
    "                            timestamp_id.append(0)\n",
    "                        else:\n",
    "                            timestamp_id.append(2)\n",
    "                else:\n",
    "                    check = -1\n",
    "                    for index, ids in enumerate(inputs['input_ids'][time + 1]):\n",
    "                        if ids == 2:\n",
    "                            check += 1\n",
    "                        if check == -1:\n",
    "                            timestamp_id.append(0)\n",
    "                        elif ids == 2:\n",
    "                            timestamp_id.append(0)\n",
    "                        else:\n",
    "                            if check < time :\n",
    "                                timestamp_id.append(1)\n",
    "                            elif check == time:\n",
    "                                timestamp_id.append(2)\n",
    "                            else:\n",
    "                                timestamp_id.append(3)\n",
    "                timestamp_id = torch.tensor(timestamp_id).to(device=inputs['input_ids'].device)\n",
    "                f_out.append(timestamp_id)\n",
    "            inputs['timestep_type_ids'] = torch.stack(f_out)\n",
    "            return inputs, padding\n",
    "\n",
    "        def forward(self, *inputs):\n",
    "            sentences = inputs[0]\n",
    "            tokens = self.tokenizer(\n",
    "                sentences,\n",
    "                return_tensors='pt',\n",
    "                return_offsets_mapping=True,\n",
    "            )\n",
    "            token_strings = []\n",
    "            token_nums = []\n",
    "            mapping = torch.zeros(len(tokens['input_ids'][0])*len(sentences), len(sentences))\n",
    "            tokens, padding = self.roberta_extract_timestamp_sequence(inputs=tokens, end_time=len(sentences))\n",
    "            for sen_num in range(len(sentences)):\n",
    "                token_strings.append(self.tokenizer.convert_ids_to_tokens(tokens['input_ids'][sen_num]))\n",
    "                token_nums.append(len(tokens['input_ids'][sen_num]))\n",
    "                mapping[sen_num*len(tokens['input_ids'][0]):((sen_num+1)*len(tokens['input_ids'][0])),sen_num] = 1\n",
    "\n",
    "            for key in tokens.keys():\n",
    "                tokens[key] = functools.reduce(operator.iconcat, tokens[key], [])\n",
    "                tokens[key] = torch.stack(tokens[key])\n",
    "            tokens['tokens'] = token_strings\n",
    "            tokens['token_nums'] = token_nums\n",
    "            return mapping.to(self.device), tokens['input_ids'].to(self.device), tokens['attention_mask'].to(self.device), tokens['offset_mapping'].to(self.device), tokens['timestep_type_ids'].to(self.device), tokens['tokens'], tokens['token_nums']\n",
    "        \n",
    "\n",
    "    word[pair_contains_words, 'input_ids', 'attention_mask', 'offset_mapping', \"timestep_type_ids\", 'tokens', 'token_nums'] = RoBertaTokenizorSensor(pair['text'], pair[pair_entity.reversed], pair[pair_step.reversed])\n",
    "    \n",
    "#     pair[pair_contains_words.reversed] = FunctionalSensor(word[pair_contains_words], forward=lambda x : x[0].t)\n",
    "    \n",
    "    class BatchifyLearner(TorchLearner):\n",
    "        import functools\n",
    "        import operator\n",
    "        def __init__(self, *pres, batchify=True, **kwargs):\n",
    "            super().__init__(*pres, **kwargs)\n",
    "            self.batchify = batchify\n",
    "            \n",
    "            \n",
    "        def fetch_value(self, pre, selector=None, concept=None):\n",
    "            from regr.graph.relation import Transformed, Relation\n",
    "            from regr.sensor.sensor import Sensor\n",
    "            from regr.graph.property import Property\n",
    "            concept = concept or self.concept\n",
    "            if isinstance(pre, str):\n",
    "                return super().fetch_value(pre, selector, concept)\n",
    "            elif isinstance(pre, (Property, Sensor)):\n",
    "                return self.context_helper[pre]\n",
    "            elif isinstance(pre, Relation):\n",
    "                return self.context_helper[self.concept[pre]]\n",
    "            elif isinstance(pre, Transformed):\n",
    "                return pre(self.context_helper, device=self.device)\n",
    "            return pre\n",
    "    \n",
    "        def define_inputs(self):\n",
    "            self.inputs = []\n",
    "            if len(self.batchify):\n",
    "                hinter = self.fetch_value(self.batchify[0])\n",
    "            for pre in self.pres:\n",
    "                values = self.fetch_value(pre)\n",
    "#                 print(pre, values)\n",
    "#                 values = torch.stack(values)\n",
    "                if len(self.batchify):\n",
    "                    final_val = []\n",
    "                    for hint in hinter.t():\n",
    "                        slicer = torch.nonzero(hint).squeeze(-1)\n",
    "                        final_val.append(values.index_select(0, slicer))\n",
    "                    values = torch.stack(final_val)\n",
    "                self.inputs.append(values)\n",
    "                \n",
    "        def update_pre_context(\n",
    "            self,\n",
    "            data_item: Dict[str, Any],\n",
    "            concept=None\n",
    "        ) -> Any:\n",
    "            super().update_pre_context(data_item, concept)\n",
    "            concept = concept or self.concept\n",
    "            for batchifier in self.batchify:\n",
    "                for sensor in concept[batchifier].find(self.non_label_sensor):\n",
    "                    sensor(data_item=data_item)\n",
    "                    \n",
    "        def update_context(\n",
    "            self,\n",
    "            data_item: Dict[str, Any],\n",
    "            force=False,\n",
    "            override=True):\n",
    "            if not force and self in data_item:\n",
    "                # data_item cached results by sensor name. override if forced recalc is needed\n",
    "                val = data_item[self]\n",
    "            else:\n",
    "                self.update_pre_context(data_item)\n",
    "                self.define_inputs()\n",
    "                val = self.forward_wrap()\n",
    "                \n",
    "                if len(self.batchify):\n",
    "                    val = functools.reduce(operator.iconcat, val, [])\n",
    "                    val = torch.stack(val)\n",
    "                    \n",
    "                data_item[self] = val\n",
    "            if override and not self.label:\n",
    "                data_item[self.prop] = val  # override state under property name\n",
    "                \n",
    "           \n",
    "    class BatchifyModuleLearner(ModuleLearner, BatchifyLearner):\n",
    "        pass\n",
    "    \n",
    "    class RobertaModelLearner(BatchifyModuleLearner):\n",
    "        def forward(self, *inputs):\n",
    "            running = {}\n",
    "            running[\"input_ids\"] = inputs[0]\n",
    "            running[\"attention_mask\"] = inputs[1]\n",
    "            running[\"timestep_type_ids\"] = inputs[2]\n",
    "            transformer_result = self.model(**running)\n",
    "            return transformer_result[0]\n",
    "        \n",
    "    from roberta import RobertaModel\n",
    "    word[\"embedding\"] = RobertaModelLearner('input_ids', 'attention_mask', 'timestep_type_ids', batchify=[pair_contains_words], module=RobertaModel.from_pretrained('tli8hf/unqover-roberta-large-squad').to('cpu'))\n",
    "            \n",
    "    \n",
    "    import torch.nn as nn\n",
    "    \n",
    "    word['start'] = BatchifyModuleLearner('embedding', batchify=[pair_contains_words], module=nn.Sequential(nn.Linear(1024, 1), nn.Softmax(dim=-1)))\n",
    "    word['end'] = BatchifyModuleLearner('embedding', batchify=[pair_contains_words], module=nn.Sequential(nn.Linear(1024, 1), nn.Softmax(dim=-1)))\n",
    "    \n",
    "    def compute_first(*inputs):\n",
    "        connection = inputs[0].t()\n",
    "        idx = torch.arange(connection.shape[1], 0, -1).to(connection.device)\n",
    "        tmp2= connection * idx\n",
    "        indices = torch.argmax(tmp2, 1, keepdim=True).squeeze(-1)\n",
    "        result = torch.index_select(inputs[1], 0, indices)\n",
    "        return result.to(connection.device)\n",
    "        \n",
    "    pair[\"first_word_repr\"] = FunctionalSensor(word[pair_contains_words], word['embedding'], forward=compute_first)\n",
    "    \n",
    "    pair[non_existence] = ModuleLearner('first_word_repr', module=nn.Sequential(nn.Linear(1024, 2), nn.Softmax(dim=-1)))\n",
    "    pair[unknown_loc] = ModuleLearner('first_word_repr', module=nn.Sequential(nn.Linear(1024, 2), nn.Softmax(dim=-1)))\n",
    "    pair[known_loc] = ModuleLearner('first_word_repr', module=nn.Sequential(nn.Linear(1024, 2), nn.Softmax(dim=-1)))\n",
    "    \n",
    "    pair[non_existence] = ReaderSensor(keyword=\"non_existence\", label=True)\n",
    "    pair[unknown_loc] = ReaderSensor(keyword=\"unknown\", label=True)\n",
    "    pair[known_loc] = ReaderSensor(keyword=\"location\", label=True)\n",
    "    \n",
    "    class BatchifySensor(FunctionalSensor):\n",
    "        import functools\n",
    "        import operator\n",
    "        def __init__(self, *pres, batchify=True, ignore=-1, **kwargs):\n",
    "            super().__init__(*pres, **kwargs)\n",
    "            self.batchify = batchify\n",
    "            self.ignore = ignore\n",
    "            \n",
    "            \n",
    "        def fetch_value(self, pre, selector=None, concept=None):\n",
    "            from regr.graph.relation import Transformed, Relation\n",
    "            from regr.sensor.sensor import Sensor\n",
    "            from regr.graph.property import Property\n",
    "            concept = concept or self.concept\n",
    "            if isinstance(pre, str):\n",
    "                return super().fetch_value(pre, selector, concept)\n",
    "            elif isinstance(pre, (Property, Sensor)):\n",
    "                return self.context_helper[pre]\n",
    "            elif isinstance(pre, Relation):\n",
    "                return self.context_helper[self.concept[pre]]\n",
    "            elif isinstance(pre, Transformed):\n",
    "                return pre(self.context_helper, device=self.device)\n",
    "            return pre\n",
    "    \n",
    "        def define_inputs(self):\n",
    "            self.inputs = []\n",
    "            if len(self.batchify):\n",
    "                hinter = self.fetch_value(self.batchify[0])\n",
    "            for pre_num, pre in enumerate(self.pres):\n",
    "                values = self.fetch_value(pre)\n",
    "                if pre_num in self.ignore:\n",
    "                    self.inputs.append(values)\n",
    "                else:\n",
    "#                     values = torch.stack(values)\n",
    "                    if len(self.batchify):\n",
    "                        final_val = []\n",
    "                        for hint in hinter.t():\n",
    "                            slicer = torch.nonzero(hint).squeeze(-1)\n",
    "                            final_val.append(values.index_select(0, slicer))\n",
    "                        values = torch.stack(final_val)\n",
    "                    self.inputs.append(values)\n",
    "                \n",
    "        def update_pre_context(\n",
    "            self,\n",
    "            data_item: Dict[str, Any],\n",
    "            concept=None\n",
    "        ) -> Any:\n",
    "            super().update_pre_context(data_item, concept)\n",
    "            concept = concept or self.concept\n",
    "            for batchifier in self.batchify:\n",
    "                for sensor in concept[batchifier].find(self.non_label_sensor):\n",
    "                    sensor(data_item=data_item)\n",
    "                    \n",
    "        def update_context(\n",
    "            self,\n",
    "            data_item: Dict[str, Any],\n",
    "            force=False,\n",
    "            override=True):\n",
    "            if not force and self in data_item:\n",
    "                # data_item cached results by sensor name. override if forced recalc is needed\n",
    "                val = data_item[self]\n",
    "            else:\n",
    "                self.update_pre_context(data_item)\n",
    "                self.define_inputs()\n",
    "                val = self.forward_wrap()\n",
    "                \n",
    "                if len(self.batchify):\n",
    "                    val = functools.reduce(operator.iconcat, val, [])\n",
    "                    \n",
    "                data_item[self] = val\n",
    "            if override and not self.label:\n",
    "                data_item[self.prop] = val  # override state under property name\n",
    "             \n",
    "    def find_exact_token_start(*inputs):\n",
    "        output = torch.zeros(inputs[0].shape[0], inputs[0].shape[1])\n",
    "        for index, data1 in enumerate(inputs[0]):\n",
    "            if inputs[1][index][0] == \"-\":\n",
    "                continue\n",
    "            token_starts = [-1]\n",
    "            for tindex, token in enumerate(data1[1:-1]):\n",
    "                token_starts.append(token[0].item() - inputs[3][index])\n",
    "            token_starts.append(-1)\n",
    "            final_loc = inputs[1][index][1]\n",
    "            if final_loc[0] != 0 or final_loc[1] != 0:\n",
    "                bert_start_token = token_starts.index(final_loc[0])\n",
    "                output[index][bert_start_token] = 1\n",
    "        return output\n",
    "    \n",
    "    def find_exact_token_end(*inputs):\n",
    "        output = torch.zeros(inputs[0].shape[0], inputs[0].shape[1])\n",
    "        for index, data1 in enumerate(inputs[0]):\n",
    "            if inputs[1][index][0] == \"-\":\n",
    "                continue\n",
    "            token_ends = [-1]\n",
    "            for tindex, token in enumerate(data1[1:-1]):\n",
    "                token_ends.append(token[1].item() - inputs[3][index])\n",
    "            token_ends.append(-1)\n",
    "            final_loc = inputs[1][index][1]\n",
    "            if final_loc[0] != 0 or final_loc[1] != 0:\n",
    "                if final_loc[1] in token_ends:\n",
    "                    bert_end_token = token_ends.index(final_loc[1])\n",
    "                elif final_loc[1] + 1 in token_ends:\n",
    "                    bert_end_token = token_ends.index(final_loc[1] + 1)\n",
    "                elif final_loc[1] + 2 in token_ends:\n",
    "                    bert_end_token = token_ends.index(final_loc[1] + 2)\n",
    "                else:\n",
    "                    raise ValueError(\"the bert end not found\")\n",
    "                output[index][bert_end_token] = 1\n",
    "        return output\n",
    "    \n",
    "    word['start'] = BatchifySensor(word['offset_mapping'], word1['annotations'], word['input_ids'], pair['padding'], batchify=[pair_contains_words], ignore=[1, 3], forward=find_exact_token_start, label=True)\n",
    "    word['end'] = BatchifySensor(word['offset_mapping'], word1['annotations'], word['input_ids'], pair['padding'], batchify=[pair_contains_words], ignore=[1, 3], forward=find_exact_token_end, label=True)\n",
    "    # word[step_contains_word, 'raw'] = ReaderSensor(keyword='words')\n",
    "#     entity['raw'] = ReaderSensor(keyword='entities')\n",
    "\n",
    "#     step[non_existence] = ReaderSensor(procedure_contain_step.forward, 'text', keyword='non_existence')\n",
    "#     step[unknown_loc] = ReaderSensor(procedure_contain_step.forward, 'text', keyword='unknown')\n",
    "#     step[known_loc] = ReaderSensor(procedure_contain_step.forward, 'text', keyword='known')\n",
    "    \n",
    "#     step[non_existence] = ReaderSensor(keyword='non_existence', label=True)\n",
    "#     step[unknown_loc] = ReaderSensor(keyword='unknown', label=True)\n",
    "#     step[known_loc] = ReaderSensor(keyword='known', label=True)\n",
    "    \n",
    "#     action[action_arg1.backward, action_arg2.backward] = JoinReaderSensor(step['text'], keyword='action')\n",
    "    \n",
    "#     action[create] = ReaderSensor(action_arg1.backward, action_arg2.backward, keyword='create')\n",
    "#     action[destroy] = ReaderSensor(action_arg1.backward, action_arg2.backward, keyword='destroy')\n",
    "#     action[other] = ReaderSensor(action_arg1.backward, action_arg2.backward, keyword='other')\n",
    "    \n",
    "#     action[create] = ReaderSensor(keyword='create', label=True)\n",
    "#     action[destroy] = ReaderSensor(keyword='destroy', label=True)\n",
    "#     action[other] = ReaderSensor(keyword='other', label=True)\n",
    "    \n",
    "    before[before_arg1.reversed, before_arg2.reversed] = JoinReaderSensor(keyword=\"before\")\n",
    "    \n",
    "    before[\"check\"] = ReaderSensor(before_arg1.reversed, before_arg2.reversed, keyword=\"before_true\")\n",
    "#     before[\"check\"] = ReaderSensor(keyword=\"before_true\", label=True)\n",
    "    \n",
    "    program = LearningBasedProgram(graph, **{\n",
    "        'Model': PoiModel,\n",
    "    })\n",
    "    return program\n",
    "#     return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # set logger level to see training and testing logs\n",
    "    import logging\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    lbp = model_declaration()\n",
    "\n",
    "    dataset = ProparaReader(\"emnlp18/grids.v1.train.json\", 'parse')  # Adding the info on the reader\n",
    "    \n",
    "    lbp.train(dataset, train_epoch_num=2, Optim=torch.optim.Adam, device='cpu')\n",
    "    \n",
    "    for datanode in lbp.populate(dataset, device=\"cpu\"):\n",
    "#         print(datanode.findDatanodes(select=pair)[0].getAttribute('first_word_repr'))\n",
    "        print(datanode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at tli8hf/unqover-roberta-large-squad and are newly initialized: ['roberta.embeddings.timestep_type_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:regr.program.program:Epoch: 0\n",
      "INFO:regr.program.program:Training:\n",
      "Epoch 0 Training:   0%|          | 0/1504 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:341: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "Epoch 0 Training:   0%|          | 6/1504 [00:08<35:08,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during updating data item with sensor robertamodellearner\n",
      "Error during updating data item with sensor functionalsensor-12\n",
      "Error during updating data item with sensor modulelearner\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-f3bb28b52684>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProparaReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"emnlp18/grids.v1.train.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'parse'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Adding the info on the reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mlbp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_epoch_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdatanode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlbp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/DomiKnowS/regr/program/program.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_set, valid_set, test_set, device, train_epoch_num, Optim)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtraining_set\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 \u001b[0mconsume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Epoch {} Training'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' - loss:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/DomiKnowS/regr/utils.py\u001b[0m in \u001b[0;36mconsume\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconsume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconsume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1105\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1108\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/DomiKnowS/regr/program/program.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/DomiKnowS/regr/program/model/pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data_item, build)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mdata_item\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"graph\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'READER'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mbuilder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataNodeBuilder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;34m*\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0mdatanode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetDataNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatanode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/DomiKnowS/regr/program/model/pytorch.py\u001b[0m in \u001b[0;36mpopulate\u001b[0;34m(self, builder)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# make sure the sensors are evaluated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTorchSensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                     \u001b[0msensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msensors\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_sensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPOPULATE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/DomiKnowS/regr/sensor/pytorch/sensors.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data_item)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_helper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_item\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error during updating data item with sensor {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/DomiKnowS/regr/sensor/pytorch/sensors.py\u001b[0m in \u001b[0;36mupdate_context\u001b[0;34m(self, data_item, force, override)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_pre_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefine_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_wrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/DomiKnowS/regr/sensor/pytorch/sensors.py\u001b[0m in \u001b[0;36mupdate_pre_context\u001b[0;34m(self, data_item, concept)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProperty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0msensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnon_label_sensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0msensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransformed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcept\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/DomiKnowS/regr/sensor/pytorch/sensors.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data_item)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_helper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_item\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error during updating data item with sensor {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/DomiKnowS/regr/sensor/pytorch/sensors.py\u001b[0m in \u001b[0;36mupdate_context\u001b[0;34m(self, data_item, force, override)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_pre_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefine_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_wrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/DomiKnowS/regr/sensor/pytorch/sensors.py\u001b[0m in \u001b[0;36mupdate_pre_context\u001b[0;34m(self, data_item, concept)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProperty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0msensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnon_label_sensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0msensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransformed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcept\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/DomiKnowS/regr/sensor/pytorch/sensors.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data_item)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_helper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_item\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error during updating data item with sensor {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-316c53d16eef>\u001b[0m in \u001b[0;36mupdate_context\u001b[0;34m(self, data_item, force, override)\u001b[0m\n\u001b[1;32m    366\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_pre_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefine_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_wrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/DomiKnowS/regr/sensor/pytorch/sensors.py\u001b[0m in \u001b[0;36mforward_wrap\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_wrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-316c53d16eef>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0mrunning\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mrunning\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timestep_type_ids\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0mtransformer_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrunning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtransformer_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/DomiKnowS/examples/Propara/roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, timestep_type_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    823\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m         )\n\u001b[1;32m    827\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/DomiKnowS/examples/Propara/roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    573\u001b[0m                     \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m                 )\n\u001b[1;32m    577\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/DomiKnowS/examples/Propara/roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m         )\n\u001b[1;32m    496\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/DomiKnowS/examples/Propara/roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         )\n\u001b[1;32m    430\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Framework/DomiKnowS/examples/Propara/roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0mattention_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_probs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mcontext_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0mcontext_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
